
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 4 – Training Models &#8212; Data Science Foundation in Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://jads-nl.github.io/data-science-foundation-curriculum/handson-ml2/original/04_training_linear_models.html" />
    <link rel="shortcut icon" href="../../_static/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chapter 5 – Support Vector Machines" href="05_support_vector_machines.html" />
    <link rel="prev" title="Chapter 3 – Classification" href="03_classification.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/jads-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Foundation in Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Why this JupyterBook?
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Statistical Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../islr/introduction.html">
   Introduction to ISLRv2
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/labs.html">
   Labs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_02.3_introduction.html">
     Lab 2.3: Introduction to Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_03.6_linear_regression.html">
     Lab 3.6: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_04.7_classification_methods.html">
     Lab 4.7: Classification Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_05.3_cross_validation_and_the_bootstrap.html">
     Lab 5.3: Cross-Validation and the Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.1_subset_selection_methods.html">
     Lab 6.5.1: Subset Selection Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.2_ridge_regression_and_the_lasso.html">
     Lab 6.5.2: Ridge Regression and the Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.3_pcr_and_pls_regression.html">
     Lab 6.5.3: PCR and PLS Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_07.8_non_linear_modelling.html">
     Lab 7.8: Non-linear Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_08.3_decision_trees.html">
     Lab 8.3: Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_09.6_support_vector_machines.html">
     Lab 9.6: Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.2_multilayer_network_on_mnist_digit_data.html">
     Lab 10.9.2: A Multilayer Network on the MNIST Digit Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.3_convolutional_neural_networks.html">
     Lab 10.9.3: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.5_imdb_document_classification.html">
     Lab 10.9.5: IMDb Document Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.6_recurrent_neural_networks.html">
     Lab 10.9.6: Recurrent Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_12.5_unsupervised_learning.html">
     Lab 12.5: Unsupervised Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/exercises.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter2/index.html">
     Chapter 2
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise1.html">
       Exercise 2.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise2.html">
       Exercise 2.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise3.html">
       Exercise 2.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise4.html">
       Exercise 2.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise5.html">
       Exercise 2.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise6.html">
       Exercise 2.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise7.html">
       Exercise 2.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise8.html">
       Exercise 2.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise9.html">
       Exercise 2.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise10.html">
       Exercise 2.10
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter3/index.html">
     Chapter 3
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise1.html">
       Exercise 3.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise2.html">
       Exercise 3.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise3.html">
       Exercise 3.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise4.html">
       Exercise 3.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise5.html">
       Exercise 3.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise6.html">
       Exercise 3.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise7.html">
       Exercise 3.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise8.html">
       Exercise 3.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise9.html">
       Exercise 3.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise10.html">
       Exercise 3.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise11.html">
       Exercise 3.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise12.html">
       Exercise 3.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise13.html">
       Exercise 3.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise14.html">
       Exercise 3.14
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise15.html">
       Exercise 3.15
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter4/index.html">
     Chapter 4
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise1.html">
       Exercise 4.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise2.html">
       Exercise 4.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise3.html">
       Exercise 4.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise4.html">
       Exercise 4.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise5.html">
       Exercise 4.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise6.html">
       Exercise 4.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise7.html">
       Exercise 4.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise8.html">
       Exercise 4.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise9.html">
       Exercise 4.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise10.html">
       Exercise 10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise11.html">
       Exercise 11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise12.html">
       Exercise 12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise13.html">
       Exercise 4.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise14.html">
       Exercise 4.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise15.html">
       Exercise 4.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise16.html">
       Exercise 4.16
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter5/index.html">
     Chapter 5
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise1.html">
       Exercise 5.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise2.html">
       Exercise 5.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise3.html">
       Problem 5.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise4.html">
       Exercise 5.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise5.html">
       Exercise 5.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise6.html">
       Exercise 5.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise7.html">
       Exercise 5.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise8.html">
       Exercise 5.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise9.html">
       Exercise 5.9
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter6/index.html">
     Chapter 6
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise1.html">
       Exercise 6.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise2.html">
       Exercise 6.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise3.html">
       Exercise 6.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise4.html">
       Exercise 6.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise5.html">
       Exercise 6.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise6.html">
       Exercise 6.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise7.html">
       Exercise 6.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise8.html">
       Exercise 6.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise9.html">
       Exercise 6.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise10.html">
       Exercise 6.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise11.html">
       Exercise 6.11
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter7/index.html">
     Chapter 7
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise1.html">
       Exercise 7.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise2.html">
       Exercise 7.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise3.html">
       Exercise 7.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise4.html">
       Exercise 7.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise5.html">
       Exercise 7.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise6.html">
       Exercise 7.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise7.html">
       Exercise 7.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise8.html">
       Exercise 7.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise9.html">
       Exercise 7.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise10.html">
       Exercise 7.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise11.html">
       Exercise 7.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise12.html">
       Exercise 7.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter8/index.html">
     Chapter 8
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise1.html">
       Exercise 8.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise2.html">
       Exercise 8.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise3.html">
       Exercise 8.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise4.html">
       Exercise 8.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise5.html">
       Exercise 8.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise6.html">
       Exercise 8.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise7.html">
       Exercise 8.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise8.html">
       Exercise 8.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise9.html">
       Exercise 8.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise10.html">
       Exercise 8.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise11.html">
       Exercise 8.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise12.html">
       Exercise 8.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter9/index.html">
     Chapter 9
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise1.html">
       Exercise 9.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise2.html">
       Exercise 9.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise3.html">
       Exercise 9.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise4.html">
       Exercise 9.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise5.html">
       Exercise 9.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise6.html">
       Exercise 9.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise7.html">
       Exercise 9.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise8.html">
       Exercise 9.8
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter12/index.html">
     Chapter 12
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise1.html">
       Exercise 12.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise2.html">
       Exercise 12.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise3.html">
       Exercise 12.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise4.html">
       Exercise 12.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise5.html">
       Exercise 12.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise6.html">
       Exercise 12.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise7.html">
       Exercise 12.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise8.html">
       Exercise 10.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise9.html">
       Exercise 12.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise10.html">
       Exercise 12.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise11.html">
       Exercise 12.11
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hands-on Machine Learning in Python
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../introduction.html">
   Hands-on Machine Learning with Aurélien Géron
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_the_machine_learning_landscape.html">
     Chapter 1 – The Machine Learning landscape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_end_to_end_machine_learning_project.html">
     Chapter 2 – End-to-end Machine Learning project
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_classification.html">
     Chapter 3 – Classification
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Chapter 4 – Training Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_support_vector_machines.html">
     Chapter 5 – Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_decision_trees.html">
     Chapter 6 – Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07_ensemble_learning_and_random_forests.html">
     Chapter 7 – Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08_dimensionality_reduction.html">
     Chapter 8 – Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09_unsupervised_learning.html">
     Chapter 9 – Unsupervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10_neural_nets_with_keras.html">
     Chapter 10 – Introduction to Artificial Neural Networks with Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11_training_deep_neural_networks.html">
     Chapter 11 – Training Deep Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12_custom_models_and_training_with_tensorflow.html">
     Chapter 12 – Custom Models and Training with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13_loading_and_preprocessing_data.html">
     Chapter 13 – Loading and Preprocessing Data with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14_deep_computer_vision_with_cnns.html">
     Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15_processing_sequences_using_rnns_and_cnns.html">
     Chapter 15 – Processing Sequences Using RNNs and CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="16_nlp_with_rnns_and_attention.html">
     Chapter 16 – Natural Language Processing with RNNs and Attention**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="17_autoencoders_and_gans.html">
     Chapter 17 – Autoencoders and GANs**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18_reinforcement_learning.html">
     Chapter 18 – Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19_training_and_deploying_at_scale.html">
     Chapter 19 – Training and Deploying TensorFlow Models at Scale
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../extra.html">
   Miscellaneous tips &amp; tricks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="math_linear_algebra.html">
     Math primer - Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="math_differential_calculus.html">
     Math primer - Differential Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_autodiff.html">
     Implementation of autodiff techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_gradient_descent_comparison.html">
     Comparison of Batch, Mini-Batch and Stochastic Gradient Descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data visualization with Altair
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction.html">
   Data visualization with Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction-to-interactive-data-visualization.html">
   Introduction to data visualization with Python
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../visualization/altair_get_started.html">
   Getting Started with Altair
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_introduction.html">
     Introduction to Altair
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_marks_encoding.html">
     Data Types, Graphical Marks, and Visual Encoding Channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_data_transformation.html">
     Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_scales_axes_legends.html">
     Scales, Axes, and Legends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_view_composition.html">
     Multi-View Composition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_interaction.html">
     Interaction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_cartographic.html">
     Cartographic Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_debugging.html">
     Altair Debugging Guide
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Interpretable Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../iml/introduction.html">
   Introduction to IML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_partial_dependence.html">
     Partial Dependence and Individual Conditional Expectation Plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance.html">
     Permutation Importance vs Random Forest Feature Importance (MDI)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance_multicollinear.html">
     Permutation Importance with Multicollinear or Correlated Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/interpreting-machine-learning-models.html">
     IML with Pima Indians and the Titanic datasets
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Principles of time-series forecasting
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/introduction.html">
   Introduction to FPP3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/examples-time-series-forecasting-with-python.html">
   Examples of time-series forecasting with Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural language processing with spaCy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/introduction.html">
   Introduction to NLP with spaCy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../nlp/dutch-restaurant-reviews.html">
   Dutch restaurant reviews
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-dutch-restaurant-reviews.html">
     Analyzing Dutch restaurant reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/prepare-restoreviews-dataset.html">
     Fetch and prepare reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-pipeline-example.html">
     Objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/language-detection-with-character-quadgrams.html">
     Extra: language detection with character quadgrams
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-model-sizes.html">
     Extra: plot of transformer model sizes
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jads-nl/data-science-foundation-in-python/main?urlpath=tree/data_science_foundation_in_python/handson-ml2/original/04_training_linear_models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jads-nl/data-science-foundation-in-python/blob/main/data_science_foundation_in_python/handson-ml2/original/04_training_linear_models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-in-python"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-in-python/issues/new?title=Issue%20on%20page%20%2Fhandson-ml2/original/04_training_linear_models.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/handson-ml2/original/04_training_linear_models.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 4 – Training Models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression">
   Linear Regression
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-normal-equation">
     The Normal Equation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   Gradient Descent
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-gradient-descent">
     Batch Gradient Descent
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stochastic-gradient-descent">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mini-batch-gradient-descent">
     Mini-batch gradient descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#polynomial-regression">
   Polynomial Regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-curves">
   Learning Curves
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularized-linear-models">
   Regularized Linear Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ridge-regression">
     Ridge Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso-regression">
     Lasso Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#elastic-net">
     Elastic Net
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#early-stopping">
     Early Stopping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression">
   Logistic Regression
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-boundaries">
     Decision Boundaries
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#softmax-regression">
     Softmax Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-11">
     1. to 11.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-gradient-descent-with-early-stopping-for-softmax-regression">
     12. Batch Gradient Descent with early stopping for Softmax Regression
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 4 – Training Models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 4 – Training Models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression">
   Linear Regression
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-normal-equation">
     The Normal Equation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-descent">
   Gradient Descent
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-gradient-descent">
     Batch Gradient Descent
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stochastic-gradient-descent">
     Stochastic Gradient Descent
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mini-batch-gradient-descent">
     Mini-batch gradient descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#polynomial-regression">
   Polynomial Regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-curves">
   Learning Curves
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regularized-linear-models">
   Regularized Linear Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ridge-regression">
     Ridge Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso-regression">
     Lasso Regression
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#elastic-net">
     Elastic Net
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#early-stopping">
     Early Stopping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression">
   Logistic Regression
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-boundaries">
     Decision Boundaries
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#softmax-regression">
     Softmax Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-11">
     1. to 11.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-gradient-descent-with-early-stopping-for-softmax-regression">
     12. Batch Gradient Descent with early stopping for Softmax Regression
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-4-training-models">
<h1>Chapter 4 – Training Models<a class="headerlink" href="#chapter-4-training-models" title="Permalink to this headline">#</a></h1>
<p><em>This notebook contains all the sample code and solutions to the exercises in chapter 4.</em></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">#</a></h1>
<p>First, let’s import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Python ≥3.5 is required
import sys
assert sys.version_info &gt;= (3, 5)

# Scikit-Learn ≥0.20 is required
import sklearn
assert sklearn.__version__ &gt;= &quot;0.20&quot;

# Common imports
import numpy as np
import os

# to make this notebook&#39;s output stable across runs
np.random.seed(42)

# To plot pretty figures
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc(&#39;axes&#39;, labelsize=14)
mpl.rc(&#39;xtick&#39;, labelsize=12)
mpl.rc(&#39;ytick&#39;, labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = &quot;.&quot;
CHAPTER_ID = &quot;training_linear_models&quot;
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, &quot;images&quot;, CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension=&quot;png&quot;, resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + &quot;.&quot; + fig_extension)
    print(&quot;Saving figure&quot;, fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="linear-regression">
<h1>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">#</a></h1>
<section id="the-normal-equation">
<h2>The Normal Equation<a class="headerlink" href="#the-normal-equation" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np

X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.plot(X, y, &quot;b.&quot;)
plt.xlabel(&quot;$x_1$&quot;, fontsize=18)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.axis([0, 2, 0, 15])
save_fig(&quot;generated_data_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure generated_data_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_8_1.png" src="../../_images/04_training_linear_models_8_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance
theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta_best
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21509616],
       [2.77011339]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_new = np.array([[0], [2]])
X_new_b = np.c_[np.ones((2, 1)), X_new]  # add x0 = 1 to each instance
y_predict = X_new_b.dot(theta_best)
y_predict
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21509616],
       [9.75532293]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.plot(X_new, y_predict, &quot;r-&quot;)
plt.plot(X, y, &quot;b.&quot;)
plt.axis([0, 2, 0, 15])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/04_training_linear_models_12_0.png" src="../../_images/04_training_linear_models_12_0.png" />
</div>
</div>
<p>The figure in the book actually corresponds to the following code, with a legend and axis labels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.plot(X_new, y_predict, &quot;r-&quot;, linewidth=2, label=&quot;Predictions&quot;)
plt.plot(X, y, &quot;b.&quot;)
plt.xlabel(&quot;$x_1$&quot;, fontsize=18)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.legend(loc=&quot;upper left&quot;, fontsize=14)
plt.axis([0, 2, 0, 15])
save_fig(&quot;linear_model_predictions_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure linear_model_predictions_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_14_1.png" src="../../_images/04_training_linear_models_14_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(X, y)
lin_reg.intercept_, lin_reg.coef_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([4.21509616]), array([[2.77011339]]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lin_reg.predict(X_new)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21509616],
       [9.75532293]])
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> class is based on the <code class="docutils literal notranslate"><span class="pre">scipy.linalg.lstsq()</span></code> function (the name stands for “least squares”), which you could call directly:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6)
theta_best_svd
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21509616],
       [2.77011339]])
</pre></div>
</div>
</div>
</div>
<p>This function computes <span class="math notranslate nohighlight">\(\mathbf{X}^+\mathbf{y}\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{X}^{+}\)</span> is the <em>pseudoinverse</em> of <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> (specifically the Moore-Penrose inverse). You can use <code class="docutils literal notranslate"><span class="pre">np.linalg.pinv()</span></code> to compute the pseudoinverse directly:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.linalg.pinv(X_b).dot(y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21509616],
       [2.77011339]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="gradient-descent">
<h1>Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">#</a></h1>
<section id="batch-gradient-descent">
<h2>Batch Gradient Descent<a class="headerlink" href="#batch-gradient-descent" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>eta = 0.1  # learning rate
n_iterations = 1000
m = 100

theta = np.random.randn(2,1)  # random initialization

for iteration in range(n_iterations):
    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)
    theta = theta - eta * gradients
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21509616],
       [2.77011339]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_new_b.dot(theta)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21509616],
       [9.75532293]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta_path_bgd = []

def plot_gradient_descent(theta, eta, theta_path=None):
    m = len(X_b)
    plt.plot(X, y, &quot;b.&quot;)
    n_iterations = 1000
    for iteration in range(n_iterations):
        if iteration &lt; 10:
            y_predict = X_new_b.dot(theta)
            style = &quot;b-&quot; if iteration &gt; 0 else &quot;r--&quot;
            plt.plot(X_new, y_predict, style)
        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)
        theta = theta - eta * gradients
        if theta_path is not None:
            theta_path.append(theta)
    plt.xlabel(&quot;$x_1$&quot;, fontsize=18)
    plt.axis([0, 2, 0, 15])
    plt.title(r&quot;$\eta = {}$&quot;.format(eta), fontsize=16)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
theta = np.random.randn(2,1)  # random initialization

plt.figure(figsize=(10,4))
plt.subplot(131); plot_gradient_descent(theta, eta=0.02)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)
plt.subplot(133); plot_gradient_descent(theta, eta=0.5)

save_fig(&quot;gradient_descent_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure gradient_descent_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_26_1.png" src="../../_images/04_training_linear_models_26_1.png" />
</div>
</div>
</section>
<section id="stochastic-gradient-descent">
<h2>Stochastic Gradient Descent<a class="headerlink" href="#stochastic-gradient-descent" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta_path_sgd = []
m = len(X_b)
np.random.seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_epochs = 50
t0, t1 = 5, 50  # learning schedule hyperparameters

def learning_schedule(t):
    return t0 / (t + t1)

theta = np.random.randn(2,1)  # random initialization

for epoch in range(n_epochs):
    for i in range(m):
        if epoch == 0 and i &lt; 20:                    # not shown in the book
            y_predict = X_new_b.dot(theta)           # not shown
            style = &quot;b-&quot; if i &gt; 0 else &quot;r--&quot;         # not shown
            plt.plot(X_new, y_predict, style)        # not shown
        random_index = np.random.randint(m)
        xi = X_b[random_index:random_index+1]
        yi = y[random_index:random_index+1]
        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)
        eta = learning_schedule(epoch * m + i)
        theta = theta - eta * gradients
        theta_path_sgd.append(theta)                 # not shown

plt.plot(X, y, &quot;b.&quot;)                                 # not shown
plt.xlabel(&quot;$x_1$&quot;, fontsize=18)                     # not shown
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)           # not shown
plt.axis([0, 2, 0, 15])                              # not shown
save_fig(&quot;sgd_plot&quot;)                                 # not shown
plt.show()                                           # not shown
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure sgd_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_29_1.png" src="../../_images/04_training_linear_models_29_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.21076011],
       [2.74856079]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import SGDRegressor

sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1, random_state=42)
sgd_reg.fit(X, y.ravel())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SGDRegressor(eta0=0.1, penalty=None, random_state=42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sgd_reg.intercept_, sgd_reg.coef_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([4.24365286]), array([2.8250878]))
</pre></div>
</div>
</div>
</div>
</section>
<section id="mini-batch-gradient-descent">
<h2>Mini-batch gradient descent<a class="headerlink" href="#mini-batch-gradient-descent" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta_path_mgd = []

n_iterations = 50
minibatch_size = 20

np.random.seed(42)
theta = np.random.randn(2,1)  # random initialization

t0, t1 = 200, 1000
def learning_schedule(t):
    return t0 / (t + t1)

t = 0
for epoch in range(n_iterations):
    shuffled_indices = np.random.permutation(m)
    X_b_shuffled = X_b[shuffled_indices]
    y_shuffled = y[shuffled_indices]
    for i in range(0, m, minibatch_size):
        t += 1
        xi = X_b_shuffled[i:i+minibatch_size]
        yi = y_shuffled[i:i+minibatch_size]
        gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)
        eta = learning_schedule(t)
        theta = theta - eta * gradients
        theta_path_mgd.append(theta)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[4.25214635],
       [2.7896408 ]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>theta_path_bgd = np.array(theta_path_bgd)
theta_path_sgd = np.array(theta_path_sgd)
theta_path_mgd = np.array(theta_path_mgd)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize=(7,4))
plt.plot(theta_path_sgd[:, 0], theta_path_sgd[:, 1], &quot;r-s&quot;, linewidth=1, label=&quot;Stochastic&quot;)
plt.plot(theta_path_mgd[:, 0], theta_path_mgd[:, 1], &quot;g-+&quot;, linewidth=2, label=&quot;Mini-batch&quot;)
plt.plot(theta_path_bgd[:, 0], theta_path_bgd[:, 1], &quot;b-o&quot;, linewidth=3, label=&quot;Batch&quot;)
plt.legend(loc=&quot;upper left&quot;, fontsize=16)
plt.xlabel(r&quot;$\theta_0$&quot;, fontsize=20)
plt.ylabel(r&quot;$\theta_1$   &quot;, fontsize=20, rotation=0)
plt.axis([2.5, 4.5, 2.3, 3.9])
save_fig(&quot;gradient_descent_paths_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure gradient_descent_paths_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_37_1.png" src="../../_images/04_training_linear_models_37_1.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="polynomial-regression">
<h1>Polynomial Regression<a class="headerlink" href="#polynomial-regression" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
import numpy.random as rnd

np.random.seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>m = 100
X = 6 * np.random.rand(m, 1) - 3
y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.plot(X, y, &quot;b.&quot;)
plt.xlabel(&quot;$x_1$&quot;, fontsize=18)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.axis([-3, 3, 0, 10])
save_fig(&quot;quadratic_data_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure quadratic_data_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_41_1.png" src="../../_images/04_training_linear_models_41_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.preprocessing import PolynomialFeatures
poly_features = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly_features.fit_transform(X)
X[0]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.75275929])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_poly[0]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.75275929,  0.56664654])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lin_reg = LinearRegression()
lin_reg.fit(X_poly, y)
lin_reg.intercept_, lin_reg.coef_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([1.78134581]), array([[0.93366893, 0.56456263]]))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_new=np.linspace(-3, 3, 100).reshape(100, 1)
X_new_poly = poly_features.transform(X_new)
y_new = lin_reg.predict(X_new_poly)
plt.plot(X, y, &quot;b.&quot;)
plt.plot(X_new, y_new, &quot;r-&quot;, linewidth=2, label=&quot;Predictions&quot;)
plt.xlabel(&quot;$x_1$&quot;, fontsize=18)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.legend(loc=&quot;upper left&quot;, fontsize=14)
plt.axis([-3, 3, 0, 10])
save_fig(&quot;quadratic_predictions_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure quadratic_predictions_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_45_1.png" src="../../_images/04_training_linear_models_45_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

for style, width, degree in ((&quot;g-&quot;, 1, 300), (&quot;b--&quot;, 2, 2), (&quot;r-+&quot;, 2, 1)):
    polybig_features = PolynomialFeatures(degree=degree, include_bias=False)
    std_scaler = StandardScaler()
    lin_reg = LinearRegression()
    polynomial_regression = Pipeline([
            (&quot;poly_features&quot;, polybig_features),
            (&quot;std_scaler&quot;, std_scaler),
            (&quot;lin_reg&quot;, lin_reg),
        ])
    polynomial_regression.fit(X, y)
    y_newbig = polynomial_regression.predict(X_new)
    plt.plot(X_new, y_newbig, style, label=str(degree), linewidth=width)

plt.plot(X, y, &quot;b.&quot;, linewidth=3)
plt.legend(loc=&quot;upper left&quot;)
plt.xlabel(&quot;$x_1$&quot;, fontsize=18)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.axis([-3, 3, 0, 10])
save_fig(&quot;high_degree_polynomials_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure high_degree_polynomials_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_46_1.png" src="../../_images/04_training_linear_models_46_1.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="learning-curves">
<h1>Learning Curves<a class="headerlink" href="#learning-curves" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

def plot_learning_curves(model, X, y):
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)
    train_errors, val_errors = [], []
    for m in range(1, len(X_train) + 1):
        model.fit(X_train[:m], y_train[:m])
        y_train_predict = model.predict(X_train[:m])
        y_val_predict = model.predict(X_val)
        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))
        val_errors.append(mean_squared_error(y_val, y_val_predict))

    plt.plot(np.sqrt(train_errors), &quot;r-+&quot;, linewidth=2, label=&quot;train&quot;)
    plt.plot(np.sqrt(val_errors), &quot;b-&quot;, linewidth=3, label=&quot;val&quot;)
    plt.legend(loc=&quot;upper right&quot;, fontsize=14)   # not shown in the book
    plt.xlabel(&quot;Training set size&quot;, fontsize=14) # not shown
    plt.ylabel(&quot;RMSE&quot;, fontsize=14)              # not shown
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lin_reg = LinearRegression()
plot_learning_curves(lin_reg, X, y)
plt.axis([0, 80, 0, 3])                         # not shown in the book
save_fig(&quot;underfitting_learning_curves_plot&quot;)   # not shown
plt.show()                                      # not shown
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure underfitting_learning_curves_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_49_1.png" src="../../_images/04_training_linear_models_49_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.pipeline import Pipeline

polynomial_regression = Pipeline([
        (&quot;poly_features&quot;, PolynomialFeatures(degree=10, include_bias=False)),
        (&quot;lin_reg&quot;, LinearRegression()),
    ])

plot_learning_curves(polynomial_regression, X, y)
plt.axis([0, 80, 0, 3])           # not shown
save_fig(&quot;learning_curves_plot&quot;)  # not shown
plt.show()                        # not shown
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure learning_curves_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_50_1.png" src="../../_images/04_training_linear_models_50_1.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="regularized-linear-models">
<h1>Regularized Linear Models<a class="headerlink" href="#regularized-linear-models" title="Permalink to this headline">#</a></h1>
<section id="ridge-regression">
<h2>Ridge Regression<a class="headerlink" href="#ridge-regression" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
m = 20
X = 3 * np.random.rand(m, 1)
y = 1 + 0.5 * X + np.random.randn(m, 1) / 1.5
X_new = np.linspace(0, 3, 100).reshape(100, 1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import Ridge
ridge_reg = Ridge(alpha=1, solver=&quot;cholesky&quot;, random_state=42)
ridge_reg.fit(X, y)
ridge_reg.predict([[1.5]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.55071465]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ridge_reg = Ridge(alpha=1, solver=&quot;sag&quot;, random_state=42)
ridge_reg.fit(X, y)
ridge_reg.predict([[1.5]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.5507201]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import Ridge

def plot_model(model_class, polynomial, alphas, **model_kargs):
    for alpha, style in zip(alphas, (&quot;b-&quot;, &quot;g--&quot;, &quot;r:&quot;)):
        model = model_class(alpha, **model_kargs) if alpha &gt; 0 else LinearRegression()
        if polynomial:
            model = Pipeline([
                    (&quot;poly_features&quot;, PolynomialFeatures(degree=10, include_bias=False)),
                    (&quot;std_scaler&quot;, StandardScaler()),
                    (&quot;regul_reg&quot;, model),
                ])
        model.fit(X, y)
        y_new_regul = model.predict(X_new)
        lw = 2 if alpha &gt; 0 else 1
        plt.plot(X_new, y_new_regul, style, linewidth=lw, label=r&quot;$\alpha = {}$&quot;.format(alpha))
    plt.plot(X, y, &quot;b.&quot;, linewidth=3)
    plt.legend(loc=&quot;upper left&quot;, fontsize=15)
    plt.xlabel(&quot;$x_1$&quot;, fontsize=18)
    plt.axis([0, 3, 0, 4])

plt.figure(figsize=(8,4))
plt.subplot(121)
plot_model(Ridge, polynomial=False, alphas=(0, 10, 100), random_state=42)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.subplot(122)
plot_model(Ridge, polynomial=True, alphas=(0, 10**-5, 1), random_state=42)

save_fig(&quot;ridge_regression_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure ridge_regression_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_56_1.png" src="../../_images/04_training_linear_models_56_1.png" />
</div>
</div>
<p><strong>Note</strong>: to be future-proof, we set <code class="docutils literal notranslate"><span class="pre">max_iter=1000</span></code> and <code class="docutils literal notranslate"><span class="pre">tol=1e-3</span></code> because these will be the default values in Scikit-Learn 0.21.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sgd_reg = SGDRegressor(penalty=&quot;l2&quot;, max_iter=1000, tol=1e-3, random_state=42)
sgd_reg.fit(X, y.ravel())
sgd_reg.predict([[1.5]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.47012588])
</pre></div>
</div>
</div>
</div>
</section>
<section id="lasso-regression">
<h2>Lasso Regression<a class="headerlink" href="#lasso-regression" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import Lasso

plt.figure(figsize=(8,4))
plt.subplot(121)
plot_model(Lasso, polynomial=False, alphas=(0, 0.1, 1), random_state=42)
plt.ylabel(&quot;$y$&quot;, rotation=0, fontsize=18)
plt.subplot(122)
plot_model(Lasso, polynomial=True, alphas=(0, 10**-7, 1), random_state=42)

save_fig(&quot;lasso_regression_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:531: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.802867703827423, tolerance: 0.0009294783355207351
  positive)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure lasso_regression_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_60_2.png" src="../../_images/04_training_linear_models_60_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import Lasso
lasso_reg = Lasso(alpha=0.1)
lasso_reg.fit(X, y)
lasso_reg.predict([[1.5]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.53788174])
</pre></div>
</div>
</div>
</div>
</section>
<section id="elastic-net">
<h2>Elastic Net<a class="headerlink" href="#elastic-net" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import ElasticNet
elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)
elastic_net.fit(X, y)
elastic_net.predict([[1.5]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.54333232])
</pre></div>
</div>
</div>
</div>
</section>
<section id="early-stopping">
<h2>Early Stopping<a class="headerlink" href="#early-stopping" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
m = 100
X = 6 * np.random.rand(m, 1) - 3
y = 2 + X + 0.5 * X**2 + np.random.randn(m, 1)

X_train, X_val, y_train, y_val = train_test_split(X[:50], y[:50].ravel(), test_size=0.5, random_state=10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from copy import deepcopy

poly_scaler = Pipeline([
        (&quot;poly_features&quot;, PolynomialFeatures(degree=90, include_bias=False)),
        (&quot;std_scaler&quot;, StandardScaler())
    ])

X_train_poly_scaled = poly_scaler.fit_transform(X_train)
X_val_poly_scaled = poly_scaler.transform(X_val)

sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True,
                       penalty=None, learning_rate=&quot;constant&quot;, eta0=0.0005, random_state=42)

minimum_val_error = float(&quot;inf&quot;)
best_epoch = None
best_model = None
for epoch in range(1000):
    sgd_reg.fit(X_train_poly_scaled, y_train)  # continues where it left off
    y_val_predict = sgd_reg.predict(X_val_poly_scaled)
    val_error = mean_squared_error(y_val, y_val_predict)
    if val_error &lt; minimum_val_error:
        minimum_val_error = val_error
        best_epoch = epoch
        best_model = deepcopy(sgd_reg)
</pre></div>
</div>
</div>
</div>
<p>Create the graph:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True,
                       penalty=None, learning_rate=&quot;constant&quot;, eta0=0.0005, random_state=42)

n_epochs = 500
train_errors, val_errors = [], []
for epoch in range(n_epochs):
    sgd_reg.fit(X_train_poly_scaled, y_train)
    y_train_predict = sgd_reg.predict(X_train_poly_scaled)
    y_val_predict = sgd_reg.predict(X_val_poly_scaled)
    train_errors.append(mean_squared_error(y_train, y_train_predict))
    val_errors.append(mean_squared_error(y_val, y_val_predict))

best_epoch = np.argmin(val_errors)
best_val_rmse = np.sqrt(val_errors[best_epoch])

plt.annotate(&#39;Best model&#39;,
             xy=(best_epoch, best_val_rmse),
             xytext=(best_epoch, best_val_rmse + 1),
             ha=&quot;center&quot;,
             arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.05),
             fontsize=16,
            )

best_val_rmse -= 0.03  # just to make the graph look better
plt.plot([0, n_epochs], [best_val_rmse, best_val_rmse], &quot;k:&quot;, linewidth=2)
plt.plot(np.sqrt(val_errors), &quot;b-&quot;, linewidth=3, label=&quot;Validation set&quot;)
plt.plot(np.sqrt(train_errors), &quot;r--&quot;, linewidth=2, label=&quot;Training set&quot;)
plt.legend(loc=&quot;upper right&quot;, fontsize=14)
plt.xlabel(&quot;Epoch&quot;, fontsize=14)
plt.ylabel(&quot;RMSE&quot;, fontsize=14)
save_fig(&quot;early_stopping_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure early_stopping_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_68_1.png" src="../../_images/04_training_linear_models_68_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>best_epoch, best_model
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(239,
 SGDRegressor(eta0=0.0005, learning_rate=&#39;constant&#39;, max_iter=1, penalty=None,
              random_state=42, tol=-inf, warm_start=True))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>t1a, t1b, t2a, t2b = -1, 3, -1.5, 1.5

t1s = np.linspace(t1a, t1b, 500)
t2s = np.linspace(t2a, t2b, 500)
t1, t2 = np.meshgrid(t1s, t2s)
T = np.c_[t1.ravel(), t2.ravel()]
Xr = np.array([[1, 1], [1, -1], [1, 0.5]])
yr = 2 * Xr[:, :1] + 0.5 * Xr[:, 1:]

J = (1/len(Xr) * np.sum((T.dot(Xr.T) - yr.T)**2, axis=1)).reshape(t1.shape)

N1 = np.linalg.norm(T, ord=1, axis=1).reshape(t1.shape)
N2 = np.linalg.norm(T, ord=2, axis=1).reshape(t1.shape)

t_min_idx = np.unravel_index(np.argmin(J), J.shape)
t1_min, t2_min = t1[t_min_idx], t2[t_min_idx]

t_init = np.array([[0.25], [-1]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def bgd_path(theta, X, y, l1, l2, core = 1, eta = 0.05, n_iterations = 200):
    path = [theta]
    for iteration in range(n_iterations):
        gradients = core * 2/len(X) * X.T.dot(X.dot(theta) - y) + l1 * np.sign(theta) + l2 * theta
        theta = theta - eta * gradients
        path.append(theta)
    return np.array(path)

fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(10.1, 8))
for i, N, l1, l2, title in ((0, N1, 2., 0, &quot;Lasso&quot;), (1, N2, 0,  2., &quot;Ridge&quot;)):
    JR = J + l1 * N1 + l2 * 0.5 * N2**2
    
    tr_min_idx = np.unravel_index(np.argmin(JR), JR.shape)
    t1r_min, t2r_min = t1[tr_min_idx], t2[tr_min_idx]

    levelsJ=(np.exp(np.linspace(0, 1, 20)) - 1) * (np.max(J) - np.min(J)) + np.min(J)
    levelsJR=(np.exp(np.linspace(0, 1, 20)) - 1) * (np.max(JR) - np.min(JR)) + np.min(JR)
    levelsN=np.linspace(0, np.max(N), 10)
    
    path_J = bgd_path(t_init, Xr, yr, l1=0, l2=0)
    path_JR = bgd_path(t_init, Xr, yr, l1, l2)
    path_N = bgd_path(np.array([[2.0], [0.5]]), Xr, yr, np.sign(l1)/3, np.sign(l2), core=0)

    ax = axes[i, 0]
    ax.grid(True)
    ax.axhline(y=0, color=&#39;k&#39;)
    ax.axvline(x=0, color=&#39;k&#39;)
    ax.contourf(t1, t2, N / 2., levels=levelsN)
    ax.plot(path_N[:, 0], path_N[:, 1], &quot;y--&quot;)
    ax.plot(0, 0, &quot;ys&quot;)
    ax.plot(t1_min, t2_min, &quot;ys&quot;)
    ax.set_title(r&quot;$\ell_{}$ penalty&quot;.format(i + 1), fontsize=16)
    ax.axis([t1a, t1b, t2a, t2b])
    if i == 1:
        ax.set_xlabel(r&quot;$\theta_1$&quot;, fontsize=16)
    ax.set_ylabel(r&quot;$\theta_2$&quot;, fontsize=16, rotation=0)

    ax = axes[i, 1]
    ax.grid(True)
    ax.axhline(y=0, color=&#39;k&#39;)
    ax.axvline(x=0, color=&#39;k&#39;)
    ax.contourf(t1, t2, JR, levels=levelsJR, alpha=0.9)
    ax.plot(path_JR[:, 0], path_JR[:, 1], &quot;w-o&quot;)
    ax.plot(path_N[:, 0], path_N[:, 1], &quot;y--&quot;)
    ax.plot(0, 0, &quot;ys&quot;)
    ax.plot(t1_min, t2_min, &quot;ys&quot;)
    ax.plot(t1r_min, t2r_min, &quot;rs&quot;)
    ax.set_title(title, fontsize=16)
    ax.axis([t1a, t1b, t2a, t2b])
    if i == 1:
        ax.set_xlabel(r&quot;$\theta_1$&quot;, fontsize=16)

save_fig(&quot;lasso_vs_ridge_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure lasso_vs_ridge_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_72_1.png" src="../../_images/04_training_linear_models_72_1.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="logistic-regression">
<h1>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">#</a></h1>
<section id="decision-boundaries">
<h2>Decision Boundaries<a class="headerlink" href="#decision-boundaries" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>t = np.linspace(-10, 10, 100)
sig = 1 / (1 + np.exp(-t))
plt.figure(figsize=(9, 3))
plt.plot([-10, 10], [0, 0], &quot;k-&quot;)
plt.plot([-10, 10], [0.5, 0.5], &quot;k:&quot;)
plt.plot([-10, 10], [1, 1], &quot;k:&quot;)
plt.plot([0, 0], [-1.1, 1.1], &quot;k-&quot;)
plt.plot(t, sig, &quot;b-&quot;, linewidth=2, label=r&quot;$\sigma(t) = \frac{1}{1 + e^{-t}}$&quot;)
plt.xlabel(&quot;t&quot;)
plt.legend(loc=&quot;upper left&quot;, fontsize=20)
plt.axis([-10, 10, -0.1, 1.1])
save_fig(&quot;logistic_function_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure logistic_function_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_75_1.png" src="../../_images/04_training_linear_models_75_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn import datasets
iris = datasets.load_iris()
list(iris.keys())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;data&#39;,
 &#39;target&#39;,
 &#39;frame&#39;,
 &#39;target_names&#39;,
 &#39;DESCR&#39;,
 &#39;feature_names&#39;,
 &#39;filename&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(iris.DESCR)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>.. _iris_dataset:

Iris plants dataset
--------------------

**Data Set Characteristics:**

    :Number of Instances: 150 (50 in each of three classes)
    :Number of Attributes: 4 numeric, predictive attributes and the class
    :Attribute Information:
        - sepal length in cm
        - sepal width in cm
        - petal length in cm
        - petal width in cm
        - class:
                - Iris-Setosa
                - Iris-Versicolour
                - Iris-Virginica
                
    :Summary Statistics:

    ============== ==== ==== ======= ===== ====================
                    Min  Max   Mean    SD   Class Correlation
    ============== ==== ==== ======= ===== ====================
    sepal length:   4.3  7.9   5.84   0.83    0.7826
    sepal width:    2.0  4.4   3.05   0.43   -0.4194
    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)
    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)
    ============== ==== ==== ======= ===== ====================

    :Missing Attribute Values: None
    :Class Distribution: 33.3% for each of 3 classes.
    :Creator: R.A. Fisher
    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)
    :Date: July, 1988

The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken
from Fisher&#39;s paper. Note that it&#39;s the same as in R, but not as in the UCI
Machine Learning Repository, which has two wrong data points.

This is perhaps the best known database to be found in the
pattern recognition literature.  Fisher&#39;s paper is a classic in the field and
is referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The
data set contains 3 classes of 50 instances each, where each class refers to a
type of iris plant.  One class is linearly separable from the other 2; the
latter are NOT linearly separable from each other.

.. topic:: References

   - Fisher, R.A. &quot;The use of multiple measurements in taxonomic problems&quot;
     Annual Eugenics, 7, Part II, 179-188 (1936); also in &quot;Contributions to
     Mathematical Statistics&quot; (John Wiley, NY, 1950).
   - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.
     (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.
   - Dasarathy, B.V. (1980) &quot;Nosing Around the Neighborhood: A New System
     Structure and Classification Rule for Recognition in Partially Exposed
     Environments&quot;.  IEEE Transactions on Pattern Analysis and Machine
     Intelligence, Vol. PAMI-2, No. 1, 67-71.
   - Gates, G.W. (1972) &quot;The Reduced Nearest Neighbor Rule&quot;.  IEEE Transactions
     on Information Theory, May 1972, 431-433.
   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al&quot;s AUTOCLASS II
     conceptual clustering system finds 3 classes in the data.
   - Many, many more ...
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X = iris[&quot;data&quot;][:, 3:]  # petal width
y = (iris[&quot;target&quot;] == 2).astype(np.int)  # 1 if Iris virginica, else 0
</pre></div>
</div>
</div>
</div>
<p><strong>Note</strong>: To be future-proof we set <code class="docutils literal notranslate"><span class="pre">solver=&quot;lbfgs&quot;</span></code> since this will be the default value in Scikit-Learn 0.22.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import LogisticRegression
log_reg = LogisticRegression(solver=&quot;lbfgs&quot;, random_state=42)
log_reg.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression(random_state=42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_new = np.linspace(0, 3, 1000).reshape(-1, 1)
y_proba = log_reg.predict_proba(X_new)

plt.plot(X_new, y_proba[:, 1], &quot;g-&quot;, linewidth=2, label=&quot;Iris virginica&quot;)
plt.plot(X_new, y_proba[:, 0], &quot;b--&quot;, linewidth=2, label=&quot;Not Iris virginica&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7fa560acd7d0&gt;]
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_81_1.png" src="../../_images/04_training_linear_models_81_1.png" />
</div>
</div>
<p>The figure in the book actually is actually a bit fancier:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_new = np.linspace(0, 3, 1000).reshape(-1, 1)
y_proba = log_reg.predict_proba(X_new)
decision_boundary = X_new[y_proba[:, 1] &gt;= 0.5][0]

plt.figure(figsize=(8, 3))
plt.plot(X[y==0], y[y==0], &quot;bs&quot;)
plt.plot(X[y==1], y[y==1], &quot;g^&quot;)
plt.plot([decision_boundary, decision_boundary], [-1, 2], &quot;k:&quot;, linewidth=2)
plt.plot(X_new, y_proba[:, 1], &quot;g-&quot;, linewidth=2, label=&quot;Iris virginica&quot;)
plt.plot(X_new, y_proba[:, 0], &quot;b--&quot;, linewidth=2, label=&quot;Not Iris virginica&quot;)
plt.text(decision_boundary+0.02, 0.15, &quot;Decision  boundary&quot;, fontsize=14, color=&quot;k&quot;, ha=&quot;center&quot;)
plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc=&#39;b&#39;, ec=&#39;b&#39;)
plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc=&#39;g&#39;, ec=&#39;g&#39;)
plt.xlabel(&quot;Petal width (cm)&quot;, fontsize=14)
plt.ylabel(&quot;Probability&quot;, fontsize=14)
plt.legend(loc=&quot;center left&quot;, fontsize=14)
plt.axis([0, 3, -0.02, 1.02])
save_fig(&quot;logistic_regression_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure logistic_regression_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_83_1.png" src="../../_images/04_training_linear_models_83_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>decision_boundary
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.66066066])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>log_reg.predict([[1.7], [1.5]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 0])
</pre></div>
</div>
</div>
</div>
</section>
<section id="softmax-regression">
<h2>Softmax Regression<a class="headerlink" href="#softmax-regression" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import LogisticRegression

X = iris[&quot;data&quot;][:, (2, 3)]  # petal length, petal width
y = (iris[&quot;target&quot;] == 2).astype(np.int)

log_reg = LogisticRegression(solver=&quot;lbfgs&quot;, C=10**10, random_state=42)
log_reg.fit(X, y)

x0, x1 = np.meshgrid(
        np.linspace(2.9, 7, 500).reshape(-1, 1),
        np.linspace(0.8, 2.7, 200).reshape(-1, 1),
    )
X_new = np.c_[x0.ravel(), x1.ravel()]

y_proba = log_reg.predict_proba(X_new)

plt.figure(figsize=(10, 4))
plt.plot(X[y==0, 0], X[y==0, 1], &quot;bs&quot;)
plt.plot(X[y==1, 0], X[y==1, 1], &quot;g^&quot;)

zz = y_proba[:, 1].reshape(x0.shape)
contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)


left_right = np.array([2.9, 7])
boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]

plt.clabel(contour, inline=1, fontsize=12)
plt.plot(left_right, boundary, &quot;k--&quot;, linewidth=3)
plt.text(3.5, 1.5, &quot;Not Iris virginica&quot;, fontsize=14, color=&quot;b&quot;, ha=&quot;center&quot;)
plt.text(6.5, 2.3, &quot;Iris virginica&quot;, fontsize=14, color=&quot;g&quot;, ha=&quot;center&quot;)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.axis([2.9, 7, 0.8, 2.7])
save_fig(&quot;logistic_regression_contour_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure logistic_regression_contour_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_87_1.png" src="../../_images/04_training_linear_models_87_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X = iris[&quot;data&quot;][:, (2, 3)]  # petal length, petal width
y = iris[&quot;target&quot;]

softmax_reg = LogisticRegression(multi_class=&quot;multinomial&quot;,solver=&quot;lbfgs&quot;, C=10, random_state=42)
softmax_reg.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression(C=10, multi_class=&#39;multinomial&#39;, random_state=42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>x0, x1 = np.meshgrid(
        np.linspace(0, 8, 500).reshape(-1, 1),
        np.linspace(0, 3.5, 200).reshape(-1, 1),
    )
X_new = np.c_[x0.ravel(), x1.ravel()]


y_proba = softmax_reg.predict_proba(X_new)
y_predict = softmax_reg.predict(X_new)

zz1 = y_proba[:, 1].reshape(x0.shape)
zz = y_predict.reshape(x0.shape)

plt.figure(figsize=(10, 4))
plt.plot(X[y==2, 0], X[y==2, 1], &quot;g^&quot;, label=&quot;Iris virginica&quot;)
plt.plot(X[y==1, 0], X[y==1, 1], &quot;bs&quot;, label=&quot;Iris versicolor&quot;)
plt.plot(X[y==0, 0], X[y==0, 1], &quot;yo&quot;, label=&quot;Iris setosa&quot;)

from matplotlib.colors import ListedColormap
custom_cmap = ListedColormap([&#39;#fafab0&#39;,&#39;#9898ff&#39;,&#39;#a0faa0&#39;])

plt.contourf(x0, x1, zz, cmap=custom_cmap)
contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)
plt.clabel(contour, inline=1, fontsize=12)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.legend(loc=&quot;center left&quot;, fontsize=14)
plt.axis([0, 7, 0, 3.5])
save_fig(&quot;softmax_regression_contour_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure softmax_regression_contour_plot
</pre></div>
</div>
<img alt="../../_images/04_training_linear_models_89_1.png" src="../../_images/04_training_linear_models_89_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>softmax_reg.predict([[5, 2]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>softmax_reg.predict_proba([[5, 2]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[6.38014896e-07, 5.74929995e-02, 9.42506362e-01]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-solutions">
<h1>Exercise solutions<a class="headerlink" href="#exercise-solutions" title="Permalink to this headline">#</a></h1>
<section id="to-11">
<h2>1. to 11.<a class="headerlink" href="#to-11" title="Permalink to this headline">#</a></h2>
<p>See appendix A.</p>
</section>
<section id="batch-gradient-descent-with-early-stopping-for-softmax-regression">
<h2>12. Batch Gradient Descent with early stopping for Softmax Regression<a class="headerlink" href="#batch-gradient-descent-with-early-stopping-for-softmax-regression" title="Permalink to this headline">#</a></h2>
<p>(without using Scikit-Learn)</p>
<p>Let’s start by loading the data. We will just reuse the Iris dataset we loaded earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X = iris[&quot;data&quot;][:, (2, 3)]  # petal length, petal width
y = iris[&quot;target&quot;]
</pre></div>
</div>
</div>
</div>
<p>We need to add the bias term for every instance (<span class="math notranslate nohighlight">\(x_0 = 1\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_with_bias = np.c_[np.ones([len(X), 1]), X]
</pre></div>
</div>
</div>
</div>
<p>And let’s set the random seed so the output of this exercise solution is reproducible:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(2042)
</pre></div>
</div>
</div>
</div>
<p>The easiest option to split the dataset into a training set, a validation set and a test set would be to use Scikit-Learn’s <code class="docutils literal notranslate"><span class="pre">train_test_split()</span></code> function, but the point of this exercise is to try understand the algorithms by implementing them manually. So here is one possible implementation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>test_ratio = 0.2
validation_ratio = 0.2
total_size = len(X_with_bias)

test_size = int(total_size * test_ratio)
validation_size = int(total_size * validation_ratio)
train_size = total_size - test_size - validation_size

rnd_indices = np.random.permutation(total_size)

X_train = X_with_bias[rnd_indices[:train_size]]
y_train = y[rnd_indices[:train_size]]
X_valid = X_with_bias[rnd_indices[train_size:-test_size]]
y_valid = y[rnd_indices[train_size:-test_size]]
X_test = X_with_bias[rnd_indices[-test_size:]]
y_test = y[rnd_indices[-test_size:]]
</pre></div>
</div>
</div>
</div>
<p>The targets are currently class indices (0, 1 or 2), but we need target class probabilities to train the Softmax Regression model. Each instance will have target class probabilities equal to 0.0 for all classes except for the target class which will have a probability of 1.0 (in other words, the vector of class probabilities for ay given instance is a one-hot vector). Let’s write a small function to convert the vector of class indices into a matrix containing a one-hot vector for each instance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def to_one_hot(y):
    n_classes = y.max() + 1
    m = len(y)
    Y_one_hot = np.zeros((m, n_classes))
    Y_one_hot[np.arange(m), y] = 1
    return Y_one_hot
</pre></div>
</div>
</div>
</div>
<p>Let’s test this function on the first 10 instances:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_train[:10]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 1, 2, 1, 1, 0, 1, 1, 1, 0])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>to_one_hot(y_train[:10])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.],
       [0., 1., 0.],
       [0., 1., 0.],
       [1., 0., 0.],
       [0., 1., 0.],
       [0., 1., 0.],
       [0., 1., 0.],
       [1., 0., 0.]])
</pre></div>
</div>
</div>
</div>
<p>Looks good, so let’s create the target class probabilities matrix for the training set and the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>Y_train_one_hot = to_one_hot(y_train)
Y_valid_one_hot = to_one_hot(y_valid)
Y_test_one_hot = to_one_hot(y_test)
</pre></div>
</div>
</div>
</div>
<p>Now let’s implement the Softmax function. Recall that it is defined by the following equation:</p>
<p><span class="math notranslate nohighlight">\(\sigma\left(\mathbf{s}(\mathbf{x})\right)_k = \dfrac{\exp\left(s_k(\mathbf{x})\right)}{\sum\limits_{j=1}^{K}{\exp\left(s_j(\mathbf{x})\right)}}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def softmax(logits):
    exps = np.exp(logits)
    exp_sums = np.sum(exps, axis=1, keepdims=True)
    return exps / exp_sums
</pre></div>
</div>
</div>
</div>
<p>We are almost ready to start training. Let’s define the number of inputs and outputs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_inputs = X_train.shape[1] # == 3 (2 features plus the bias term)
n_outputs = len(np.unique(y_train))   # == 3 (3 iris classes)
</pre></div>
</div>
</div>
</div>
<p>Now here comes the hardest part: training! Theoretically, it’s simple: it’s just a matter of translating the math equations into Python code. But in practice, it can be quite tricky: in particular, it’s easy to mix up the order of the terms, or the indices. You can even end up with code that looks like it’s working but is actually not computing exactly the right thing. When unsure, you should write down the shape of each term in the equation and make sure the corresponding terms in your code match closely. It can also help to evaluate each term independently and print them out. The good news it that you won’t have to do this everyday, since all this is well implemented by Scikit-Learn, but it will help you understand what’s going on under the hood.</p>
<p>So the equations we will need are the cost function:</p>
<p>$J(\mathbf{\Theta}) =</p>
<ul class="simple">
<li><p>\dfrac{1}{m}\sum\limits_{i=1}^{m}\sum\limits_{k=1}^{K}{y_k^{(i)}\log\left(\hat{p}_k^{(i)}\right)}$</p></li>
</ul>
<p>And the equation for the gradients:</p>
<p><span class="math notranslate nohighlight">\(\nabla_{\mathbf{\theta}^{(k)}} \, J(\mathbf{\Theta}) = \dfrac{1}{m} \sum\limits_{i=1}^{m}{ \left ( \hat{p}^{(i)}_k - y_k^{(i)} \right ) \mathbf{x}^{(i)}}\)</span></p>
<p>Note that <span class="math notranslate nohighlight">\(\log\left(\hat{p}_k^{(i)}\right)\)</span> may not be computable if <span class="math notranslate nohighlight">\(\hat{p}_k^{(i)} = 0\)</span>. So we will add a tiny value <span class="math notranslate nohighlight">\(\epsilon\)</span> to <span class="math notranslate nohighlight">\(\log\left(\hat{p}_k^{(i)}\right)\)</span> to avoid getting <code class="docutils literal notranslate"><span class="pre">nan</span></code> values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>eta = 0.01
n_iterations = 5001
m = len(X_train)
epsilon = 1e-7

Theta = np.random.randn(n_inputs, n_outputs)

for iteration in range(n_iterations):
    logits = X_train.dot(Theta)
    Y_proba = softmax(logits)
    if iteration % 500 == 0:
        loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))
        print(iteration, loss)
    error = Y_proba - Y_train_one_hot
    gradients = 1/m * X_train.T.dot(error)
    Theta = Theta - eta * gradients
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0 5.446205811872683
500 0.8350062641405651
1000 0.6878801447192402
1500 0.6012379137693314
2000 0.5444496861981872
2500 0.5038530181431525
3000 0.47292289721922487
3500 0.44824244188957774
4000 0.4278651093928793
4500 0.41060071429187134
5000 0.3956780375390374
</pre></div>
</div>
</div>
</div>
<p>And that’s it! The Softmax model is trained. Let’s look at the model parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>Theta
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 3.32094157, -0.6501102 , -2.99979416],
       [-1.1718465 ,  0.11706172,  0.10507543],
       [-0.70224261, -0.09527802,  1.4786383 ]])
</pre></div>
</div>
</div>
</div>
<p>Let’s make predictions for the validation set and check the accuracy score:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>logits = X_valid.dot(Theta)
Y_proba = softmax(logits)
y_predict = np.argmax(Y_proba, axis=1)

accuracy_score = np.mean(y_predict == y_valid)
accuracy_score
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9666666666666667
</pre></div>
</div>
</div>
</div>
<p>Well, this model looks pretty good. For the sake of the exercise, let’s add a bit of <span class="math notranslate nohighlight">\(\ell_2\)</span> regularization. The following training code is similar to the one above, but the loss now has an additional <span class="math notranslate nohighlight">\(\ell_2\)</span> penalty, and the gradients have the proper additional term (note that we don’t regularize the first element of <code class="docutils literal notranslate"><span class="pre">Theta</span></code> since this corresponds to the bias term). Also, let’s try increasing the learning rate <code class="docutils literal notranslate"><span class="pre">eta</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>eta = 0.1
n_iterations = 5001
m = len(X_train)
epsilon = 1e-7
alpha = 0.1  # regularization hyperparameter

Theta = np.random.randn(n_inputs, n_outputs)

for iteration in range(n_iterations):
    logits = X_train.dot(Theta)
    Y_proba = softmax(logits)
    if iteration % 500 == 0:
        xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))
        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))
        loss = xentropy_loss + alpha * l2_loss
        print(iteration, loss)
    error = Y_proba - Y_train_one_hot
    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]
    Theta = Theta - eta * gradients
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0 6.629842469083912
500 0.5339667976629505
1000 0.5036400750148942
1500 0.49468910594603216
2000 0.4912968418075476
2500 0.48989924700933296
3000 0.4892990598451198
3500 0.4890351244397859
4000 0.4889173621830818
4500 0.4888643337449303
5000 0.4888403120738818
</pre></div>
</div>
</div>
</div>
<p>Because of the additional <span class="math notranslate nohighlight">\(\ell_2\)</span> penalty, the loss seems greater than earlier, but perhaps this model will perform better? Let’s find out:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>logits = X_valid.dot(Theta)
Y_proba = softmax(logits)
y_predict = np.argmax(Y_proba, axis=1)

accuracy_score = np.mean(y_predict == y_valid)
accuracy_score
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Cool, perfect accuracy! We probably just got lucky with this validation set, but still, it’s pleasant.</p>
<p>Now let’s add early stopping. For this we just need to measure the loss on the validation set at every iteration and stop when the error starts growing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>eta = 0.1 
n_iterations = 5001
m = len(X_train)
epsilon = 1e-7
alpha = 0.1  # regularization hyperparameter
best_loss = np.infty

Theta = np.random.randn(n_inputs, n_outputs)

for iteration in range(n_iterations):
    logits = X_train.dot(Theta)
    Y_proba = softmax(logits)
    error = Y_proba - Y_train_one_hot
    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]
    Theta = Theta - eta * gradients

    logits = X_valid.dot(Theta)
    Y_proba = softmax(logits)
    xentropy_loss = -np.mean(np.sum(Y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))
    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))
    loss = xentropy_loss + alpha * l2_loss
    if iteration % 500 == 0:
        print(iteration, loss)
    if loss &lt; best_loss:
        best_loss = loss
    else:
        print(iteration - 1, best_loss)
        print(iteration, loss, &quot;early stopping!&quot;)
        break
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0 4.7096017363419875
500 0.5739711987633519
1000 0.5435638529109128
1500 0.5355752782580262
2000 0.5331959249285545
2500 0.5325946767399382
2765 0.5325460966791898
2766 0.5325460971327978 early stopping!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>logits = X_valid.dot(Theta)
Y_proba = softmax(logits)
y_predict = np.argmax(Y_proba, axis=1)

accuracy_score = np.mean(y_predict == y_valid)
accuracy_score
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Still perfect, but faster.</p>
<p>Now let’s plot the model’s predictions on the whole dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>x0, x1 = np.meshgrid(
        np.linspace(0, 8, 500).reshape(-1, 1),
        np.linspace(0, 3.5, 200).reshape(-1, 1),
    )
X_new = np.c_[x0.ravel(), x1.ravel()]
X_new_with_bias = np.c_[np.ones([len(X_new), 1]), X_new]

logits = X_new_with_bias.dot(Theta)
Y_proba = softmax(logits)
y_predict = np.argmax(Y_proba, axis=1)

zz1 = Y_proba[:, 1].reshape(x0.shape)
zz = y_predict.reshape(x0.shape)

plt.figure(figsize=(10, 4))
plt.plot(X[y==2, 0], X[y==2, 1], &quot;g^&quot;, label=&quot;Iris virginica&quot;)
plt.plot(X[y==1, 0], X[y==1, 1], &quot;bs&quot;, label=&quot;Iris versicolor&quot;)
plt.plot(X[y==0, 0], X[y==0, 1], &quot;yo&quot;, label=&quot;Iris setosa&quot;)

from matplotlib.colors import ListedColormap
custom_cmap = ListedColormap([&#39;#fafab0&#39;,&#39;#9898ff&#39;,&#39;#a0faa0&#39;])

plt.contourf(x0, x1, zz, cmap=custom_cmap)
contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)
plt.clabel(contour, inline=1, fontsize=12)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.legend(loc=&quot;upper left&quot;, fontsize=14)
plt.axis([0, 7, 0, 3.5])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/04_training_linear_models_131_0.png" src="../../_images/04_training_linear_models_131_0.png" />
</div>
</div>
<p>And now let’s measure the final model’s accuracy on the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>logits = X_test.dot(Theta)
Y_proba = softmax(logits)
y_predict = np.argmax(Y_proba, axis=1)

accuracy_score = np.mean(y_predict == y_test)
accuracy_score
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9333333333333333
</pre></div>
</div>
</div>
</div>
<p>Our perfect model turns out to have slight imperfections. This variability is likely due to the very small size of the dataset: depending on how you sample the training set, validation set and the test set, you can get quite different results. Try changing the random seed and running the code again a few times, you will see that the results will vary.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./handson-ml2/original"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="03_classification.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Chapter 3 – Classification</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="05_support_vector_machines.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 5 – Support Vector Machines</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Daniel Kapitan<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>
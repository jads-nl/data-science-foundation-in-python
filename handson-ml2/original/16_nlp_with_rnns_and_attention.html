
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 16 – Natural Language Processing with RNNs and Attention** &#8212; Data Science Foundation Curriculum</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jads-nl.github.io/data-science-foundation-curriculum/handson-ml2/original/16_nlp_with_rnns_and_attention.html" />
    <link rel="shortcut icon" href="../../_static/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chapter 17 – Autoencoders and GANs**" href="17_autoencoders_and_gans.html" />
    <link rel="prev" title="Chapter 15 – Processing Sequences Using RNNs and CNNs" href="15_processing_sequences_using_rnns_and_cnns.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/jads-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Foundation Curriculum</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Why this JupyterBook?
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Statistical Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../islr/introduction.html">
   Introduction to ISLRv2
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/labs.html">
   Labs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_02.3_introduction.html">
     Lab 2.3: Introduction to Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_03.6_linear_regression.html">
     Lab 3.6: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_04.7_classification_methods.html">
     Lab 4.7: Classification Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_05.3_cross_validation_and_the_bootstrap.html">
     Lab 5.3: Cross-Validation and the Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.1_subset_selection_methods.html">
     Lab 6.5.1: Subset Selection Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.2_ridge_regression_and_the_lasso.html">
     Lab 6.5.2: Ridge Regression and the Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.3_pcr_and_pls_regression.html">
     Lab 6.5.3: PCR and PLS Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_07.8_non_linear_modelling.html">
     Lab 7.8: Non-linear Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_08.3_decision_trees.html">
     Lab 8.3: Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_09.6_support_vector_machines.html">
     Lab 9.6: Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.2_multilayer_network_on_mnist_digit_data.html">
     Lab 10.9.2: A Multilayer Network on the MNIST Digit Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.3_convolutional_neural_networks.html">
     Lab 10.9.3: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.5_imdb_document_classification.html">
     Lab 10.9.5: IMDb Document Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.6_recurrent_neural_networks.html">
     Lab 10.9.6: Recurrent Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_12.5_unsupervised_learning.html">
     Lab 12.5: Unsupervised Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/exercises.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter2/index.html">
     Chapter 2
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise1.html">
       Exercise 2.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise2.html">
       Exercise 2.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise3.html">
       Exercise 2.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise4.html">
       Exercise 2.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise5.html">
       Exercise 2.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise6.html">
       Exercise 2.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise7.html">
       Exercise 2.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise8.html">
       Exercise 2.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise9.html">
       Exercise 2.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise10.html">
       Exercise 2.10
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter3/index.html">
     Chapter 3
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise1.html">
       Exercise 3.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise2.html">
       Exercise 3.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise3.html">
       Exercise 3.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise4.html">
       Exercise 3.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise5.html">
       Exercise 3.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise6.html">
       Exercise 3.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise7.html">
       Exercise 3.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise8.html">
       Exercise 3.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise9.html">
       Exercise 3.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise10.html">
       Exercise 3.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise11.html">
       Exercise 3.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise12.html">
       Exercise 3.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise13.html">
       Exercise 3.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise14.html">
       Exercise 3.14
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise15.html">
       Exercise 3.15
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter4/index.html">
     Chapter 4
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise1.html">
       Exercise 4.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise2.html">
       Exercise 4.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise3.html">
       Exercise 4.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise4.html">
       Exercise 4.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise5.html">
       Exercise 4.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise6.html">
       Exercise 4.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise7.html">
       Exercise 4.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise8.html">
       Exercise 4.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise9.html">
       Exercise 4.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise10.html">
       Exercise 10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise11.html">
       Exercise 11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise12.html">
       Exercise 12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise13.html">
       Exercise 4.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise14.html">
       Exercise 4.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise15.html">
       Exercise 4.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise16.html">
       Exercise 4.16
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter5/index.html">
     Chapter 5
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise1.html">
       Exercise 5.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise2.html">
       Exercise 5.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise3.html">
       Problem 5.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise4.html">
       Exercise 5.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise5.html">
       Exercise 5.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise6.html">
       Exercise 5.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise7.html">
       Exercise 5.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise8.html">
       Exercise 5.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise9.html">
       Exercise 5.9
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter6/index.html">
     Chapter 6
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise1.html">
       Exercise 6.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise2.html">
       Exercise 6.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise3.html">
       Exercise 6.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise4.html">
       Exercise 6.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise5.html">
       Exercise 6.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise6.html">
       Exercise 6.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise7.html">
       Exercise 6.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise8.html">
       Exercise 6.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise9.html">
       Exercise 6.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise10.html">
       Exercise 6.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise11.html">
       Exercise 6.11
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter7/index.html">
     Chapter 7
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise1.html">
       Exercise 7.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise2.html">
       Exercise 7.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise3.html">
       Exercise 7.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise4.html">
       Exercise 7.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise5.html">
       Exercise 7.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise6.html">
       Exercise 7.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise7.html">
       Exercise 7.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise8.html">
       Exercise 7.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise9.html">
       Exercise 7.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise10.html">
       Exercise 7.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise11.html">
       Exercise 7.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise12.html">
       Exercise 7.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter8/index.html">
     Chapter 8
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise1.html">
       Exercise 8.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise2.html">
       Exercise 8.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise3.html">
       Exercise 8.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise4.html">
       Exercise 8.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise5.html">
       Exercise 8.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise6.html">
       Exercise 8.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise7.html">
       Exercise 8.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise8.html">
       Exercise 8.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise9.html">
       Exercise 8.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise10.html">
       Exercise 8.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise11.html">
       Exercise 8.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise12.html">
       Exercise 8.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter9/index.html">
     Chapter 9
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise1.html">
       Exercise 9.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise2.html">
       Exercise 9.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise3.html">
       Exercise 9.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise4.html">
       Exercise 9.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise5.html">
       Exercise 9.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise6.html">
       Exercise 9.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise7.html">
       Exercise 9.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise8.html">
       Exercise 9.8
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter12/index.html">
     Chapter 12
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise1.html">
       Exercise 12.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise2.html">
       Exercise 12.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise3.html">
       Exercise 12.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise4.html">
       Exercise 12.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise5.html">
       Exercise 12.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise6.html">
       Exercise 12.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise7.html">
       Exercise 12.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise8.html">
       Exercise 10.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise9.html">
       Exercise 12.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise10.html">
       Exercise 12.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise11.html">
       Exercise 12.11
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hands-on Machine Learning in Python
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../introduction.html">
   Hands-on Machine Learning with Aurélien Géron
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_the_machine_learning_landscape.html">
     Chapter 1 – The Machine Learning landscape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_end_to_end_machine_learning_project.html">
     Chapter 2 – End-to-end Machine Learning project
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_classification.html">
     Chapter 3 – Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_training_linear_models.html">
     Chapter 4 – Training Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_support_vector_machines.html">
     Chapter 5 – Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_decision_trees.html">
     Chapter 6 – Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07_ensemble_learning_and_random_forests.html">
     Chapter 7 – Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08_dimensionality_reduction.html">
     Chapter 8 – Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09_unsupervised_learning.html">
     Chapter 9 – Unsupervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10_neural_nets_with_keras.html">
     Chapter 10 – Introduction to Artificial Neural Networks with Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11_training_deep_neural_networks.html">
     Chapter 11 – Training Deep Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12_custom_models_and_training_with_tensorflow.html">
     Chapter 12 – Custom Models and Training with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13_loading_and_preprocessing_data.html">
     Chapter 13 – Loading and Preprocessing Data with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14_deep_computer_vision_with_cnns.html">
     Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15_processing_sequences_using_rnns_and_cnns.html">
     Chapter 15 – Processing Sequences Using RNNs and CNNs
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Chapter 16 – Natural Language Processing with RNNs and Attention**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="17_autoencoders_and_gans.html">
     Chapter 17 – Autoencoders and GANs**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18_reinforcement_learning.html">
     Chapter 18 – Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19_training_and_deploying_at_scale.html">
     Chapter 19 – Training and Deploying TensorFlow Models at Scale
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../extra.html">
   Miscellaneous tips &amp; tricks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="math_linear_algebra.html">
     Math primer - Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="math_differential_calculus.html">
     Math primer - Differential Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_autodiff.html">
     Implementation of autodiff techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_gradient_descent_comparison.html">
     Comparison of Batch, Mini-Batch and Stochastic Gradient Descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data visualization with Altair
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction-to-interactive-data-visualization.html">
   Introduction to data visualization with Python
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../visualization/altair_get_started.html">
   Getting Started with Altair
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_introduction.html">
     Introduction to Altair
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_marks_encoding.html">
     Data Types, Graphical Marks, and Visual Encoding Channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_data_transformation.html">
     Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_scales_axes_legends.html">
     Scales, Axes, and Legends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_view_composition.html">
     Multi-View Composition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_interaction.html">
     Interaction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_cartographic.html">
     Cartographic Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_debugging.html">
     Altair Debugging Guide
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Interpretable Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../iml/introduction.html">
   Introduction to IML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_partial_dependence.html">
     Partial Dependence and Individual Conditional Expectation Plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance.html">
     Permutation Importance vs Random Forest Feature Importance (MDI)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance_multicollinear.html">
     Permutation Importance with Multicollinear or Correlated Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/interpreting-machine-learning-models.html">
     IML with Pima Indians and the Titanic datasets
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Principles of time-series forecasting
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/introduction.html">
   Introduction to FPP3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/examples-time-series-forecasting-with-python.html">
   Examples of time-series forecasting with Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural language processing with spaCy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/introduction.html">
   Introduction to NLP with spaCy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../nlp/dutch-restaurant-reviews.html">
   Dutch restaurant reviews
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-dutch-restaurant-reviews.html">
     Analyzing Dutch restaurant reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/prepare-restoreviews-dataset.html">
     Fetch and prepare reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-pipeline-example.html">
     Predict detractors from reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/language-detection-with-character-quadgrams.html">
     Extra: language detection with character quadgrams
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-model-sizes.html">
     Extra: plot of transformer model sizes
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jads-nl/data-science-foundation-curriculum/main?urlpath=tree/data_science_foundation_curriculum/handson-ml2/original/16_nlp_with_rnns_and_attention.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jads-nl/data-science-foundation-curriculum/blob/main/data_science_foundation_curriculum/handson-ml2/original/16_nlp_with_rnns_and_attention.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-curriculum"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-curriculum/issues/new?title=Issue%20on%20page%20%2Fhandson-ml2/original/16_nlp_with_rnns_and_attention.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/handson-ml2/original/16_nlp_with_rnns_and_attention.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 16 – Natural Language Processing with RNNs and Attention**
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#char-rnn">
   Char-RNN
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#splitting-a-sequence-into-batches-of-shuffled-windows">
     Splitting a sequence into batches of shuffled windows
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loading-the-data-and-preparing-the-dataset">
     Loading the Data and Preparing the Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-and-training-the-model">
     Creating and Training the Model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-model-to-generate-text">
     Using the Model to Generate Text
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stateful-rnn">
     Stateful RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sentiment-analysis">
   Sentiment Analysis
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reusing-pretrained-embeddings">
     Reusing Pretrained Embeddings
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automatic-translation">
     Automatic Translation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bidirectional-recurrent-layers">
       Bidirectional Recurrent Layers
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#positional-encoding">
       Positional Encoding
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-7">
     1. to 7.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     8.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     9.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-version-a-very-basic-seq2seq-model">
       First version: a very basic seq2seq model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#second-version-feeding-the-shifted-targets-to-the-decoder-teacher-forcing">
       Second version: feeding the shifted targets to the decoder (teacher forcing)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#third-version-using-tf-addons-s-seq2seq-implementation">
       Third version: using TF-Addons’s seq2seq implementation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fourth-version-using-tf-addons-s-seq2seq-implementation-with-a-scheduled-sampler">
       Fourth version: using TF-Addons’s seq2seq implementation with a scheduled sampler
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fifth-version-using-tfa-seq2seq-the-keras-subclassing-api-and-attention-mechanisms">
       Fifth version: using TFA seq2seq, the Keras subclassing API and attention mechanisms
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     10.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     11.
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 16 – Natural Language Processing with RNNs and Attention**</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 16 – Natural Language Processing with RNNs and Attention**
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#char-rnn">
   Char-RNN
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#splitting-a-sequence-into-batches-of-shuffled-windows">
     Splitting a sequence into batches of shuffled windows
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#loading-the-data-and-preparing-the-dataset">
     Loading the Data and Preparing the Dataset
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-and-training-the-model">
     Creating and Training the Model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-the-model-to-generate-text">
     Using the Model to Generate Text
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stateful-rnn">
     Stateful RNN
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sentiment-analysis">
   Sentiment Analysis
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#reusing-pretrained-embeddings">
     Reusing Pretrained Embeddings
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#automatic-translation">
     Automatic Translation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bidirectional-recurrent-layers">
       Bidirectional Recurrent Layers
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#positional-encoding">
       Positional Encoding
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-7">
     1. to 7.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     8.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     9.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#first-version-a-very-basic-seq2seq-model">
       First version: a very basic seq2seq model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#second-version-feeding-the-shifted-targets-to-the-decoder-teacher-forcing">
       Second version: feeding the shifted targets to the decoder (teacher forcing)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#third-version-using-tf-addons-s-seq2seq-implementation">
       Third version: using TF-Addons’s seq2seq implementation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fourth-version-using-tf-addons-s-seq2seq-implementation-with-a-scheduled-sampler">
       Fourth version: using TF-Addons’s seq2seq implementation with a scheduled sampler
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#fifth-version-using-tfa-seq2seq-the-keras-subclassing-api-and-attention-mechanisms">
       Fifth version: using TFA seq2seq, the Keras subclassing API and attention mechanisms
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     10.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     11.
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-16-natural-language-processing-with-rnns-and-attention">
<h1>Chapter 16 – Natural Language Processing with RNNs and Attention**<a class="headerlink" href="#chapter-16-natural-language-processing-with-rnns-and-attention" title="Permalink to this headline">#</a></h1>
<p><em>This notebook contains all the sample code in chapter 16.</em></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">#</a></h1>
<p>First, let’s import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Python ≥3.5 is required</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="k">assert</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Is this notebook running on Colab or Kaggle?</span>
<span class="n">IS_COLAB</span> <span class="o">=</span> <span class="s2">&quot;google.colab&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>
<span class="n">IS_KAGGLE</span> <span class="o">=</span> <span class="s2">&quot;kaggle_secrets&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>

<span class="k">if</span> <span class="n">IS_COLAB</span><span class="p">:</span>
    <span class="o">%</span><span class="k">pip</span> install -q -U tensorflow-addons
    <span class="o">%</span><span class="k">pip</span> install -q -U transformers

<span class="c1"># Scikit-Learn ≥0.20 is required</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="k">assert</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;0.20&quot;</span>

<span class="c1"># TensorFlow ≥2.0 is required</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="k">assert</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;2.0&quot;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No GPU was detected. LSTMs and CNNs can be very slow without a GPU.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">IS_COLAB</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Go to Runtime &gt; Change runtime and select a GPU hardware accelerator.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">IS_KAGGLE</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Go to Settings &gt; Accelerator and select GPU.&quot;</span><span class="p">)</span>

<span class="c1"># Common imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># to make this notebook&#39;s output stable across runs</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># To plot pretty figures</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;xtick&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;ytick&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># Where to save the figures</span>
<span class="n">PROJECT_ROOT_DIR</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span>
<span class="n">CHAPTER_ID</span> <span class="o">=</span> <span class="s2">&quot;nlp&quot;</span>
<span class="n">IMAGES_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">PROJECT_ROOT_DIR</span><span class="p">,</span> <span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="n">CHAPTER_ID</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">IMAGES_PATH</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">save_fig</span><span class="p">(</span><span class="n">fig_id</span><span class="p">,</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fig_extension</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IMAGES_PATH</span><span class="p">,</span> <span class="n">fig_id</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span> <span class="o">+</span> <span class="n">fig_extension</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving figure&quot;</span><span class="p">,</span> <span class="n">fig_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tight_layout</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">fig_extension</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="n">resolution</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No GPU was detected. LSTMs and CNNs can be very slow without a GPU.
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="char-rnn">
<h1>Char-RNN<a class="headerlink" href="#char-rnn" title="Permalink to this headline">#</a></h1>
<section id="splitting-a-sequence-into-batches-of-shuffled-windows">
<h2>Splitting a sequence into batches of shuffled windows<a class="headerlink" href="#splitting-a-sequence-into-batches-of-shuffled-windows" title="Permalink to this headline">#</a></h2>
<p>For example, let’s split the sequence 0 to 14 into windows of length 5, each shifted by 2 (e.g.,<code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4]</span></code>, <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5,</span> <span class="pre">6]</span></code>, etc.), then shuffle them, and split them into inputs (the first 4 steps) and targets (the last 4 steps) (e.g., <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5,</span> <span class="pre">6]</span></code> would be split into <code class="docutils literal notranslate"><span class="pre">[[2,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">5],</span> <span class="pre">[3,</span> <span class="pre">4,</span> <span class="pre">5,</span> <span class="pre">6]]</span></code>), then create batches of 3 such input/target pairs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">15</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">flat_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">window</span><span class="p">:</span> <span class="n">window</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">n_steps</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">window</span><span class="p">:</span> <span class="p">(</span><span class="n">window</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">window</span><span class="p">[</span><span class="mi">1</span><span class="p">:]))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">Y_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;_&quot;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">,</span> <span class="s2">&quot;Batch&quot;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">X_batch&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">X_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Y_batch&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">Y_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>____________________ Batch 0 
X_batch
[[6 7 8 9]
 [2 3 4 5]
 [4 5 6 7]]
===== 
Y_batch
[[ 7  8  9 10]
 [ 3  4  5  6]
 [ 5  6  7  8]]
____________________ Batch 1 
X_batch
[[ 0  1  2  3]
 [ 8  9 10 11]
 [10 11 12 13]]
===== 
Y_batch
[[ 1  2  3  4]
 [ 9 10 11 12]
 [11 12 13 14]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="loading-the-data-and-preparing-the-dataset">
<h2>Loading the Data and Preparing the Dataset<a class="headerlink" href="#loading-the-data-and-preparing-the-dataset" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shakespeare_url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt&quot;</span>
<span class="n">filepath</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="s2">&quot;shakespeare.txt&quot;</span><span class="p">,</span> <span class="n">shakespeare_url</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">shakespeare_text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt
1122304/1115394 [==============================] - 0s 0us/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">shakespeare_text</span><span class="p">[:</span><span class="mi">148</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You are all resolved rather to die than to famish?
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">shakespeare_text</span><span class="o">.</span><span class="n">lower</span><span class="p">())))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;\n !$&amp;&#39;,-.3:;?abcdefghijklmnopqrstuvwxyz&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">Tokenizer</span><span class="p">(</span><span class="n">char_level</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">shakespeare_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="s2">&quot;First&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[20, 6, 9, 8, 3]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sequences_to_texts</span><span class="p">([[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;f i r s t&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_id</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="c1"># number of distinct characters</span>
<span class="n">dataset_size</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">document_count</span> <span class="c1"># total number of characters</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">encoded</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">shakespeare_text</span><span class="p">]))</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">dataset_size</span> <span class="o">*</span> <span class="mi">90</span> <span class="o">//</span> <span class="mi">100</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">encoded</span><span class="p">[:</span><span class="n">train_size</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Note</strong>: in previous versions of this code, we used <code class="docutils literal notranslate"><span class="pre">dataset.repeat()</span></code> now to make the dataset “infinite”, and later in the notebook we set the <code class="docutils literal notranslate"><span class="pre">steps_per_epoch</span></code> argument when calling the <code class="docutils literal notranslate"><span class="pre">model.fit()</span></code> method. This was needed to work around some TensorFlow bugs. However, since these bugs have now been fixed, we can simplify the code: no need for <code class="docutils literal notranslate"><span class="pre">dataset.repeat()</span></code> or <code class="docutils literal notranslate"><span class="pre">steps_per_epoch</span></code> anymore.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_steps</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">window_length</span> <span class="o">=</span> <span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># target = input shifted 1 character ahead</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">flat_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">window</span><span class="p">:</span> <span class="n">window</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">window_length</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">windows</span><span class="p">:</span> <span class="p">(</span><span class="n">windows</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">windows</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">Y_batch</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">max_id</span><span class="p">),</span> <span class="n">Y_batch</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">Y_batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">X_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(32, 100, 39) (32, 100)
</pre></div>
</div>
</div>
</div>
</section>
<section id="creating-and-training-the-model">
<h2>Creating and Training the Model<a class="headerlink" href="#creating-and-training-the-model" title="Permalink to this headline">#</a></h2>
<p><strong>Warning</strong>: the following code may take up to 24 hours to run, depending on your hardware. If you use a GPU, it may take just 1 or 2 hours, or less.</p>
<p><strong>Note</strong>: the <code class="docutils literal notranslate"><span class="pre">GRU</span></code> class will only use the GPU (if you have one) when using the default values for the following arguments: <code class="docutils literal notranslate"><span class="pre">activation</span></code>, <code class="docutils literal notranslate"><span class="pre">recurrent_activation</span></code>, <code class="docutils literal notranslate"><span class="pre">recurrent_dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">unroll</span></code>, <code class="docutils literal notranslate"><span class="pre">use_bias</span></code> and <code class="docutils literal notranslate"><span class="pre">reset_after</span></code>. This is why I commented out <code class="docutils literal notranslate"><span class="pre">recurrent_dropout=0.2</span></code> (compared to the book).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_id</span><span class="p">],</span>
                     <span class="c1">#dropout=0.2, recurrent_dropout=0.2),</span>
                     <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="c1">#dropout=0.2, recurrent_dropout=0.2),</span>
                     <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">max_id</span><span class="p">,</span>
                                                    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
31368/31368 [==============================] - 7150s 228ms/step - loss: 1.4671
Epoch 2/10
31368/31368 [==============================] - 7094s 226ms/step - loss: 1.3614
Epoch 3/10
31368/31368 [==============================] - 7063s 225ms/step - loss: 1.3404
Epoch 4/10
31368/31368 [==============================] - 7039s 224ms/step - loss: 1.3311
Epoch 5/10
31368/31368 [==============================] - 7056s 225ms/step - loss: 1.3256
Epoch 6/10
31368/31368 [==============================] - 7049s 225ms/step - loss: 1.3209
Epoch 7/10
31368/31368 [==============================] - 7068s 225ms/step - loss: 1.3166
Epoch 8/10
31368/31368 [==============================] - 7030s 224ms/step - loss: 1.3138
Epoch 9/10
31368/31368 [==============================] - 7061s 225ms/step - loss: 1.3120
Epoch 10/10
31368/31368 [==============================] - 7177s 229ms/step - loss: 1.3105
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-the-model-to-generate-text">
<h2>Using the Model to Generate Text<a class="headerlink" href="#using-the-model-to-generate-text" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">texts</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">max_id</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Warning</strong>: the <code class="docutils literal notranslate"><span class="pre">predict_classes()</span></code> method is deprecated. Instead, we must use <code class="docutils literal notranslate"><span class="pre">np.argmax(model(X_new),</span> <span class="pre">axis=-1)</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_new</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">([</span><span class="s2">&quot;How are yo&quot;</span><span class="p">])</span>
<span class="c1">#Y_pred = model.predict_classes(X_new)</span>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X_new</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">sequences_to_texts</span><span class="p">(</span><span class="n">Y_pred</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 1st sentence, last char</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;u&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">categorical</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.4</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)]],</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 2, 1, 0, 2, 1,
        0, 1, 2, 1, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">next_char</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">X_new</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
    <span class="n">y_proba</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_new</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>
    <span class="n">rescaled_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_proba</span><span class="p">)</span> <span class="o">/</span> <span class="n">temperature</span>
    <span class="n">char_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">categorical</span><span class="p">(</span><span class="n">rescaled_logits</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">sequences_to_texts</span><span class="p">(</span><span class="n">char_id</span><span class="o">.</span><span class="n">numpy</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">next_char</span><span class="p">(</span><span class="s2">&quot;How are yo&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;u&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">complete_text</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">n_chars</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_chars</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">+=</span> <span class="n">next_char</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">temperature</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">complete_text</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>the belly the charges of the other words
and belly 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">complete_text</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>thing! they know&#39;t.

biondello:
for you are the own
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">complete_text</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>th no cyty
use ffor was firive this toighingaber; b
</pre></div>
</div>
</div>
</div>
</section>
<section id="stateful-rnn">
<h2>Stateful RNN<a class="headerlink" href="#stateful-rnn" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">encoded</span><span class="p">[:</span><span class="n">train_size</span><span class="p">])</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">flat_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">window</span><span class="p">:</span> <span class="n">window</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">window_length</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">windows</span><span class="p">:</span> <span class="p">(</span><span class="n">windows</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">windows</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">Y_batch</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">max_id</span><span class="p">),</span> <span class="n">Y_batch</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">encoded_parts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">encoded</span><span class="p">[:</span><span class="n">train_size</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">)</span>
<span class="n">datasets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">encoded_part</span> <span class="ow">in</span> <span class="n">encoded_parts</span><span class="p">:</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">encoded_part</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="n">window_length</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">flat_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">window</span><span class="p">:</span> <span class="n">window</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">window_length</span><span class="p">))</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">zip</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">datasets</span><span class="p">))</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="o">*</span><span class="n">windows</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">windows</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">windows</span><span class="p">:</span> <span class="p">(</span><span class="n">windows</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">windows</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">Y_batch</span><span class="p">:</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="n">max_id</span><span class="p">),</span> <span class="n">Y_batch</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Note</strong>: once again, I commented out <code class="docutils literal notranslate"><span class="pre">recurrent_dropout=0.2</span></code> (compared to the book) so you can get GPU acceleration (if you have one).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stateful</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="c1">#dropout=0.2, recurrent_dropout=0.2,</span>
                     <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                     <span class="n">batch_input_shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_id</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stateful</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="c1">#dropout=0.2, recurrent_dropout=0.2),</span>
                     <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">max_id</span><span class="p">,</span>
                                                    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ResetStatesCallback</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">ResetStatesCallback</span><span class="p">()])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/50
313/313 [==============================] - 62s 198ms/step - loss: 2.6189
Epoch 2/50
313/313 [==============================] - 58s 187ms/step - loss: 2.2091
Epoch 3/50
313/313 [==============================] - 56s 178ms/step - loss: 2.0775
Epoch 4/50
313/313 [==============================] - 56s 179ms/step - loss: 2.4689
Epoch 5/50
313/313 [==============================] - 56s 179ms/step - loss: 2.3274
Epoch 6/50
313/313 [==============================] - 57s 183ms/step - loss: 2.1412
Epoch 7/50
313/313 [==============================] - 57s 183ms/step - loss: 2.0748
Epoch 8/50
313/313 [==============================] - 56s 179ms/step - loss: 1.9850
Epoch 9/50
313/313 [==============================] - 56s 179ms/step - loss: 1.9465
Epoch 10/50
313/313 [==============================] - 56s 179ms/step - loss: 1.8995
Epoch 11/50
313/313 [==============================] - 57s 182ms/step - loss: 1.8576
Epoch 12/50
313/313 [==============================] - 56s 179ms/step - loss: 1.8510
Epoch 13/50
313/313 [==============================] - 57s 184ms/step - loss: 1.8038
Epoch 14/50
313/313 [==============================] - 56s 178ms/step - loss: 1.7867
Epoch 15/50
313/313 [==============================] - 56s 180ms/step - loss: 1.7635
Epoch 16/50
313/313 [==============================] - 56s 179ms/step - loss: 1.7270
Epoch 17/50
313/313 [==============================] - 58s 184ms/step - loss: 1.7097
&lt;&lt;31 more lines&gt;&gt;
313/313 [==============================] - 58s 185ms/step - loss: 1.5998
Epoch 34/50
313/313 [==============================] - 58s 184ms/step - loss: 1.5954
Epoch 35/50
313/313 [==============================] - 58s 185ms/step - loss: 1.5944
Epoch 36/50
313/313 [==============================] - 57s 183ms/step - loss: 1.5902
Epoch 37/50
313/313 [==============================] - 57s 183ms/step - loss: 1.5893
Epoch 38/50
313/313 [==============================] - 59s 187ms/step - loss: 1.5845
Epoch 39/50
313/313 [==============================] - 57s 183ms/step - loss: 1.5821
Epoch 40/50
313/313 [==============================] - 59s 187ms/step - loss: 1.5798
Epoch 41/50
313/313 [==============================] - 57s 181ms/step - loss: 1.5794
Epoch 42/50
313/313 [==============================] - 57s 182ms/step - loss: 1.5774
Epoch 43/50
313/313 [==============================] - 57s 182ms/step - loss: 1.5755
Epoch 44/50
313/313 [==============================] - 58s 186ms/step - loss: 1.5735
Epoch 45/50
313/313 [==============================] - 58s 186ms/step - loss: 1.5714
Epoch 46/50
313/313 [==============================] - 57s 181ms/step - loss: 1.5686
Epoch 47/50
313/313 [==============================] - 57s 181ms/step - loss: 1.5675
Epoch 48/50
313/313 [==============================] - 56s 180ms/step - loss: 1.5657
Epoch 49/50
313/313 [==============================] - 58s 185ms/step - loss: 1.5654
Epoch 50/50
313/313 [==============================] - 57s 182ms/step - loss: 1.5620
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7f8d45d95d10&gt;
</pre></div>
</div>
</div>
</div>
<p>To use the model with different batch sizes, we need to create a stateless copy. We can get rid of dropout since it is only used during training:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stateless_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_id</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">max_id</span><span class="p">,</span>
                                                    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>To set the weights, we first need to build the model (so the weights get created):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stateless_model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorShape</span><span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">max_id</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stateless_model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">stateless_model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">complete_text</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tor:
in the negver up how it thou like him;
when it
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="sentiment-analysis">
<h1>Sentiment Analysis<a class="headerlink" href="#sentiment-analysis" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can load the IMDB dataset easily:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz
17465344/17464789 [==============================] - 0s 0us/step
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word_index</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span><span class="o">.</span><span class="n">get_word_index</span><span class="p">()</span>
<span class="n">id_to_word</span> <span class="o">=</span> <span class="p">{</span><span class="n">id_</span> <span class="o">+</span> <span class="mi">3</span><span class="p">:</span> <span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">id_</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="k">for</span> <span class="n">id_</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">((</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;sos&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">)):</span>
    <span class="n">id_to_word</span><span class="p">[</span><span class="n">id_</span><span class="p">]</span> <span class="o">=</span> <span class="n">token</span>
<span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">id_to_word</span><span class="p">[</span><span class="n">id_</span><span class="p">]</span> <span class="k">for</span> <span class="n">id_</span> <span class="ow">in</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">10</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json
1646592/1641221 [==============================] - 0s 0us/step
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;&lt;sos&gt; this film was just brilliant casting location scenery story&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>

<span class="n">datasets</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;imdb_reviews&quot;</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">Downloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/aurelien_geron_kiwisoft_io/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...</span>
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "9d19e9f5f622440b9feb5ed1a98db7b3", "version_major": 2, "version_minor": 0}
</script><script type="application/vnd.jupyter.widget-view+json">
{"model_id": "001634a67f0e42f69450a95ed84492b2", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shuffling and writing examples to /home/aurelien_geron_kiwisoft_io/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteK5RNB1/imdb_reviews-train.tfrecord
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "c661939803ee4442be234cc9e1485599", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shuffling and writing examples to /home/aurelien_geron_kiwisoft_io/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteK5RNB1/imdb_reviews-test.tfrecord
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "bdd0d660b82e4f93b4824e6e3573f197", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shuffling and writing examples to /home/aurelien_geron_kiwisoft_io/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteK5RNB1/imdb_reviews-unsupervised.tfrecord
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "91133fb7161d440383d4d50bd06f16ba", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">Dataset imdb_reviews downloaded and prepared to /home/aurelien_geron_kiwisoft_io/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;test&#39;, &#39;train&#39;, &#39;unsupervised&#39;])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_size</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">num_examples</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">num_examples</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(25000, 25000)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">review</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">numpy</span><span class="p">()):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Review:&quot;</span><span class="p">,</span> <span class="n">review</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)[:</span><span class="mi">200</span><span class="p">],</span> <span class="s2">&quot;...&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label:&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="s2">&quot;= Positive&quot;</span> <span class="k">if</span> <span class="n">label</span> <span class="k">else</span> <span class="s2">&quot;= Negative&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Review: This was an absolutely terrible movie. Don&#39;t be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...
Label: 0 = Negative

Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...
Label: 0 = Negative
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">):</span>
    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">substr</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">regex_replace</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="sa">rb</span><span class="s2">&quot;&lt;br\s*/?&gt;&quot;</span><span class="p">,</span> <span class="sa">b</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">regex_replace</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="sa">b</span><span class="s2">&quot;[^a-zA-Z&#39;]&quot;</span><span class="p">,</span> <span class="sa">b</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">(</span><span class="n">default_value</span><span class="o">=</span><span class="sa">b</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">),</span> <span class="n">y_batch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preprocess</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;tf.Tensor: shape=(2, 53), dtype=string, numpy=
 array([[b&#39;This&#39;, b&#39;was&#39;, b&#39;an&#39;, b&#39;absolutely&#39;, b&#39;terrible&#39;, b&#39;movie&#39;,
         b&quot;Don&#39;t&quot;, b&#39;be&#39;, b&#39;lured&#39;, b&#39;in&#39;, b&#39;by&#39;, b&#39;Christopher&#39;,
         b&#39;Walken&#39;, b&#39;or&#39;, b&#39;Michael&#39;, b&#39;Ironside&#39;, b&#39;Both&#39;, b&#39;are&#39;,
         b&#39;great&#39;, b&#39;actors&#39;, b&#39;but&#39;, b&#39;this&#39;, b&#39;must&#39;, b&#39;simply&#39;, b&#39;be&#39;,
         b&#39;their&#39;, b&#39;worst&#39;, b&#39;role&#39;, b&#39;in&#39;, b&#39;history&#39;, b&#39;Even&#39;,
         b&#39;their&#39;, b&#39;great&#39;, b&#39;acting&#39;, b&#39;could&#39;, b&#39;not&#39;, b&#39;redeem&#39;,
         b&#39;this&#39;, b&quot;movie&#39;s&quot;, b&#39;ridiculous&#39;, b&#39;storyline&#39;, b&#39;This&#39;,
         b&#39;movie&#39;, b&#39;is&#39;, b&#39;an&#39;, b&#39;early&#39;, b&#39;nineties&#39;, b&#39;US&#39;,
         b&#39;propaganda&#39;, b&#39;pi&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;],
        [b&#39;I&#39;, b&#39;have&#39;, b&#39;been&#39;, b&#39;known&#39;, b&#39;to&#39;, b&#39;fall&#39;, b&#39;asleep&#39;,
         b&#39;during&#39;, b&#39;films&#39;, b&#39;but&#39;, b&#39;this&#39;, b&#39;is&#39;, b&#39;usually&#39;, b&#39;due&#39;,
         b&#39;to&#39;, b&#39;a&#39;, b&#39;combination&#39;, b&#39;of&#39;, b&#39;things&#39;, b&#39;including&#39;,
         b&#39;really&#39;, b&#39;tired&#39;, b&#39;being&#39;, b&#39;warm&#39;, b&#39;and&#39;, b&#39;comfortable&#39;,
         b&#39;on&#39;, b&#39;the&#39;, b&#39;sette&#39;, b&#39;and&#39;, b&#39;having&#39;, b&#39;just&#39;, b&#39;eaten&#39;,
         b&#39;a&#39;, b&#39;lot&#39;, b&#39;However&#39;, b&#39;on&#39;, b&#39;this&#39;, b&#39;occasion&#39;, b&#39;I&#39;,
         b&#39;fell&#39;, b&#39;asleep&#39;, b&#39;because&#39;, b&#39;the&#39;, b&#39;film&#39;, b&#39;was&#39;,
         b&#39;rubbish&#39;, b&#39;The&#39;, b&#39;plot&#39;, b&#39;development&#39;, b&#39;was&#39;, b&#39;constant&#39;,
         b&#39;Cons&#39;]], dtype=object)&gt;,
 &lt;tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0])&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preprocess</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">X_batch</span><span class="p">:</span>
        <span class="n">vocabulary</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">review</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocabulary</span><span class="o">.</span><span class="n">most_common</span><span class="p">()[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(b&#39;&lt;pad&gt;&#39;, 214309), (b&#39;the&#39;, 61137), (b&#39;a&#39;, 38564)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>53893
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">truncated_vocabulary</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">word</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">vocabulary</span><span class="o">.</span><span class="n">most_common</span><span class="p">()[:</span><span class="n">vocab_size</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">truncated_vocabulary</span><span class="p">)}</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="sa">b</span><span class="s2">&quot;This movie was faaaaaantastic&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">word_to_id</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="ow">or</span> <span class="n">vocab_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>22
12
11
10000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">words</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">truncated_vocabulary</span><span class="p">)</span>
<span class="n">word_ids</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">truncated_vocabulary</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
<span class="n">vocab_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lookup</span><span class="o">.</span><span class="n">KeyValueTensorInitializer</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">word_ids</span><span class="p">)</span>
<span class="n">num_oov_buckets</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lookup</span><span class="o">.</span><span class="n">StaticVocabularyTable</span><span class="p">(</span><span class="n">vocab_init</span><span class="p">,</span> <span class="n">num_oov_buckets</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">table</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="sa">b</span><span class="s2">&quot;This movie was faaaaaantastic&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">()]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10053]])&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">encode_words</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">table</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">X_batch</span><span class="p">),</span> <span class="n">y_batch</span>

<span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preprocess</span><span class="p">)</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">encode_words</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">train_set</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y_batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(
[[  22   11   28 ...    0    0    0]
 [   6   21   70 ...    0    0    0]
 [4099 6881    1 ...    0    0    0]
 ...
 [  22   12  118 ...  331 1047    0]
 [1757 4101  451 ...    0    0    0]
 [3365 4392    6 ...    0    0    0]], shape=(32, 60), dtype=int64)
tf.Tensor([0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0], shape=(32,), dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embed_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">num_oov_buckets</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span>
                           <span class="n">mask_zero</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># not shown in the book</span>
                           <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
782/782 [==============================] - 118s 152ms/step - loss: 0.5305 - accuracy: 0.7282
Epoch 2/5
782/782 [==============================] - 113s 145ms/step - loss: 0.3459 - accuracy: 0.8554
Epoch 3/5
782/782 [==============================] - 113s 145ms/step - loss: 0.1913 - accuracy: 0.9319
Epoch 4/5
782/782 [==============================] - 114s 146ms/step - loss: 0.1341 - accuracy: 0.9535
Epoch 5/5
782/782 [==============================] - 116s 148ms/step - loss: 0.1011 - accuracy: 0.9624
</pre></div>
</div>
</div>
</div>
<p>Or using manual masking:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">])</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="n">num_oov_buckets</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">z</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">z</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)(</span><span class="n">z</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">inputs</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">outputs</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
782/782 [==============================] - 118s 152ms/step - loss: 0.5425 - accuracy: 0.7155
Epoch 2/5
782/782 [==============================] - 112s 143ms/step - loss: 0.3479 - accuracy: 0.8558
Epoch 3/5
782/782 [==============================] - 112s 144ms/step - loss: 0.1761 - accuracy: 0.9388
Epoch 4/5
782/782 [==============================] - 115s 147ms/step - loss: 0.1281 - accuracy: 0.9531
Epoch 5/5
782/782 [==============================] - 116s 148ms/step - loss: 0.1088 - accuracy: 0.9603
</pre></div>
</div>
</div>
</div>
<section id="reusing-pretrained-embeddings">
<h2>Reusing Pretrained Embeddings<a class="headerlink" href="#reusing-pretrained-embeddings" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TFHUB_CACHE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">curdir</span><span class="p">,</span> <span class="s2">&quot;my_tfhub_cache&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TFHUB_CACHE_DIR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TFHUB_CACHE_DIR</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">hub</span><span class="o">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="s2">&quot;https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1&quot;</span><span class="p">,</span>
                   <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">output_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">50</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">dirpath</span><span class="p">,</span> <span class="n">dirnames</span><span class="p">,</span> <span class="n">filenames</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">TFHUB_CACHE_DIR</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dirpath</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>./my_tfhub_cache/82c4aaf4250ffb09088bd48368ee7fd00e5464fe.descriptor.txt
./my_tfhub_cache/82c4aaf4250ffb09088bd48368ee7fd00e5464fe/saved_model.pb
./my_tfhub_cache/82c4aaf4250ffb09088bd48368ee7fd00e5464fe/variables/variables.data-00000-of-00001
./my_tfhub_cache/82c4aaf4250ffb09088bd48368ee7fd00e5464fe/variables/variables.index
./my_tfhub_cache/82c4aaf4250ffb09088bd48368ee7fd00e5464fe/assets/tokens.txt
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>

<span class="n">datasets</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;imdb_reviews&quot;</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">splits</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">num_examples</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
782/782 [==============================] - 128s 164ms/step - loss: 0.5460 - accuracy: 0.7267
Epoch 2/5
782/782 [==============================] - 128s 164ms/step - loss: 0.5129 - accuracy: 0.7495
Epoch 3/5
782/782 [==============================] - 129s 165ms/step - loss: 0.5082 - accuracy: 0.7530
Epoch 4/5
782/782 [==============================] - 128s 164ms/step - loss: 0.5047 - accuracy: 0.7533
Epoch 5/5
782/782 [==============================] - 128s 164ms/step - loss: 0.5015 - accuracy: 0.7560
</pre></div>
</div>
</div>
</div>
</section>
<section id="automatic-translation">
<h2>Automatic Translation<a class="headerlink" href="#automatic-translation" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">embed_size</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>

<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">sequence_lengths</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
<span class="n">encoder_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)</span>
<span class="n">decoder_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">encoder_embeddings</span><span class="p">)</span>
<span class="n">encoder_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">]</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">TrainingSampler</span><span class="p">()</span>

<span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">basic_decoder</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">decoder_cell</span><span class="p">,</span> <span class="n">sampler</span><span class="p">,</span>
                                                 <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
<span class="n">final_outputs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">final_sequence_lengths</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
    <span class="n">decoder_embeddings</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span>
    <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_lengths</span><span class="p">)</span>
<span class="n">Y_proba</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">final_outputs</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">sequence_lengths</span><span class="p">],</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">Y_proba</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="o">*</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">X_decoder</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">Y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">seq_lengths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">([</span><span class="mi">1000</span><span class="p">],</span> <span class="mi">15</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">X_decoder</span><span class="p">,</span> <span class="n">seq_lengths</span><span class="p">],</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/2
32/32 [==============================] - 6s 6ms/sample - loss: 4.6053
Epoch 2/2
32/32 [==============================] - 3s 3ms/sample - loss: 4.6031
</pre></div>
</div>
</div>
</div>
<section id="bidirectional-recurrent-layers">
<h3>Bidirectional Recurrent Layers<a class="headerlink" href="#bidirectional-recurrent-layers" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_10 (GRU)                 (None, None, 10)          660       
_________________________________________________________________
bidirectional (Bidirectional (None, None, 20)          1320      
=================================================================
Total params: 1,980
Trainable params: 1,980
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</section>
<section id="positional-encoding">
<h3>Positional Encoding<a class="headerlink" href="#positional-encoding" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">,</span> <span class="n">max_dims</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_dims</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="n">max_dims</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># max_dims must be even</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_steps</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_dims</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">pos_emb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">,</span> <span class="n">max_dims</span><span class="p">))</span>
        <span class="n">pos_emb</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="mi">10000</span><span class="o">**</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="n">max_dims</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="n">pos_emb</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">p</span> <span class="o">/</span> <span class="mi">10000</span><span class="o">**</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="n">max_dims</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">pos_emb</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">inputs</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">:</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_steps</span> <span class="o">=</span> <span class="mi">201</span>
<span class="n">max_dims</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">pos_emb</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">max_dims</span><span class="p">)</span>
<span class="n">PE</span> <span class="o">=</span> <span class="n">pos_emb</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_steps</span><span class="p">,</span> <span class="n">max_dims</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i1</span><span class="p">,</span> <span class="n">i2</span><span class="p">,</span> <span class="n">crop_i</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">101</span><span class="p">,</span> <span class="mi">150</span>
<span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">p3</span> <span class="o">=</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">35</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p1</span><span class="p">,</span> <span class="n">p1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p1</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p2</span><span class="p">,</span> <span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p2</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p3</span><span class="p">,</span> <span class="n">PE</span><span class="p">[</span><span class="n">p3</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="s2">&quot;bx&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p3</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">PE</span><span class="p">[:,</span><span class="n">i1</span><span class="p">],</span> <span class="s2">&quot;b-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$i = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i1</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">PE</span><span class="p">[:,</span><span class="n">i2</span><span class="p">],</span> <span class="s2">&quot;r-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$i = </span><span class="si">{}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i2</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="n">PE</span><span class="p">[</span><span class="n">p1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="n">PE</span><span class="p">[</span><span class="n">p2</span><span class="p">,</span> <span class="n">i1</span><span class="p">]],</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="n">PE</span><span class="p">[</span><span class="n">p1</span><span class="p">,</span> <span class="n">i2</span><span class="p">],</span> <span class="n">PE</span><span class="p">[</span><span class="n">p2</span><span class="p">,</span> <span class="n">i2</span><span class="p">]],</span> <span class="s2">&quot;ro&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;center right&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">framealpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$P_{(p,i)}$&quot;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">PE</span><span class="o">.</span><span class="n">T</span><span class="p">[:</span><span class="n">crop_i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">i1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>
<span class="n">cheat</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># need to raise the red line a bit, or else it hides the blue one</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">i2</span><span class="o">+</span><span class="n">cheat</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p1</span><span class="p">,</span> <span class="n">p1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">crop_i</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p2</span><span class="p">,</span> <span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">crop_i</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="n">i2</span><span class="o">+</span><span class="n">cheat</span><span class="p">,</span> <span class="n">i2</span><span class="o">+</span><span class="n">cheat</span><span class="p">],</span> <span class="s2">&quot;ro&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">],</span> <span class="p">[</span><span class="n">i1</span><span class="p">,</span> <span class="n">i1</span><span class="p">],</span> <span class="s2">&quot;bo&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">crop_i</span><span class="p">])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$p$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$i$&quot;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">save_fig</span><span class="p">(</span><span class="s2">&quot;positional_embedding_plot&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/16_nlp_with_rnns_and_attention_97_0.png" src="../../_images/16_nlp_with_rnns_and_attention_97_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embed_size</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span> <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">500</span><span class="p">;</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
<span class="n">encoder_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)</span>
<span class="n">decoder_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">)</span>
<span class="n">positional_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">max_dims</span><span class="o">=</span><span class="n">embed_size</span><span class="p">)</span>
<span class="n">encoder_in</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">encoder_embeddings</span><span class="p">)</span>
<span class="n">decoder_in</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">decoder_embeddings</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here is a (very) simplified Transformer (the actual architecture has skip connections, layer norm, dense nets, and most importantly it uses Multi-Head Attention instead of regular Attention):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span> <span class="o">=</span> <span class="n">encoder_in</span>
<span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Attention</span><span class="p">(</span><span class="n">use_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)([</span><span class="n">Z</span><span class="p">,</span> <span class="n">Z</span><span class="p">])</span>

<span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">Z</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">decoder_in</span>
<span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Attention</span><span class="p">(</span><span class="n">use_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="kc">True</span><span class="p">)([</span><span class="n">Z</span><span class="p">,</span> <span class="n">Z</span><span class="p">])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Attention</span><span class="p">(</span><span class="n">use_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">)([</span><span class="n">Z</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">])</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">TimeDistributed</span><span class="p">(</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))(</span><span class="n">Z</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here’s a basic implementation of the <code class="docutils literal notranslate"><span class="pre">MultiHeadAttention</span></code> layer. One will likely be added to <code class="docutils literal notranslate"><span class="pre">keras.layers</span></code> in the near future. Note that <code class="docutils literal notranslate"><span class="pre">Conv1D</span></code> layers with <code class="docutils literal notranslate"><span class="pre">kernel_size=1</span></code> (and the default <code class="docutils literal notranslate"><span class="pre">padding=&quot;valid&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">strides=1</span></code>) is equivalent to a <code class="docutils literal notranslate"><span class="pre">TimeDistributed(Dense(...))</span></code> layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span>

<span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">causal</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_scale</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal</span> <span class="o">=</span> <span class="n">causal</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_scale</span> <span class="o">=</span> <span class="n">use_scale</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_input_shape</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dims</span> <span class="o">=</span> <span class="n">batch_input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dims</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dims</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span> <span class="c1"># could be hyperparameters instead</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_dims</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_linear</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_dims</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_linear</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_dims</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Attention</span><span class="p">(</span><span class="n">causal</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">causal</span><span class="p">,</span> <span class="n">use_scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_scale</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_linear</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">batch_input_shape</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_multi_head_linear</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">linear</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
        <span class="n">projected</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">linear</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">shape</span><span class="p">)</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">permute_dimensions</span><span class="p">(</span><span class="n">projected</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">perm</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="n">v</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="n">q_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multi_head_linear</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_linear</span><span class="p">)</span>
        <span class="n">v_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multi_head_linear</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_linear</span><span class="p">)</span>
        <span class="n">k_proj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_multi_head_linear</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_linear</span><span class="p">)</span>
        <span class="n">multi_attended</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">([</span><span class="n">q_proj</span><span class="p">,</span> <span class="n">v_proj</span><span class="p">,</span> <span class="n">k_proj</span><span class="p">])</span>
        <span class="n">shape_attended</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">multi_attended</span><span class="p">)</span>
        <span class="n">reshaped_attended</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">multi_attended</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">shape_attended</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape_attended</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
        <span class="n">perm</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">permute_dimensions</span><span class="p">(</span><span class="n">reshaped_attended</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">perm</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape_attended</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_linear</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="n">multi_attn</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>
<span class="n">multi_attn</span><span class="p">([</span><span class="n">Q</span><span class="p">,</span> <span class="n">V</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Layer multi_head_attention is casting an input tensor from dtype float64 to the layer&#39;s dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it&#39;s dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx(&#39;float64&#39;)`. To change just this layer, pass dtype=&#39;float64&#39; to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Layer multi_head_attention is casting an input tensor from dtype float64 to the layer&#39;s dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it&#39;s dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx(&#39;float64&#39;)`. To change just this layer, pass dtype=&#39;float64&#39; to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TensorShape([2, 50, 512])
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-solutions">
<h1>Exercise solutions<a class="headerlink" href="#exercise-solutions" title="Permalink to this headline">#</a></h1>
<section id="to-7">
<h2>1. to 7.<a class="headerlink" href="#to-7" title="Permalink to this headline">#</a></h2>
<p>See Appendix A.</p>
</section>
<section id="id1">
<h2>8.<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<p><em>Exercise:</em> Embedded Reber grammars <em>were used by Hochreiter and Schmidhuber in <a class="reference external" href="https://homl.info/93">their paper</a> about LSTMs. They are artificial grammars that produce strings such as “BPBTSXXVPSEPE.” Check out Jenny Orr’s <a class="reference external" href="https://homl.info/108">nice introduction</a> to this topic. Choose a particular embedded Reber grammar (such as the one represented on Jenny Orr’s page), then train an RNN to identify whether a string respects that grammar or not. You will first need to write a function capable of generating a training batch containing about 50% strings that respect the grammar, and 50% that don’t.</em></p>
<p>First we need to build a function that generates strings based on a grammar. The grammar will be represented as a list of possible transitions for each state. A transition specifies the string to output (or a grammar to generate it) and the next state.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">default_reber_grammar</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>           <span class="c1"># (state 0) =B=&gt;(state 1)</span>
    <span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)],</span> <span class="c1"># (state 1) =T=&gt;(state 2) or =P=&gt;(state 3)</span>
    <span class="p">[(</span><span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)],</span> <span class="c1"># (state 2) =S=&gt;(state 2) or =X=&gt;(state 4)</span>
    <span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;V&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span> <span class="c1"># and so on...</span>
    <span class="p">[(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="mi">6</span><span class="p">)],</span>
    <span class="p">[(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;V&quot;</span><span class="p">,</span> <span class="mi">6</span><span class="p">)],</span>
    <span class="p">[(</span><span class="s2">&quot;E&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]]</span>        <span class="c1"># (state 6) =E=&gt;(terminal state)</span>

<span class="n">embedded_reber_grammar</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[(</span><span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
    <span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)],</span>
    <span class="p">[(</span><span class="n">default_reber_grammar</span><span class="p">,</span> <span class="mi">4</span><span class="p">)],</span>
    <span class="p">[(</span><span class="n">default_reber_grammar</span><span class="p">,</span> <span class="mi">5</span><span class="p">)],</span>
    <span class="p">[(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="mi">6</span><span class="p">)],</span>
    <span class="p">[(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="mi">6</span><span class="p">)],</span>
    <span class="p">[(</span><span class="s2">&quot;E&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]]</span>

<span class="k">def</span> <span class="nf">generate_string</span><span class="p">(</span><span class="n">grammar</span><span class="p">):</span>
    <span class="n">state</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">grammar</span><span class="p">[</span><span class="n">state</span><span class="p">]))</span>
        <span class="n">production</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">grammar</span><span class="p">[</span><span class="n">state</span><span class="p">][</span><span class="n">index</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">production</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">production</span> <span class="o">=</span> <span class="n">generate_string</span><span class="p">(</span><span class="n">grammar</span><span class="o">=</span><span class="n">production</span><span class="p">)</span>
        <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">production</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s generate a few strings based on the default Reber grammar:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">generate_string</span><span class="p">(</span><span class="n">default_reber_grammar</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE 
</pre></div>
</div>
</div>
</div>
<p>Looks good. Now let’s generate a few strings based on the embedded Reber grammar:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">generate_string</span><span class="p">(</span><span class="n">embedded_reber_grammar</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE BPBTXXVPSEPE BTBTXXVVETE BPBPVVEPE BPBPVVEPE BPBTSXSEPE BPBPVVEPE BPBPTVPSEPE BPBTXXVVEPE BTBPTVPXVVETE BTBPVVETE BTBTSSSSSSSXXVVETE BPBTSSSXXTTTTVPSEPE BTBPTTVVETE BPBTXXTVVEPE BTBTXSETE 
</pre></div>
</div>
</div>
</div>
<p>Okay, now we need a function to generate strings that do not respect the grammar. We could generate a random string, but the task would be a bit too easy, so instead we will generate a string that respects the grammar, and we will corrupt it by changing just one character:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">POSSIBLE_CHARS</span> <span class="o">=</span> <span class="s2">&quot;BEPSTVX&quot;</span>

<span class="k">def</span> <span class="nf">generate_corrupted_string</span><span class="p">(</span><span class="n">grammar</span><span class="p">,</span> <span class="n">chars</span><span class="o">=</span><span class="n">POSSIBLE_CHARS</span><span class="p">):</span>
    <span class="n">good_string</span> <span class="o">=</span> <span class="n">generate_string</span><span class="p">(</span><span class="n">grammar</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">good_string</span><span class="p">))</span>
    <span class="n">good_char</span> <span class="o">=</span> <span class="n">good_string</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
    <span class="n">bad_char</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">good_char</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">good_string</span><span class="p">[:</span><span class="n">index</span><span class="p">]</span> <span class="o">+</span> <span class="n">bad_char</span> <span class="o">+</span> <span class="n">good_string</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at a few corrupted strings:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">generate_corrupted_string</span><span class="p">(</span><span class="n">embedded_reber_grammar</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BTBPTTTPPXTVPXTTVPSETE BPBTXEEPE BPBPTVVVEPE BPBTSSSSXSETE BPTTXSEPE BTBPVPXTTTTTTEVETE BPBTXXSVEPE BSBPTTVPSETE BPBXVVEPE BEBTXSETE BPBPVPSXPE BTBPVVVETE BPBTSXSETE BPBPTTTPTTTTTVPSEPE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE 
</pre></div>
</div>
</div>
</div>
<p>We cannot feed strings directly to an RNN, so we need to encode them somehow. One option would be to one-hot encode each character. Another option is to use embeddings. Let’s go for the second option (but since there are just a handful of characters, one-hot encoding would probably be a good option as well). For embeddings to work, we need to convert each string into a sequence of character IDs. Let’s write a function for that, using each character’s index in the string of possible characters “BEPSTVX”:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">string_to_ids</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">chars</span><span class="o">=</span><span class="n">POSSIBLE_CHARS</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">chars</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">string_to_ids</span><span class="p">(</span><span class="s2">&quot;BTTTXXVVETE&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0, 4, 4, 4, 6, 6, 5, 5, 1, 4, 1]
</pre></div>
</div>
</div>
</div>
<p>We can now generate the dataset, with 50% good strings, and 50% bad strings:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_dataset</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
    <span class="n">good_strings</span> <span class="o">=</span> <span class="p">[</span><span class="n">string_to_ids</span><span class="p">(</span><span class="n">generate_string</span><span class="p">(</span><span class="n">embedded_reber_grammar</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)]</span>
    <span class="n">bad_strings</span> <span class="o">=</span> <span class="p">[</span><span class="n">string_to_ids</span><span class="p">(</span><span class="n">generate_corrupted_string</span><span class="p">(</span><span class="n">embedded_reber_grammar</span><span class="p">))</span>
                   <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span> <span class="o">-</span> <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)]</span>
    <span class="n">all_strings</span> <span class="o">=</span> <span class="n">good_strings</span> <span class="o">+</span> <span class="n">bad_strings</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ragged</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">all_strings</span><span class="p">,</span> <span class="n">ragged_rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">good_strings</span><span class="p">))]</span> <span class="o">+</span>
                 <span class="p">[[</span><span class="mf">0.</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">bad_strings</span><span class="p">))])</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">generate_dataset</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">generate_dataset</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at the first training sequence:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(22,), dtype=int32, numpy=
array([0, 4, 0, 2, 4, 4, 4, 5, 2, 6, 4, 5, 2, 6, 4, 4, 5, 2, 3, 1, 4, 1],
      dtype=int32)&gt;
</pre></div>
</div>
</div>
</div>
<p>What class does it belong to?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.])
</pre></div>
</div>
</div>
</div>
<p>Perfect! We are ready to create the RNN to identify good strings. We build a simple sequence binary classifier:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">ragged</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">POSSIBLE_CHARS</span><span class="p">),</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">embedding_size</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">momentum</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;
/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 5s 42us/sample - loss: 0.6847 - accuracy: 0.5138 - val_loss: 8.1518 - val_accuracy: 0.6115
Epoch 2/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 28us/sample - loss: 0.6524 - accuracy: 0.5571 - val_loss: 7.9259 - val_accuracy: 0.6085
Epoch 3/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 28us/sample - loss: 0.6686 - accuracy: 0.5783 - val_loss: 7.7483 - val_accuracy: 0.6110
Epoch 4/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 28us/sample - loss: 0.6201 - accuracy: 0.5969 - val_loss: 7.5567 - val_accuracy: 0.6110
Epoch 5/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 28us/sample - loss: 0.5705 - accuracy: 0.6428 - val_loss: 6.9117 - val_accuracy: 0.7075
Epoch 6/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 0.5660 - accuracy: 0.7008 - val_loss: 5.7277 - val_accuracy: 0.7580
Epoch 7/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 28us/sample - loss: 0.3997 - accuracy: 0.8336 - val_loss: 4.3641 - val_accuracy: 0.8550
Epoch 8/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 0.1771 - accuracy: 0.8958 - val_loss: 1.5009 - val_accuracy: 0.9605
Epoch 9/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 0.2710 - accuracy: 0.9566 - val_loss: 3.2648 - val_accuracy: 0.9005
Epoch 10/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 0.2574 - accuracy: 0.9620 - val_loss: 1.0385 - val_accuracy: 0.9790
Epoch 11/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 0.0356 - accuracy: 0.9845 - val_loss: 0.1081 - val_accuracy: 1.0000
Epoch 12/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 4s 29us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000
Epoch 13/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000
Epoch 14/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 28us/sample - loss: 8.1710e-04 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000
Epoch 15/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 5.8225e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000
Epoch 16/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 5.8369e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000
Epoch 17/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 4s 30us/sample - loss: 3.8744e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000
Epoch 18/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 4s 29us/sample - loss: 4.2988e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000
Epoch 19/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 4s 29us/sample - loss: 2.7449e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000
Epoch 20/20
313/313 [========================================================================================================================================================================================================================================================================================================================================================================] - 3s 29us/sample - loss: 2.9469e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000
</pre></div>
</div>
</div>
</div>
<p>Now let’s test our RNN on two tricky strings: the first one is bad while the second one is good. They only differ by the second to last character. If the RNN gets this right, it shows that it managed to notice the pattern that the second letter should always be equal to the second to last letter. That requires a fairly long short-term memory (which is the reason why we used a GRU cell).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_strings</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE&quot;</span><span class="p">,</span>
                <span class="s2">&quot;BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE&quot;</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ragged</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">string_to_ids</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">test_strings</span><span class="p">],</span> <span class="n">ragged_rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated probability that these are Reber strings:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">string</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_strings</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">: </span><span class="si">{:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">y_proba</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Estimated probability that these are Reber strings:
BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 0.40%
BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 99.96%
</pre></div>
</div>
</div>
</div>
<p>Ta-da! It worked fine. The RNN found the correct answers with very high confidence. :)</p>
</section>
<section id="id2">
<h2>9.<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<p><em>Exercise: Train an Encoder–Decoder model that can convert a date string from one format to another (e.g., from “April 22, 2019” to “2019-04-22”).</em></p>
<p>Let’s start by creating the dataset. We will use random days between 1000-01-01 and 9999-12-31:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">date</span>

<span class="c1"># cannot use strftime()&#39;s %B format since it depends on the locale</span>
<span class="n">MONTHS</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;January&quot;</span><span class="p">,</span> <span class="s2">&quot;February&quot;</span><span class="p">,</span> <span class="s2">&quot;March&quot;</span><span class="p">,</span> <span class="s2">&quot;April&quot;</span><span class="p">,</span> <span class="s2">&quot;May&quot;</span><span class="p">,</span> <span class="s2">&quot;June&quot;</span><span class="p">,</span>
          <span class="s2">&quot;July&quot;</span><span class="p">,</span> <span class="s2">&quot;August&quot;</span><span class="p">,</span> <span class="s2">&quot;September&quot;</span><span class="p">,</span> <span class="s2">&quot;October&quot;</span><span class="p">,</span> <span class="s2">&quot;November&quot;</span><span class="p">,</span> <span class="s2">&quot;December&quot;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">random_dates</span><span class="p">(</span><span class="n">n_dates</span><span class="p">):</span>
    <span class="n">min_date</span> <span class="o">=</span> <span class="n">date</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">toordinal</span><span class="p">()</span>
    <span class="n">max_date</span> <span class="o">=</span> <span class="n">date</span><span class="p">(</span><span class="mi">9999</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">31</span><span class="p">)</span><span class="o">.</span><span class="n">toordinal</span><span class="p">()</span>

    <span class="n">ordinals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">max_date</span> <span class="o">-</span> <span class="n">min_date</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_dates</span><span class="p">)</span> <span class="o">+</span> <span class="n">min_date</span>
    <span class="n">dates</span> <span class="o">=</span> <span class="p">[</span><span class="n">date</span><span class="o">.</span><span class="n">fromordinal</span><span class="p">(</span><span class="n">ordinal</span><span class="p">)</span> <span class="k">for</span> <span class="n">ordinal</span> <span class="ow">in</span> <span class="n">ordinals</span><span class="p">]</span>

    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">MONTHS</span><span class="p">[</span><span class="n">dt</span><span class="o">.</span><span class="n">month</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">dt</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2">, %Y&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">dates</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">dt</span><span class="o">.</span><span class="n">isoformat</span><span class="p">()</span> <span class="k">for</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">dates</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<p>Here are a few random dates, displayed in both the input format and the target format:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">n_dates</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">x_example</span><span class="p">,</span> <span class="n">y_example</span> <span class="o">=</span> <span class="n">random_dates</span><span class="p">(</span><span class="n">n_dates</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:25s}{:25s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;Input&quot;</span><span class="p">,</span> <span class="s2">&quot;Target&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dates</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:25s}{:25s}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x_example</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">y_example</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input                    Target                   
--------------------------------------------------
September 20, 7075       7075-09-20               
May 15, 8579             8579-05-15               
January 11, 7103         7103-01-11               
</pre></div>
</div>
</div>
</div>
<p>Let’s get the list of all possible characters in the inputs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">INPUT_CHARS</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">MONTHS</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;0123456789, &quot;</span><span class="p">)))</span>
<span class="n">INPUT_CHARS</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39; ,0123456789ADFJMNOSabceghilmnoprstuvy&#39;
</pre></div>
</div>
</div>
</div>
<p>And here’s the list of possible characters in the outputs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">OUTPUT_CHARS</span> <span class="o">=</span> <span class="s2">&quot;0123456789-&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s write a function to convert a string to a list of character IDs, as we did in the previous exercise:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">date_str_to_ids</span><span class="p">(</span><span class="n">date_str</span><span class="p">,</span> <span class="n">chars</span><span class="o">=</span><span class="n">INPUT_CHARS</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">chars</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">date_str</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">date_str_to_ids</span><span class="p">(</span><span class="n">x_example</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">INPUT_CHARS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[7, 11, 19, 22, 11, 16, 9, 11, 20, 38, 28, 26, 37, 38, 33, 26, 33, 31]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">date_str_to_ids</span><span class="p">(</span><span class="n">y_example</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">OUTPUT_CHARS</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_date_strs</span><span class="p">(</span><span class="n">date_strs</span><span class="p">,</span> <span class="n">chars</span><span class="o">=</span><span class="n">INPUT_CHARS</span><span class="p">):</span>
    <span class="n">X_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">date_str_to_ids</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="n">chars</span><span class="p">)</span> <span class="k">for</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">date_strs</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ragged</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">X_ids</span><span class="p">,</span> <span class="n">ragged_rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">X</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to_tensor</span><span class="p">()</span> <span class="c1"># using 0 as the padding token ID</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">n_dates</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">random_dates</span><span class="p">(</span><span class="n">n_dates</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prepare_date_strs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">INPUT_CHARS</span><span class="p">),</span> <span class="n">prepare_date_strs</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">OUTPUT_CHARS</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">Y_valid</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1], dtype=int32)&gt;
</pre></div>
</div>
</div>
</div>
<section id="first-version-a-very-basic-seq2seq-model">
<h3>First version: a very basic seq2seq model<a class="headerlink" href="#first-version-a-very-basic-seq2seq-model" title="Permalink to this headline">#</a></h3>
<p>Let’s first try the simplest possible model: we feed in the input sequence, which first goes through the encoder (an embedding layer followed by a single LSTM layer), which outputs a vector, then it goes through a decoder (a single LSTM layer, followed by a dense output layer), which outputs a sequence of vectors, each representing the estimated probabilities for all possible output character.</p>
<p>Since the decoder expects a sequence as input, we repeat the vector (which is output by the decoder) as many times as the longest possible output sequence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">max_output_length</span> <span class="o">=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">INPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                           <span class="n">output_dim</span><span class="o">=</span><span class="n">embedding_size</span><span class="p">,</span>
                           <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">decoder</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">encoder</span><span class="p">,</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">RepeatVector</span><span class="p">(</span><span class="n">max_output_length</span><span class="p">),</span>
    <span class="n">decoder</span>
<span class="p">])</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">Y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
313/313 [==============================] - 6s 18ms/step - loss: 1.8111 - accuracy: 0.3533 - val_loss: 1.3581 - val_accuracy: 0.4965
Epoch 2/20
313/313 [==============================] - 5s 15ms/step - loss: 1.3518 - accuracy: 0.5103 - val_loss: 1.1915 - val_accuracy: 0.5694
Epoch 3/20
313/313 [==============================] - 5s 15ms/step - loss: 1.1706 - accuracy: 0.5908 - val_loss: 0.9983 - val_accuracy: 0.6398
Epoch 4/20
313/313 [==============================] - 5s 15ms/step - loss: 0.9158 - accuracy: 0.6686 - val_loss: 0.8012 - val_accuracy: 0.6987
Epoch 5/20
313/313 [==============================] - 5s 15ms/step - loss: 0.7058 - accuracy: 0.7308 - val_loss: 0.6224 - val_accuracy: 0.7599
Epoch 6/20
313/313 [==============================] - 5s 15ms/step - loss: 0.7756 - accuracy: 0.7203 - val_loss: 0.6541 - val_accuracy: 0.7599
Epoch 7/20
313/313 [==============================] - 5s 16ms/step - loss: 0.5379 - accuracy: 0.8034 - val_loss: 0.4174 - val_accuracy: 0.8440
Epoch 8/20
313/313 [==============================] - 5s 15ms/step - loss: 0.4867 - accuracy: 0.8262 - val_loss: 0.4188 - val_accuracy: 0.8480
Epoch 9/20
313/313 [==============================] - 5s 15ms/step - loss: 0.2979 - accuracy: 0.8951 - val_loss: 0.2549 - val_accuracy: 0.9126
Epoch 10/20
313/313 [==============================] - 5s 14ms/step - loss: 0.1785 - accuracy: 0.9479 - val_loss: 0.1461 - val_accuracy: 0.9594
Epoch 11/20
313/313 [==============================] - 5s 15ms/step - loss: 0.1830 - accuracy: 0.9557 - val_loss: 0.1644 - val_accuracy: 0.9550
Epoch 12/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0775 - accuracy: 0.9857 - val_loss: 0.0595 - val_accuracy: 0.9901
Epoch 13/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0400 - accuracy: 0.9953 - val_loss: 0.0342 - val_accuracy: 0.9957
Epoch 14/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0248 - accuracy: 0.9979 - val_loss: 0.0231 - val_accuracy: 0.9983
Epoch 15/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0161 - accuracy: 0.9991 - val_loss: 0.0149 - val_accuracy: 0.9995
Epoch 16/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0108 - accuracy: 0.9997 - val_loss: 0.0106 - val_accuracy: 0.9996
Epoch 17/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0074 - accuracy: 0.9999 - val_loss: 0.0077 - val_accuracy: 0.9999
Epoch 18/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9999
Epoch 19/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000
Epoch 20/20
313/313 [==============================] - 5s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000
</pre></div>
</div>
</div>
</div>
<p>Looks great, we reach 100% validation accuracy! Let’s use the model to make some predictions. We will need to be able to convert a sequence of character IDs to a readable string:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ids_to_date_strs</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">chars</span><span class="o">=</span><span class="n">OUTPUT_CHARS</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([(</span><span class="s2">&quot;?&quot;</span> <span class="o">+</span> <span class="n">chars</span><span class="p">)[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">sequence</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can use the model to convert some dates</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_new</span> <span class="o">=</span> <span class="n">prepare_date_strs</span><span class="p">([</span><span class="s2">&quot;September 17, 2009&quot;</span><span class="p">,</span> <span class="s2">&quot;July 14, 1789&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#ids = model.predict_classes(X_new)</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">date_str</span> <span class="ow">in</span> <span class="n">ids_to_date_strs</span><span class="p">(</span><span class="n">ids</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">date_str</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2009-09-17
1789-07-14
</pre></div>
</div>
</div>
</div>
<p>Perfect! :)</p>
<p>However, since the model was only trained on input strings of length 18 (which is the length of the longest date), it does not perform well if we try to use it to make predictions on shorter sequences:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_new</span> <span class="o">=</span> <span class="n">prepare_date_strs</span><span class="p">([</span><span class="s2">&quot;May 02, 2020&quot;</span><span class="p">,</span> <span class="s2">&quot;July 14, 1789&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#ids = model.predict_classes(X_new)</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">date_str</span> <span class="ow">in</span> <span class="n">ids_to_date_strs</span><span class="p">(</span><span class="n">ids</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">date_str</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2020-01-02
1789-02-14
</pre></div>
</div>
</div>
</div>
<p>Oops! We need to ensure that we always pass sequences of the same length as during training, using padding if necessary. Let’s write a little helper function for that:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_input_length</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">prepare_date_strs_padded</span><span class="p">(</span><span class="n">date_strs</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">prepare_date_strs</span><span class="p">(</span><span class="n">date_strs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">max_input_length</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_input_length</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]])</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="k">def</span> <span class="nf">convert_date_strs</span><span class="p">(</span><span class="n">date_strs</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">prepare_date_strs_padded</span><span class="p">(</span><span class="n">date_strs</span><span class="p">)</span>
    <span class="c1">#ids = model.predict_classes(X)</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ids_to_date_strs</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">convert_date_strs</span><span class="p">([</span><span class="s2">&quot;May 02, 2020&quot;</span><span class="p">,</span> <span class="s2">&quot;July 14, 1789&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;2020-05-02&#39;, &#39;1789-07-14&#39;]
</pre></div>
</div>
</div>
</div>
<p>Cool! Granted, there are certainly much easier ways to write a date conversion tool (e.g., using regular expressions or even basic string manipulation), but you have to admit that using neural networks is way cooler. ;-)</p>
<p>However, real-life sequence-to-sequence problems will usually be harder, so for the sake of completeness, let’s build a more powerful model.</p>
</section>
<section id="second-version-feeding-the-shifted-targets-to-the-decoder-teacher-forcing">
<h3>Second version: feeding the shifted targets to the decoder (teacher forcing)<a class="headerlink" href="#second-version-feeding-the-shifted-targets-to-the-decoder-teacher-forcing" title="Permalink to this headline">#</a></h3>
<p>Instead of feeding the decoder a simple repetition of the encoder’s output vector, we can feed it the target sequence, shifted by one time step to the right. This way, at each time step the decoder will know what the previous target character was. This should help is tackle more complex sequence-to-sequence problems.</p>
<p>Since the first output character of each target sequence has no previous character, we will need a new token to represent the start-of-sequence (sos).</p>
<p>During inference, we won’t know the target, so what will we feed the decoder? We can just predict one character at a time, starting with an sos token, then feeding the decoder all the characters that were predicted so far (we will look at this in more details later in this notebook).</p>
<p>But if the decoder’s LSTM expects to get the previous target as input at each step, how shall we pass it it the vector output by the encoder? Well, one option is to ignore the output vector, and instead use the encoder’s LSTM state as the initial state of the decoder’s LSTM (which requires that encoder’s LSTM must have the same number of units as the decoder’s LSTM).</p>
<p>Now let’s create the decoder’s inputs (for training, validation and testing). The sos token will be represented using the last possible output character’s ID + 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sos_id</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">shifted_output_sequences</span><span class="p">(</span><span class="n">Y</span><span class="p">):</span>
    <span class="n">sos_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="n">sos_id</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">sos_tokens</span><span class="p">,</span> <span class="n">Y</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_train_decoder</span> <span class="o">=</span> <span class="n">shifted_output_sequences</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">X_valid_decoder</span> <span class="o">=</span> <span class="n">shifted_output_sequences</span><span class="p">(</span><span class="n">Y_valid</span><span class="p">)</span>
<span class="n">X_test_decoder</span> <span class="o">=</span> <span class="n">shifted_output_sequences</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at the decoder’s training inputs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_decoder</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(10000, 10), dtype=int32, numpy=
array([[12,  8,  1, ..., 10, 11,  3],
       [12,  9,  6, ...,  6, 11,  2],
       [12,  8,  2, ...,  2, 11,  2],
       ...,
       [12, 10,  8, ...,  2, 11,  4],
       [12,  2,  2, ...,  3, 11,  3],
       [12,  8,  9, ...,  8, 11,  3]], dtype=int32)&gt;
</pre></div>
</div>
</div>
</div>
<p>Now let’s build the model. It’s not a simple sequential model anymore, so let’s use the functional API:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoder_embedding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">decoder_embedding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">lstm_units</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">encoder_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">encoder_embedding</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">INPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">output_dim</span><span class="o">=</span><span class="n">encoder_embedding_size</span><span class="p">)(</span><span class="n">encoder_input</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">encoder_state_h</span><span class="p">,</span> <span class="n">encoder_state_c</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
    <span class="n">lstm_units</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">encoder_embedding</span><span class="p">)</span>
<span class="n">encoder_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">encoder_state_h</span><span class="p">,</span> <span class="n">encoder_state_c</span><span class="p">]</span>

<span class="n">decoder_input</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">decoder_embedding</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">output_dim</span><span class="o">=</span><span class="n">decoder_embedding_size</span><span class="p">)(</span><span class="n">decoder_input</span><span class="p">)</span>
<span class="n">decoder_lstm_output</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">lstm_units</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span>
    <span class="n">decoder_embedding</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">)</span>
<span class="n">decoder_output</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                    <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">decoder_lstm_output</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">encoder_input</span><span class="p">,</span> <span class="n">decoder_input</span><span class="p">],</span>
                           <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">decoder_output</span><span class="p">])</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train_decoder</span><span class="p">],</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">([</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">X_valid_decoder</span><span class="p">],</span> <span class="n">Y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
313/313 [==============================] - 5s 17ms/step - loss: 1.6898 - accuracy: 0.3714 - val_loss: 1.4141 - val_accuracy: 0.4603
Epoch 2/10
313/313 [==============================] - 5s 15ms/step - loss: 1.2118 - accuracy: 0.5541 - val_loss: 0.9360 - val_accuracy: 0.6653
Epoch 3/10
313/313 [==============================] - 5s 15ms/step - loss: 0.6399 - accuracy: 0.7766 - val_loss: 0.4054 - val_accuracy: 0.8631
Epoch 4/10
313/313 [==============================] - 5s 15ms/step - loss: 0.2207 - accuracy: 0.9463 - val_loss: 0.1069 - val_accuracy: 0.9869
Epoch 5/10
313/313 [==============================] - 5s 15ms/step - loss: 0.0805 - accuracy: 0.9910 - val_loss: 0.0445 - val_accuracy: 0.9976
Epoch 6/10
313/313 [==============================] - 5s 15ms/step - loss: 0.0297 - accuracy: 0.9993 - val_loss: 0.0237 - val_accuracy: 0.9992
Epoch 7/10
313/313 [==============================] - 5s 15ms/step - loss: 0.0743 - accuracy: 0.9857 - val_loss: 0.0702 - val_accuracy: 0.9889
Epoch 8/10
313/313 [==============================] - 5s 15ms/step - loss: 0.0187 - accuracy: 0.9995 - val_loss: 0.0112 - val_accuracy: 0.9999
Epoch 9/10
313/313 [==============================] - 5s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000
Epoch 10/10
313/313 [==============================] - 5s 15ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000
</pre></div>
</div>
</div>
</div>
<p>This model also reaches 100% validation accuracy, but it does so even faster.</p>
<p>Let’s once again use the model to make some predictions. This time we need to predict characters one by one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sos_id</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">predict_date_strs</span><span class="p">(</span><span class="n">date_strs</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">prepare_date_strs_padded</span><span class="p">(</span><span class="n">date_strs</span><span class="p">)</span>
    <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">value</span><span class="o">=</span><span class="n">sos_id</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_output_length</span><span class="p">):</span>
        <span class="n">pad_size</span> <span class="o">=</span> <span class="n">max_output_length</span> <span class="o">-</span> <span class="n">Y_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">X_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">Y_pred</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">pad_size</span><span class="p">]])</span>
        <span class="n">Y_probas_next</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">X_decoder</span><span class="p">])[:,</span> <span class="n">index</span><span class="p">:</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">Y_pred_next</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_probas_next</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Y_pred</span><span class="p">,</span> <span class="n">Y_pred_next</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ids_to_date_strs</span><span class="p">(</span><span class="n">Y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predict_date_strs</span><span class="p">([</span><span class="s2">&quot;July 14, 1789&quot;</span><span class="p">,</span> <span class="s2">&quot;May 01, 2020&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;1789-07-14&#39;, &#39;2020-05-01&#39;]
</pre></div>
</div>
</div>
</div>
<p>Works fine! :)</p>
</section>
<section id="third-version-using-tf-addons-s-seq2seq-implementation">
<h3>Third version: using TF-Addons’s seq2seq implementation<a class="headerlink" href="#third-version-using-tf-addons-s-seq2seq-implementation" title="Permalink to this headline">#</a></h3>
<p>Let’s build exactly the same model, but using TF-Addon’s seq2seq API. The implementation below is almost very similar to the TFA example higher in this notebook, except without the model input to specify the output sequence length, for simplicity (but you can easily add it back in if you need it for your projects, when the output sequences have very different lengths).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">encoder_embedding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">decoder_embedding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">units</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">sequence_lengths</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="n">encoder_embeddings</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">INPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">encoder_embedding_size</span><span class="p">)(</span><span class="n">encoder_inputs</span><span class="p">)</span>

<span class="n">decoder_embedding_layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">decoder_embedding_size</span><span class="p">)</span>
<span class="n">decoder_embeddings</span> <span class="o">=</span> <span class="n">decoder_embedding_layer</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">encoder_embeddings</span><span class="p">)</span>
<span class="n">encoder_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">]</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">TrainingSampler</span><span class="p">()</span>

<span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">decoder</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">basic_decoder</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">decoder_cell</span><span class="p">,</span>
                                                 <span class="n">sampler</span><span class="p">,</span>
                                                 <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
<span class="n">final_outputs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">final_sequence_lengths</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
    <span class="n">decoder_embeddings</span><span class="p">,</span>
    <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">)</span>
<span class="n">Y_proba</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">final_outputs</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">],</span>
                           <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">Y_proba</span><span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train_decoder</span><span class="p">],</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">([</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">X_valid_decoder</span><span class="p">],</span> <span class="n">Y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/15
313/313 [==============================] - 5s 17ms/step - loss: 1.6757 - accuracy: 0.3683 - val_loss: 1.4602 - val_accuracy: 0.4214
Epoch 2/15
313/313 [==============================] - 5s 15ms/step - loss: 1.3873 - accuracy: 0.4566 - val_loss: 1.2904 - val_accuracy: 0.4957
Epoch 3/15
313/313 [==============================] - 5s 15ms/step - loss: 1.0471 - accuracy: 0.6109 - val_loss: 0.7737 - val_accuracy: 0.7276
Epoch 4/15
313/313 [==============================] - 5s 15ms/step - loss: 0.5056 - accuracy: 0.8296 - val_loss: 0.2695 - val_accuracy: 0.9305
Epoch 5/15
313/313 [==============================] - 5s 15ms/step - loss: 0.1677 - accuracy: 0.9657 - val_loss: 0.0870 - val_accuracy: 0.9912
Epoch 6/15
313/313 [==============================] - 5s 15ms/step - loss: 0.1007 - accuracy: 0.9850 - val_loss: 0.0492 - val_accuracy: 0.9975
Epoch 7/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0308 - accuracy: 0.9993 - val_loss: 0.0228 - val_accuracy: 0.9996
Epoch 8/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0168 - accuracy: 0.9999 - val_loss: 0.0144 - val_accuracy: 0.9999
Epoch 9/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9999
Epoch 10/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9999
Epoch 11/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9999
Epoch 12/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000
Epoch 13/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000
Epoch 14/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000
Epoch 15/15
313/313 [==============================] - 5s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000
</pre></div>
</div>
</div>
</div>
<p>And once again, 100% validation accuracy! To use the model, we can just reuse the <code class="docutils literal notranslate"><span class="pre">predict_date_strs()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predict_date_strs</span><span class="p">([</span><span class="s2">&quot;July 14, 1789&quot;</span><span class="p">,</span> <span class="s2">&quot;May 01, 2020&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;1789-07-14&#39;, &#39;2020-05-01&#39;]
</pre></div>
</div>
</div>
</div>
<p>However, there’s a much more efficient way to perform inference. Until now, during inference, we’ve run the model once for each new character. Instead, we can create a new decoder, based on the previously trained layers, but using a <code class="docutils literal notranslate"><span class="pre">GreedyEmbeddingSampler</span></code> instead of a <code class="docutils literal notranslate"><span class="pre">TrainingSampler</span></code>.</p>
<p>At each time step, the <code class="docutils literal notranslate"><span class="pre">GreedyEmbeddingSampler</span></code> will compute the argmax of the decoder’s outputs, and run the resulting token IDs through the decoder’s embedding layer. Then it will feed the resulting embeddings to the decoder’s LSTM cell at the next time step. This way, we only need to run the decoder once to get the full prediction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inference_sampler</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">GreedyEmbeddingSampler</span><span class="p">(</span>
    <span class="n">embedding_fn</span><span class="o">=</span><span class="n">decoder_embedding_layer</span><span class="p">)</span>
<span class="n">inference_decoder</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">basic_decoder</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
    <span class="n">decoder_cell</span><span class="p">,</span> <span class="n">inference_sampler</span><span class="p">,</span> <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">,</span>
    <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_output_length</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)[:</span><span class="mi">1</span><span class="p">]</span>
<span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">sos_id</span><span class="p">)</span>
<span class="n">final_outputs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">final_sequence_lengths</span> <span class="o">=</span> <span class="n">inference_decoder</span><span class="p">(</span>
    <span class="n">start_tokens</span><span class="p">,</span>
    <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span>
    <span class="n">start_tokens</span><span class="o">=</span><span class="n">start_tokens</span><span class="p">,</span>
    <span class="n">end_token</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">inference_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">],</span>
                                     <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">final_outputs</span><span class="o">.</span><span class="n">sample_id</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>A few notes:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">GreedyEmbeddingSampler</span></code> needs the <code class="docutils literal notranslate"><span class="pre">start_tokens</span></code> (a vector containing the start-of-sequence ID for each decoder sequence), and the <code class="docutils literal notranslate"><span class="pre">end_token</span></code> (the decoder will stop decoding a sequence once the model outputs this token).</p></li>
<li><p>We must set <code class="docutils literal notranslate"><span class="pre">maximum_iterations</span></code> when creating the <code class="docutils literal notranslate"><span class="pre">BasicDecoder</span></code>, or else it may run into an infinite loop (if the model never outputs the end token for at least one of the sequences). This would force you would to restart the Jupyter kernel.</p></li>
<li><p>The decoder inputs are not needed anymore, since all the decoder inputs are generated dynamically based on the outputs from the previous time step.</p></li>
<li><p>The model’s outputs are <code class="docutils literal notranslate"><span class="pre">final_outputs.sample_id</span></code> instead of the softmax of <code class="docutils literal notranslate"><span class="pre">final_outputs.rnn_outputs</span></code>. This allows us to directly get the argmax of the model’s outputs. If you prefer to have access to the logits, you can replace <code class="docutils literal notranslate"><span class="pre">final_outputs.sample_id</span></code> with <code class="docutils literal notranslate"><span class="pre">final_outputs.rnn_outputs</span></code>.</p></li>
</ul>
<p>Now we can write a simple function that uses the model to perform the date format conversion:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fast_predict_date_strs</span><span class="p">(</span><span class="n">date_strs</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">prepare_date_strs_padded</span><span class="p">(</span><span class="n">date_strs</span><span class="p">)</span>
    <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">inference_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ids_to_date_strs</span><span class="p">(</span><span class="n">Y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fast_predict_date_strs</span><span class="p">([</span><span class="s2">&quot;July 14, 1789&quot;</span><span class="p">,</span> <span class="s2">&quot;May 01, 2020&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;1789-07-14&#39;, &#39;2020-05-01&#39;]
</pre></div>
</div>
</div>
</div>
<p>Let’s check that it really is faster:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> predict_date_strs([&quot;July 14, 1789&quot;, &quot;May 01, 2020&quot;])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>199 ms ± 3.94 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> fast_predict_date_strs([&quot;July 14, 1789&quot;, &quot;May 01, 2020&quot;])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>18.3 ms ± 366 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div>
</div>
</div>
</div>
<p>That’s more than a 10x speedup! And it would be even more if we were handling longer sequences.</p>
</section>
<section id="fourth-version-using-tf-addons-s-seq2seq-implementation-with-a-scheduled-sampler">
<h3>Fourth version: using TF-Addons’s seq2seq implementation with a scheduled sampler<a class="headerlink" href="#fourth-version-using-tf-addons-s-seq2seq-implementation-with-a-scheduled-sampler" title="Permalink to this headline">#</a></h3>
<p><strong>Warning</strong>: due to a TF bug, this version only works using TensorFlow 2.2 or above.</p>
<p>When we trained the previous model, at each time step <em>t</em> we gave the model the target token for time step <em>t</em> - 1. However, at inference time, the model did not get the previous target at each time step. Instead, it got the previous prediction. So there is a discrepancy between training and inference, which may lead to disappointing performance. To alleviate this, we can gradually replace the targets with the predictions, during training. For this, we just need to replace the <code class="docutils literal notranslate"><span class="pre">TrainingSampler</span></code> with a <code class="docutils literal notranslate"><span class="pre">ScheduledEmbeddingTrainingSampler</span></code>, and use a Keras callback to gradually increase the <code class="docutils literal notranslate"><span class="pre">sampling_probability</span></code> (i.e., the probability that the decoder will use the prediction from the previous time step rather than the target for the previous time step).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_addons</span> <span class="k">as</span> <span class="nn">tfa</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">encoder_embedding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">decoder_embedding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">units</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">sequence_lengths</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

<span class="n">encoder_embeddings</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">INPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">encoder_embedding_size</span><span class="p">)(</span><span class="n">encoder_inputs</span><span class="p">)</span>

<span class="n">decoder_embedding_layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="n">decoder_embedding_size</span><span class="p">)</span>
<span class="n">decoder_embeddings</span> <span class="o">=</span> <span class="n">decoder_embedding_layer</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">encoder_embeddings</span><span class="p">)</span>
<span class="n">encoder_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">]</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">ScheduledEmbeddingTrainingSampler</span><span class="p">(</span>
    <span class="n">sampling_probability</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
    <span class="n">embedding_fn</span><span class="o">=</span><span class="n">decoder_embedding_layer</span><span class="p">)</span>
<span class="c1"># we must set the sampling_probability after creating the sampler</span>
<span class="c1"># (see https://github.com/tensorflow/addons/pull/1714)</span>
<span class="n">sampler</span><span class="o">.</span><span class="n">sampling_probability</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>

<span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
<span class="n">output_layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">decoder</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">basic_decoder</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">decoder_cell</span><span class="p">,</span>
                                                 <span class="n">sampler</span><span class="p">,</span>
                                                 <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
<span class="n">final_outputs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">final_sequence_lengths</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span>
    <span class="n">decoder_embeddings</span><span class="p">,</span>
    <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">)</span>
<span class="n">Y_proba</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;softmax&quot;</span><span class="p">)(</span><span class="n">final_outputs</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">],</span>
                           <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">Y_proba</span><span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">update_sampling_probability</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="n">proba</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_epochs</span> <span class="o">-</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">sampler</span><span class="o">.</span><span class="n">sampling_probability</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">proba</span><span class="p">)</span>

<span class="n">sampling_probability_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LambdaCallback</span><span class="p">(</span>
    <span class="n">on_epoch_begin</span><span class="o">=</span><span class="n">update_sampling_probability</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train_decoder</span><span class="p">],</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">([</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">X_valid_decoder</span><span class="p">],</span> <span class="n">Y_valid</span><span class="p">),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">sampling_probability_cb</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  &quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. &quot;
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>313/313 [==============================] - 6s 19ms/step - loss: 1.6759 - accuracy: 0.3681 - val_loss: 1.4611 - val_accuracy: 0.4198
Epoch 2/20
313/313 [==============================] - 5s 17ms/step - loss: 1.3872 - accuracy: 0.4583 - val_loss: 1.2827 - val_accuracy: 0.5021
Epoch 3/20
313/313 [==============================] - 5s 17ms/step - loss: 1.0425 - accuracy: 0.6152 - val_loss: 0.8165 - val_accuracy: 0.7000
Epoch 4/20
313/313 [==============================] - 5s 17ms/step - loss: 0.6353 - accuracy: 0.7673 - val_loss: 0.4365 - val_accuracy: 0.8464
Epoch 5/20
313/313 [==============================] - 5s 17ms/step - loss: 0.3764 - accuracy: 0.8765 - val_loss: 0.2795 - val_accuracy: 0.9166
Epoch 6/20
313/313 [==============================] - 5s 17ms/step - loss: 0.2506 - accuracy: 0.9269 - val_loss: 0.1805 - val_accuracy: 0.9489
Epoch 7/20
313/313 [==============================] - 5s 17ms/step - loss: 0.1427 - accuracy: 0.9625 - val_loss: 0.1115 - val_accuracy: 0.9718
Epoch 8/20
313/313 [==============================] - 5s 17ms/step - loss: 0.0853 - accuracy: 0.9804 - val_loss: 0.0785 - val_accuracy: 0.9809
Epoch 9/20
313/313 [==============================] - 5s 17ms/step - loss: 0.1010 - accuracy: 0.9797 - val_loss: 0.1198 - val_accuracy: 0.9746
Epoch 10/20
313/313 [==============================] - 5s 17ms/step - loss: 0.0447 - accuracy: 0.9917 - val_loss: 0.0306 - val_accuracy: 0.9949
Epoch 11/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0241 - accuracy: 0.9961 - val_loss: 0.0205 - val_accuracy: 0.9968
Epoch 12/20
313/313 [==============================] - 5s 17ms/step - loss: 0.0705 - accuracy: 0.9861 - val_loss: 0.0823 - val_accuracy: 0.9860
Epoch 13/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0182 - accuracy: 0.9977 - val_loss: 0.0117 - val_accuracy: 0.9980
Epoch 14/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 0.0085 - val_accuracy: 0.9990
Epoch 15/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9993
Epoch 16/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9996
Epoch 17/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9995
Epoch 18/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0024 - val_accuracy: 0.9999
Epoch 19/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0031 - val_accuracy: 0.9992
Epoch 20/20
313/313 [==============================] - 5s 16ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9999
</pre></div>
</div>
</div>
</div>
<p>Not quite 100% validation accuracy, but close enough!</p>
<p>For inference, we could do the exact same thing as earlier, using a <code class="docutils literal notranslate"><span class="pre">GreedyEmbeddingSampler</span></code>. However, just for the sake of completeness, let’s use a <code class="docutils literal notranslate"><span class="pre">SampleEmbeddingSampler</span></code> instead. It’s almost the same thing, except that instead of using the argmax of the model’s output to find the token ID, it treats the outputs as logits and uses them to sample a token ID randomly. This can be useful when you want to generate text. The <code class="docutils literal notranslate"><span class="pre">softmax_temperature</span></code> argument serves the
same purpose as when we generated Shakespeare-like text (the higher this argument, the more random the generated text will be).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">softmax_temperature</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>

<span class="n">inference_sampler</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">SampleEmbeddingSampler</span><span class="p">(</span>
    <span class="n">embedding_fn</span><span class="o">=</span><span class="n">decoder_embedding_layer</span><span class="p">,</span>
    <span class="n">softmax_temperature</span><span class="o">=</span><span class="n">softmax_temperature</span><span class="p">)</span>
<span class="n">inference_decoder</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">basic_decoder</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
    <span class="n">decoder_cell</span><span class="p">,</span> <span class="n">inference_sampler</span><span class="p">,</span> <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">,</span>
    <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_output_length</span><span class="p">)</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)[:</span><span class="mi">1</span><span class="p">]</span>
<span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fill</span><span class="p">(</span><span class="n">dims</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">sos_id</span><span class="p">)</span>
<span class="n">final_outputs</span><span class="p">,</span> <span class="n">final_state</span><span class="p">,</span> <span class="n">final_sequence_lengths</span> <span class="o">=</span> <span class="n">inference_decoder</span><span class="p">(</span>
    <span class="n">start_tokens</span><span class="p">,</span>
    <span class="n">initial_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">,</span>
    <span class="n">start_tokens</span><span class="o">=</span><span class="n">start_tokens</span><span class="p">,</span>
    <span class="n">end_token</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">inference_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">],</span>
                                     <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">final_outputs</span><span class="o">.</span><span class="n">sample_id</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">creative_predict_date_strs</span><span class="p">(</span><span class="n">date_strs</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">softmax_temperature</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">temperature</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">prepare_date_strs_padded</span><span class="p">(</span><span class="n">date_strs</span><span class="p">)</span>
    <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">inference_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ids_to_date_strs</span><span class="p">(</span><span class="n">Y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">creative_predict_date_strs</span><span class="p">([</span><span class="s2">&quot;July 14, 1789&quot;</span><span class="p">,</span> <span class="s2">&quot;May 01, 2020&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;1789-07-14&#39;, &#39;2020-05-01&#39;]
</pre></div>
</div>
</div>
</div>
<p>Dates look good at room temperature. Now let’s heat things up a bit:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">creative_predict_date_strs</span><span class="p">([</span><span class="s2">&quot;July 14, 1789&quot;</span><span class="p">,</span> <span class="s2">&quot;May 01, 2020&quot;</span><span class="p">],</span>
                           <span class="n">temperature</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;2289607-12&#39;, &#39;9272-03-01&#39;]
</pre></div>
</div>
</div>
</div>
<p>Oops, the dates are overcooked, now. Let’s call them “creative” dates.</p>
</section>
<section id="fifth-version-using-tfa-seq2seq-the-keras-subclassing-api-and-attention-mechanisms">
<h3>Fifth version: using TFA seq2seq, the Keras subclassing API and attention mechanisms<a class="headerlink" href="#fifth-version-using-tfa-seq2seq-the-keras-subclassing-api-and-attention-mechanisms" title="Permalink to this headline">#</a></h3>
<p>The sequences in this problem are pretty short, but if we wanted to tackle longer sequences, we would probably have to use attention mechanisms. While it’s possible to code our own implementation, it’s simpler and more efficient to use TF-Addons’s implementation instead. Let’s do that now, this time using Keras’ subclassing API.</p>
<p><strong>Warning</strong>: due to a TensorFlow bug (see <a class="reference external" href="https://github.com/tensorflow/addons/issues/1153">this issue</a> for details), the <code class="docutils literal notranslate"><span class="pre">get_initial_state()</span></code> method fails in eager mode, so for now we have to use the subclassing API, as Keras automatically calls <code class="docutils literal notranslate"><span class="pre">tf.function()</span></code> on the <code class="docutils literal notranslate"><span class="pre">call()</span></code> method (so it runs in graph mode).</p>
<p>In this implementation, we’ve reverted back to using the <code class="docutils literal notranslate"><span class="pre">TrainingSampler</span></code>, for simplicity (but you can easily tweak it to use a <code class="docutils literal notranslate"><span class="pre">ScheduledEmbeddingTrainingSampler</span></code> instead). We also use a <code class="docutils literal notranslate"><span class="pre">GreedyEmbeddingSampler</span></code> during inference, so this class is pretty easy to use:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DateTranslation</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">encoder_embedding_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                 <span class="n">decoder_embedding_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_embedding</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">INPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="n">encoder_embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="p">,</span>
                                         <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">return_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_embedding</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">input_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span>
            <span class="n">output_dim</span><span class="o">=</span><span class="n">decoder_embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">LuongAttention</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
        <span class="n">decoder_inner_cell</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">units</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_cell</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">AttentionWrapper</span><span class="p">(</span>
            <span class="n">cell</span><span class="o">=</span><span class="n">decoder_inner_cell</span><span class="p">,</span>
            <span class="n">attention_mechanism</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">)</span>
        <span class="n">output_layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">OUTPUT_CHARS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
            <span class="n">cell</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_cell</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">TrainingSampler</span><span class="p">(),</span>
            <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inference_decoder</span> <span class="o">=</span> <span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span>
            <span class="n">cell</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_cell</span><span class="p">,</span>
            <span class="n">sampler</span><span class="o">=</span><span class="n">tfa</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">GreedyEmbeddingSampler</span><span class="p">(</span>
                <span class="n">embedding_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder_embedding</span><span class="p">),</span>
            <span class="n">output_layer</span><span class="o">=</span><span class="n">output_layer</span><span class="p">,</span>
            <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_output_length</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">encoder_input</span><span class="p">,</span> <span class="n">decoder_input</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">encoder_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_embedding</span><span class="p">(</span><span class="n">encoder_input</span><span class="p">)</span>
        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_state_h</span><span class="p">,</span> <span class="n">encoder_state_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span>
            <span class="n">encoder_embeddings</span><span class="p">,</span>
            <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="n">encoder_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">encoder_state_h</span><span class="p">,</span> <span class="n">encoder_state_c</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="p">,</span>
                       <span class="n">setup_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="n">decoder_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_embedding</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">)</span>

        <span class="n">decoder_initial_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_cell</span><span class="o">.</span><span class="n">get_initial_state</span><span class="p">(</span>
            <span class="n">decoder_embeddings</span><span class="p">)</span>
        <span class="n">decoder_initial_state</span> <span class="o">=</span> <span class="n">decoder_initial_state</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span>
            <span class="n">cell_state</span><span class="o">=</span><span class="n">encoder_state</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
                <span class="n">decoder_embeddings</span><span class="p">,</span>
                <span class="n">initial_state</span><span class="o">=</span><span class="n">decoder_initial_state</span><span class="p">,</span>
                <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">start_tokens</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">encoder_input</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">sos_id</span>
            <span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference_decoder</span><span class="p">(</span>
                <span class="n">decoder_embeddings</span><span class="p">,</span>
                <span class="n">initial_state</span><span class="o">=</span><span class="n">decoder_initial_state</span><span class="p">,</span>
                <span class="n">start_tokens</span><span class="o">=</span><span class="n">start_tokens</span><span class="p">,</span>
                <span class="n">end_token</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DateTranslation</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_train_decoder</span><span class="p">],</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">([</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">X_valid_decoder</span><span class="p">],</span> <span class="n">Y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/25
313/313 [==============================] - 7s 21ms/step - loss: 2.1549 - accuracy: 0.2295 - val_loss: 2.1450 - val_accuracy: 0.2239
Epoch 2/25
313/313 [==============================] - 6s 19ms/step - loss: 1.8147 - accuracy: 0.3492 - val_loss: 1.4931 - val_accuracy: 0.4476
Epoch 3/25
313/313 [==============================] - 6s 18ms/step - loss: 1.3585 - accuracy: 0.4909 - val_loss: 1.3168 - val_accuracy: 0.5100
Epoch 4/25
313/313 [==============================] - 6s 18ms/step - loss: 1.2787 - accuracy: 0.5293 - val_loss: 1.1767 - val_accuracy: 0.5624
Epoch 5/25
313/313 [==============================] - 6s 18ms/step - loss: 1.1236 - accuracy: 0.5776 - val_loss: 1.0769 - val_accuracy: 0.5907
Epoch 6/25
313/313 [==============================] - 6s 18ms/step - loss: 1.0369 - accuracy: 0.6073 - val_loss: 1.0159 - val_accuracy: 0.6199
Epoch 7/25
313/313 [==============================] - 6s 18ms/step - loss: 0.9752 - accuracy: 0.6295 - val_loss: 0.9723 - val_accuracy: 0.6346
Epoch 8/25
313/313 [==============================] - 6s 18ms/step - loss: 0.9794 - accuracy: 0.6315 - val_loss: 0.9444 - val_accuracy: 0.6371
Epoch 9/25
313/313 [==============================] - 6s 18ms/step - loss: 0.9338 - accuracy: 0.6415 - val_loss: 0.9296 - val_accuracy: 0.6381
Epoch 10/25
313/313 [==============================] - 6s 19ms/step - loss: 0.9439 - accuracy: 0.6418 - val_loss: 0.9028 - val_accuracy: 0.6574
Epoch 11/25
313/313 [==============================] - 6s 19ms/step - loss: 0.8807 - accuracy: 0.6637 - val_loss: 0.9835 - val_accuracy: 0.6369
Epoch 12/25
313/313 [==============================] - 6s 19ms/step - loss: 0.7307 - accuracy: 0.6953 - val_loss: 0.8942 - val_accuracy: 0.6873
Epoch 13/25
313/313 [==============================] - 6s 19ms/step - loss: 0.5833 - accuracy: 0.7327 - val_loss: 0.6944 - val_accuracy: 0.7391
Epoch 14/25
313/313 [==============================] - 6s 19ms/step - loss: 0.4664 - accuracy: 0.7940 - val_loss: 0.6228 - val_accuracy: 0.7885
Epoch 15/25
313/313 [==============================] - 6s 19ms/step - loss: 0.3205 - accuracy: 0.8740 - val_loss: 0.4825 - val_accuracy: 0.8780
Epoch 16/25
313/313 [==============================] - 6s 19ms/step - loss: 0.2329 - accuracy: 0.9216 - val_loss: 0.3851 - val_accuracy: 0.9118
Epoch 17/25
313/313 [==============================] - 7s 21ms/step - loss: 0.2480 - accuracy: 0.9372 - val_loss: 0.2785 - val_accuracy: 0.9111
Epoch 18/25
313/313 [==============================] - 7s 22ms/step - loss: 0.1182 - accuracy: 0.9801 - val_loss: 0.1372 - val_accuracy: 0.9786
Epoch 19/25
313/313 [==============================] - 7s 22ms/step - loss: 0.0643 - accuracy: 0.9937 - val_loss: 0.0681 - val_accuracy: 0.9909
Epoch 20/25
313/313 [==============================] - 6s 18ms/step - loss: 0.0446 - accuracy: 0.9952 - val_loss: 0.0487 - val_accuracy: 0.9934
Epoch 21/25
313/313 [==============================] - 6s 18ms/step - loss: 0.0247 - accuracy: 0.9987 - val_loss: 0.0228 - val_accuracy: 0.9987
Epoch 22/25
313/313 [==============================] - 6s 18ms/step - loss: 0.0456 - accuracy: 0.9918 - val_loss: 0.0207 - val_accuracy: 0.9985
Epoch 23/25
313/313 [==============================] - 6s 18ms/step - loss: 0.0131 - accuracy: 0.9997 - val_loss: 0.0127 - val_accuracy: 0.9993
Epoch 24/25
313/313 [==============================] - 6s 19ms/step - loss: 0.0360 - accuracy: 0.9933 - val_loss: 0.0146 - val_accuracy: 0.9990
Epoch 25/25
313/313 [==============================] - 6s 19ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.0089 - val_accuracy: 0.9992
</pre></div>
</div>
</div>
</div>
<p>Not quite 100% validation accuracy, but close. It took a bit longer to converge this time, but there were also more parameters and more computations per iteration. And we did not use a scheduled sampler.</p>
<p>To use the model, we can write yet another little function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fast_predict_date_strs_v2</span><span class="p">(</span><span class="n">date_strs</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">prepare_date_strs_padded</span><span class="p">(</span><span class="n">date_strs</span><span class="p">)</span>
    <span class="n">X_decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">max_output_length</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">Y_probas</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">X_decoder</span><span class="p">])</span>
    <span class="n">Y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_probas</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ids_to_date_strs</span><span class="p">(</span><span class="n">Y_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fast_predict_date_strs_v2</span><span class="p">([</span><span class="s2">&quot;July 14, 1789&quot;</span><span class="p">,</span> <span class="s2">&quot;May 01, 2020&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;1789-07-14&#39;, &#39;2020-05-01&#39;]
</pre></div>
</div>
</div>
</div>
<p>There are still a few interesting features from TF-Addons that you may want to look at:</p>
<ul class="simple">
<li><p>Using a <code class="docutils literal notranslate"><span class="pre">BeamSearchDecoder</span></code> rather than a <code class="docutils literal notranslate"><span class="pre">BasicDecoder</span></code> for inference. Instead of outputing the character with the highest probability, this decoder keeps track of the several candidates, and keeps only the most likely sequences of candidates (see chapter 16 in the book for more details).</p></li>
<li><p>Setting masks or specifying <code class="docutils literal notranslate"><span class="pre">sequence_length</span></code> if the input or target sequences may have very different lengths.</p></li>
<li><p>Using a <code class="docutils literal notranslate"><span class="pre">ScheduledOutputTrainingSampler</span></code>, which gives you more flexibility than the <code class="docutils literal notranslate"><span class="pre">ScheduledEmbeddingTrainingSampler</span></code> to decide how to feed the output at time <em>t</em> to the cell at time <em>t</em>+1. By default it feeds the outputs directly to cell, without computing the argmax ID and passing it through an embedding layer. Alternatively, you specify a <code class="docutils literal notranslate"><span class="pre">next_inputs_fn</span></code> function that will be used to convert the cell outputs to inputs at the next step.</p></li>
</ul>
</section>
</section>
<section id="id3">
<h2>10.<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<p><em>Exercise: Go through TensorFlow’s <a class="reference external" href="https://homl.info/nmttuto">Neural Machine Translation with Attention tutorial</a>.</em></p>
<p>Simply open the Colab and follow its instructions. Alternatively, if you want a simpler example of using TF-Addons’s seq2seq implementation for Neural Machine Translation (NMT), look at the solution to the previous question. The last model implementation will give you a simpler example of using TF-Addons to build an NMT model using attention mechanisms.</p>
</section>
<section id="id4">
<h2>11.<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h2>
<p><em>Exercise: Use one of the recent language models (e.g., GPT) to generate more convincing Shakespearean text.</em></p>
<p>The simplest way to use recent language models is to use the excellent <a class="reference external" href="https://huggingface.co/transformers/">transformers library</a>, open sourced by Hugging Face. It provides many modern neural net architectures (including BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet and more) for Natural Language Processing (NLP), including many pretrained models. It relies on either TensorFlow or PyTorch. Best of all: it’s amazingly simple to use.</p>
<p>First, let’s load a pretrained model. In this example, we will use OpenAI’s GPT model, with an additional Language Model on top (just a linear layer with weights tied to the input embeddings). Let’s import it and load the pretrained weights (this will download about 445MB of data to <code class="docutils literal notranslate"><span class="pre">~/.cache/torch/transformers</span></code>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TFOpenAIGPTLMHeadModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TFOpenAIGPTLMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai-gpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next we will need a specialized tokenizer for this model. This one will try to use the <a class="reference external" href="https://spacy.io/">spaCy</a> and <a class="reference external" href="https://pypi.org/project/ftfy/">ftfy</a> libraries if they are installed, or else it will fall back to BERT’s <code class="docutils literal notranslate"><span class="pre">BasicTokenizer</span></code> followed by Byte-Pair Encoding (which should be fine for most use cases).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">OpenAIGPTTokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">OpenAIGPTTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;openai-gpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s use the tokenizer to tokenize and encode the prompt text:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompt_text</span> <span class="o">=</span> <span class="s2">&quot;This royal throne of kings, this sceptred isle&quot;</span>
<span class="n">encoded_prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">,</span>
                                  <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                  <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">)</span>
<span class="n">encoded_prompt</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(1, 10), dtype=int32, numpy=
array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,
        16187]], dtype=int32)&gt;
</pre></div>
</div>
</div>
</div>
<p>Easy! Next, let’s use the model to generate text after the prompt. We will generate 5 different sentences, each starting with the prompt text, followed by 40 additional tokens. For an explanation of what all the hyperparameters do, make sure to check out this great <a class="reference external" href="https://huggingface.co/blog/how-to-generate">blog post</a> by Patrick von Platen (from Hugging Face). You can play around with the hyperparameters to try to obtain better results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_sequences</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">length</span> <span class="o">=</span> <span class="mi">40</span>

<span class="n">generated_sequences</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="o">=</span><span class="n">encoded_prompt</span><span class="p">,</span>
    <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="n">length</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoded_prompt</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">repetition_penalty</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">num_sequences</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">generated_sequences</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(5, 50), dtype=int32, numpy=
array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,
        16187,   239,   784,   645,  1184,   558,  1886,   688,  6437,
          240,   784,   645,   507,   641,  5486,   240,   600,   636,
          868,   604,   694,  2816,   485,  1894,   822,   481,  1491,
          600,   880,  6061,   239,   256, 40477,   256,   600,   635,
          538,   604,  1816,   525,   239],
       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,
        16187,   488,  1288,   989,   640, 16605,   239,   256, 40477,
          674,   481, 12744,  3912,   488,  3912,  5936,  2441,   811,
          488,  1040,   485,   754,  3952,   239, 40477,   481,  1375,
         1981,   833,  1210,   481, 17384,   488,   481,  3089,   488,
          481,  4815,   509,   498,  1424],
       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,
        16187,   980,   987,  1074, 13138,   240,   531,   501,   517,
          836,   525, 12659,   485,  2642,   512,   239,   500,   616,
         7339,   704,   989,  1259, 38752,   481,  9606,   498,   481,
         6903,   239,   500,   616,  7339,   704,  3064,   994,   580,
         3953,   617,   616,  4741,   488],
       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,
        16187, 10595,   485,   510,   239,   244, 40477,   244,   481,
         1424,  6404,   498,  1922,    23, 37492,   257,   244, 40477,
          244,  3491,   240,   244,   603,   481,   618,   556,   246,
         3386,   498,   524,   756,   239,   244,   616,  1276,   509,
         1098, 10945,   498,   246,  6785],
       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,
        16187,   544,  2203,   239,   616,   544,   246,  6460,   260,
          850,   629,  4844,  3064,  3766,   240,   246,  1082,   806,
         9606,   640, 32581,   240,   595,  7914,  1243,   488, 18535,
          239,   249,   587,   538,   788,   775,  2319,   498,  1013,
          525,   544,   595,   754,  1074]], dtype=int32)&gt;
</pre></div>
</div>
</div>
</div>
<p>Now let’s decode the generated sequences and print them:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">generated_sequences</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>this royal throne of kings, this sceptred isle. even if someone had given them permission, even if it were required, they would never have been allowed to live through the hell they&#39;ve survived.&#39;
&#39;they couldn&#39;t have known that.
--------------------------------------------------------------------------------
this royal throne of kings, this sceptred isle and these people are royalty.&#39;
 then the mute prince and prince edward broke off and went to their rooms. 
 the talk passed again between the princes and the guards and the princess was of great
--------------------------------------------------------------------------------
this royal throne of kings, this sceptred isle has its own highness, an alatte that waits to save you. in this kingdom your people must emulate the kings of the realm. in this kingdom your kin should be saved from this pit and
--------------------------------------------------------------------------------
this royal throne of kings, this sceptred isle belongs to me. &quot; 
 &quot; the great throne of penvynne? &quot; 
 &quot; indeed, &quot; said the king with a nod of his head. &quot; this world was once composed of a magical
--------------------------------------------------------------------------------
this royal throne of kings, this sceptred isle is empty. this is a modern - day fedaykin court, a place where kings are governed, not emperors and judges. i don&#39;t see any sign of life that is not their own
--------------------------------------------------------------------------------
</pre></div>
</div>
</div>
</div>
<p>You can try more recent (and larger) models, such as GPT-2, CTRL, Transformer-XL or XLNet, which are all available as pretrained models in the transformers library, including variants with Language Models on top. The preprocessing steps vary slightly between models, so make sure to check out this <a class="reference external" href="https://github.com/huggingface/transformers/blob/master/examples/run_generation.py">generation example</a> from the transformers documentation (this example uses PyTorch, but it will work with very little tweaks, such as adding <code class="docutils literal notranslate"><span class="pre">TF</span></code> at the beginning of the model class name, removing the <code class="docutils literal notranslate"><span class="pre">.to()</span></code> method calls, and using <code class="docutils literal notranslate"><span class="pre">return_tensors=&quot;tf&quot;</span></code> instead of <code class="docutils literal notranslate"><span class="pre">&quot;pt&quot;</span></code>.</p>
<p>Hope you enjoyed this chapter! :)</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./handson-ml2/original"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="15_processing_sequences_using_rnns_and_cnns.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Chapter 15 – Processing Sequences Using RNNs and CNNs</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="17_autoencoders_and_gans.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 17 – Autoencoders and GANs**</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Daniel Kapitan<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>
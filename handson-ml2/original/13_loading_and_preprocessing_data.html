
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 13 – Loading and Preprocessing Data with TensorFlow &#8212; Data Science Foundation in Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://jads-nl.github.io/data-science-foundation-curriculum/handson-ml2/original/13_loading_and_preprocessing_data.html" />
    <link rel="shortcut icon" href="../../_static/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks" href="14_deep_computer_vision_with_cnns.html" />
    <link rel="prev" title="Chapter 12 – Custom Models and Training with TensorFlow" href="12_custom_models_and_training_with_tensorflow.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/jads-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Foundation in Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Why this JupyterBook?
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Statistical Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../islr/introduction.html">
   Introduction to ISLRv2
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/labs.html">
   Labs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_02.3_introduction.html">
     Lab 2.3: Introduction to Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_03.6_linear_regression.html">
     Lab 3.6: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_04.7_classification_methods.html">
     Lab 4.7: Classification Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_05.3_cross_validation_and_the_bootstrap.html">
     Lab 5.3: Cross-Validation and the Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.1_subset_selection_methods.html">
     Lab 6.5.1: Subset Selection Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.2_ridge_regression_and_the_lasso.html">
     Lab 6.5.2: Ridge Regression and the Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.3_pcr_and_pls_regression.html">
     Lab 6.5.3: PCR and PLS Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_07.8_non_linear_modelling.html">
     Lab 7.8: Non-linear Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_08.3_decision_trees.html">
     Lab 8.3: Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_09.6_support_vector_machines.html">
     Lab 9.6: Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.2_multilayer_network_on_mnist_digit_data.html">
     Lab 10.9.2: A Multilayer Network on the MNIST Digit Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.3_convolutional_neural_networks.html">
     Lab 10.9.3: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.5_imdb_document_classification.html">
     Lab 10.9.5: IMDb Document Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.6_recurrent_neural_networks.html">
     Lab 10.9.6: Recurrent Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_12.5_unsupervised_learning.html">
     Lab 12.5: Unsupervised Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/exercises.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter2/index.html">
     Chapter 2
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise1.html">
       Exercise 2.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise2.html">
       Exercise 2.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise3.html">
       Exercise 2.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise4.html">
       Exercise 2.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise5.html">
       Exercise 2.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise6.html">
       Exercise 2.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise7.html">
       Exercise 2.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise8.html">
       Exercise 2.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise9.html">
       Exercise 2.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise10.html">
       Exercise 2.10
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter3/index.html">
     Chapter 3
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise1.html">
       Exercise 3.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise2.html">
       Exercise 3.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise3.html">
       Exercise 3.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise4.html">
       Exercise 3.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise5.html">
       Exercise 3.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise6.html">
       Exercise 3.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise7.html">
       Exercise 3.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise8.html">
       Exercise 3.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise9.html">
       Exercise 3.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise10.html">
       Exercise 3.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise11.html">
       Exercise 3.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise12.html">
       Exercise 3.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise13.html">
       Exercise 3.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise14.html">
       Exercise 3.14
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise15.html">
       Exercise 3.15
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter4/index.html">
     Chapter 4
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise1.html">
       Exercise 4.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise2.html">
       Exercise 4.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise3.html">
       Exercise 4.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise4.html">
       Exercise 4.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise5.html">
       Exercise 4.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise6.html">
       Exercise 4.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise7.html">
       Exercise 4.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise8.html">
       Exercise 4.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise9.html">
       Exercise 4.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise10.html">
       Exercise 10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise11.html">
       Exercise 11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise12.html">
       Exercise 12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise13.html">
       Exercise 4.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise14.html">
       Exercise 4.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise15.html">
       Exercise 4.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise16.html">
       Exercise 4.16
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter5/index.html">
     Chapter 5
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise1.html">
       Exercise 5.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise2.html">
       Exercise 5.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise3.html">
       Problem 5.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise4.html">
       Exercise 5.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise5.html">
       Exercise 5.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise6.html">
       Exercise 5.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise7.html">
       Exercise 5.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise8.html">
       Exercise 5.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise9.html">
       Exercise 5.9
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter6/index.html">
     Chapter 6
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise1.html">
       Exercise 6.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise2.html">
       Exercise 6.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise3.html">
       Exercise 6.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise4.html">
       Exercise 6.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise5.html">
       Exercise 6.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise6.html">
       Exercise 6.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise7.html">
       Exercise 6.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise8.html">
       Exercise 6.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise9.html">
       Exercise 6.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise10.html">
       Exercise 6.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise11.html">
       Exercise 6.11
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter7/index.html">
     Chapter 7
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise1.html">
       Exercise 7.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise2.html">
       Exercise 7.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise3.html">
       Exercise 7.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise4.html">
       Exercise 7.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise5.html">
       Exercise 7.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise6.html">
       Exercise 7.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise7.html">
       Exercise 7.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise8.html">
       Exercise 7.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise9.html">
       Exercise 7.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise10.html">
       Exercise 7.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise11.html">
       Exercise 7.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise12.html">
       Exercise 7.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter8/index.html">
     Chapter 8
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise1.html">
       Exercise 8.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise2.html">
       Exercise 8.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise3.html">
       Exercise 8.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise4.html">
       Exercise 8.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise5.html">
       Exercise 8.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise6.html">
       Exercise 8.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise7.html">
       Exercise 8.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise8.html">
       Exercise 8.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise9.html">
       Exercise 8.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise10.html">
       Exercise 8.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise11.html">
       Exercise 8.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise12.html">
       Exercise 8.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter9/index.html">
     Chapter 9
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise1.html">
       Exercise 9.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise2.html">
       Exercise 9.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise3.html">
       Exercise 9.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise4.html">
       Exercise 9.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise5.html">
       Exercise 9.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise6.html">
       Exercise 9.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise7.html">
       Exercise 9.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise8.html">
       Exercise 9.8
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter12/index.html">
     Chapter 12
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise1.html">
       Exercise 12.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise2.html">
       Exercise 12.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise3.html">
       Exercise 12.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise4.html">
       Exercise 12.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise5.html">
       Exercise 12.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise6.html">
       Exercise 12.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise7.html">
       Exercise 12.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise8.html">
       Exercise 10.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise9.html">
       Exercise 12.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise10.html">
       Exercise 12.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise11.html">
       Exercise 12.11
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hands-on Machine Learning in Python
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../introduction.html">
   Hands-on Machine Learning with Aurélien Géron
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_the_machine_learning_landscape.html">
     Chapter 1 – The Machine Learning landscape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_end_to_end_machine_learning_project.html">
     Chapter 2 – End-to-end Machine Learning project
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_classification.html">
     Chapter 3 – Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_training_linear_models.html">
     Chapter 4 – Training Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_support_vector_machines.html">
     Chapter 5 – Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_decision_trees.html">
     Chapter 6 – Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07_ensemble_learning_and_random_forests.html">
     Chapter 7 – Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08_dimensionality_reduction.html">
     Chapter 8 – Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09_unsupervised_learning.html">
     Chapter 9 – Unsupervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10_neural_nets_with_keras.html">
     Chapter 10 – Introduction to Artificial Neural Networks with Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11_training_deep_neural_networks.html">
     Chapter 11 – Training Deep Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12_custom_models_and_training_with_tensorflow.html">
     Chapter 12 – Custom Models and Training with TensorFlow
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Chapter 13 – Loading and Preprocessing Data with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14_deep_computer_vision_with_cnns.html">
     Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15_processing_sequences_using_rnns_and_cnns.html">
     Chapter 15 – Processing Sequences Using RNNs and CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="16_nlp_with_rnns_and_attention.html">
     Chapter 16 – Natural Language Processing with RNNs and Attention**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="17_autoencoders_and_gans.html">
     Chapter 17 – Autoencoders and GANs**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18_reinforcement_learning.html">
     Chapter 18 – Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19_training_and_deploying_at_scale.html">
     Chapter 19 – Training and Deploying TensorFlow Models at Scale
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../extra.html">
   Miscellaneous tips &amp; tricks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="math_linear_algebra.html">
     Math primer - Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="math_differential_calculus.html">
     Math primer - Differential Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_autodiff.html">
     Implementation of autodiff techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_gradient_descent_comparison.html">
     Comparison of Batch, Mini-Batch and Stochastic Gradient Descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data visualization with Altair
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction.html">
   Data visualization with Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction-to-interactive-data-visualization.html">
   Introduction to data visualization with Python
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../visualization/altair_get_started.html">
   Getting Started with Altair
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_introduction.html">
     Introduction to Altair
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_marks_encoding.html">
     Data Types, Graphical Marks, and Visual Encoding Channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_data_transformation.html">
     Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_scales_axes_legends.html">
     Scales, Axes, and Legends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_view_composition.html">
     Multi-View Composition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_interaction.html">
     Interaction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_cartographic.html">
     Cartographic Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_debugging.html">
     Altair Debugging Guide
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Interpretable Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../iml/introduction.html">
   Introduction to IML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_partial_dependence.html">
     Partial Dependence and Individual Conditional Expectation Plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance.html">
     Permutation Importance vs Random Forest Feature Importance (MDI)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance_multicollinear.html">
     Permutation Importance with Multicollinear or Correlated Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/interpreting-machine-learning-models.html">
     IML with Pima Indians and the Titanic datasets
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Principles of time-series forecasting
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/introduction.html">
   Introduction to FPP3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/examples-time-series-forecasting-with-python.html">
   Examples of time-series forecasting with Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural language processing with spaCy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/introduction.html">
   Introduction to NLP with spaCy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../nlp/dutch-restaurant-reviews.html">
   Dutch restaurant reviews
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-dutch-restaurant-reviews.html">
     Analyzing Dutch restaurant reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/prepare-restoreviews-dataset.html">
     Fetch and prepare reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-pipeline-example.html">
     Objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/language-detection-with-character-quadgrams.html">
     Extra: language detection with character quadgrams
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-model-sizes.html">
     Extra: plot of transformer model sizes
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jads-nl/data-science-foundation-in-python/main?urlpath=tree/data_science_foundation_in_python/handson-ml2/original/13_loading_and_preprocessing_data.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jads-nl/data-science-foundation-in-python/blob/main/data_science_foundation_in_python/handson-ml2/original/13_loading_and_preprocessing_data.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-in-python"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-in-python/issues/new?title=Issue%20on%20page%20%2Fhandson-ml2/original/13_loading_and_preprocessing_data.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/handson-ml2/original/13_loading_and_preprocessing_data.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 13 – Loading and Preprocessing Data with TensorFlow
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets">
     Datasets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#split-the-california-dataset-to-multiple-csv-files">
     Split the California dataset to multiple CSV files
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#building-an-input-pipeline">
     Building an Input Pipeline
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-tfrecord-binary-format">
     The
     <code class="docutils literal notranslate">
      <span class="pre">
       TFRecord
      </span>
     </code>
     binary format
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-brief-intro-to-protocol-buffers">
       A Brief Intro to Protocol Buffers
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#custom-protobuf">
         Custom protobuf
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tensorflow-protobufs">
       TensorFlow Protobufs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#putting-images-in-tfrecords">
       Putting Images in TFRecords
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#putting-tensors-and-sparse-tensors-in-tfrecords">
       Putting Tensors and Sparse Tensors in TFRecords
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#handling-sequential-data-using-sequenceexample">
     Handling Sequential Data Using
     <code class="docutils literal notranslate">
      <span class="pre">
       SequenceExample
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-features-api">
   The Features API
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-feature-columns-for-parsing">
     Using Feature Columns for Parsing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-transform">
   TF Transform
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensorflow-datasets">
   TensorFlow Datasets
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensorflow-hub">
   TensorFlow Hub
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-8">
     1. to 8.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     9.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a">
       a.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#b">
       b.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     10.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       a.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       b.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c">
       c.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#d">
       d.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#e">
       e.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#f">
       f.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#g">
       g.
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 13 – Loading and Preprocessing Data with TensorFlow</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 13 – Loading and Preprocessing Data with TensorFlow
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#datasets">
     Datasets
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#split-the-california-dataset-to-multiple-csv-files">
     Split the California dataset to multiple CSV files
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#building-an-input-pipeline">
     Building an Input Pipeline
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-tfrecord-binary-format">
     The
     <code class="docutils literal notranslate">
      <span class="pre">
       TFRecord
      </span>
     </code>
     binary format
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a-brief-intro-to-protocol-buffers">
       A Brief Intro to Protocol Buffers
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#custom-protobuf">
         Custom protobuf
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tensorflow-protobufs">
       TensorFlow Protobufs
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#putting-images-in-tfrecords">
       Putting Images in TFRecords
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#putting-tensors-and-sparse-tensors-in-tfrecords">
       Putting Tensors and Sparse Tensors in TFRecords
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#handling-sequential-data-using-sequenceexample">
     Handling Sequential Data Using
     <code class="docutils literal notranslate">
      <span class="pre">
       SequenceExample
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-features-api">
   The Features API
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#using-feature-columns-for-parsing">
     Using Feature Columns for Parsing
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tf-transform">
   TF Transform
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensorflow-datasets">
   TensorFlow Datasets
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tensorflow-hub">
   TensorFlow Hub
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-8">
     1. to 8.
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     9.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#a">
       a.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#b">
       b.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     10.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       a.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       b.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#c">
       c.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#d">
       d.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#e">
       e.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#f">
       f.
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#g">
       g.
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-13-loading-and-preprocessing-data-with-tensorflow">
<h1>Chapter 13 – Loading and Preprocessing Data with TensorFlow<a class="headerlink" href="#chapter-13-loading-and-preprocessing-data-with-tensorflow" title="Permalink to this headline">#</a></h1>
<p><em>This notebook contains all the sample code and solutions to the exercises in chapter 13.</em></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">#</a></h1>
<p>First, let’s import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Python ≥3.5 is required
import sys
assert sys.version_info &gt;= (3, 5)

# Is this notebook running on Colab or Kaggle?
IS_COLAB = &quot;google.colab&quot; in sys.modules
IS_KAGGLE = &quot;kaggle_secrets&quot; in sys.modules

if IS_COLAB or IS_KAGGLE:
    %pip install -q -U tfx==0.21.2
    print(&quot;You can safely ignore the package incompatibility errors.&quot;)

# Scikit-Learn ≥0.20 is required
import sklearn
assert sklearn.__version__ &gt;= &quot;0.20&quot;

# TensorFlow ≥2.0 is required
import tensorflow as tf
from tensorflow import keras
assert tf.__version__ &gt;= &quot;2.0&quot;

# Common imports
import numpy as np
import os

# to make this notebook&#39;s output stable across runs
np.random.seed(42)

# To plot pretty figures
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc(&#39;axes&#39;, labelsize=14)
mpl.rc(&#39;xtick&#39;, labelsize=12)
mpl.rc(&#39;ytick&#39;, labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = &quot;.&quot;
CHAPTER_ID = &quot;data&quot;
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, &quot;images&quot;, CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension=&quot;png&quot;, resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + &quot;.&quot; + fig_extension)
    print(&quot;Saving figure&quot;, fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)
</pre></div>
</div>
</div>
</div>
<section id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X = tf.range(10)
dataset = tf.data.Dataset.from_tensor_slices(X)
dataset
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;TensorSliceDataset shapes: (), types: tf.int32&gt;
</pre></div>
</div>
</div>
</div>
<p>Equivalently:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset = tf.data.Dataset.range(10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for item in dataset:
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(0, shape=(), dtype=int64)
tf.Tensor(1, shape=(), dtype=int64)
tf.Tensor(2, shape=(), dtype=int64)
tf.Tensor(3, shape=(), dtype=int64)
tf.Tensor(4, shape=(), dtype=int64)
tf.Tensor(5, shape=(), dtype=int64)
tf.Tensor(6, shape=(), dtype=int64)
tf.Tensor(7, shape=(), dtype=int64)
tf.Tensor(8, shape=(), dtype=int64)
tf.Tensor(9, shape=(), dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset = dataset.repeat(3).batch(7)
for item in dataset:
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)
tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)
tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)
tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)
tf.Tensor([8 9], shape=(2,), dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset = dataset.map(lambda x: x * 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for item in dataset:
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int64)
tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int64)
tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int64)
tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int64)
tf.Tensor([16 18], shape=(2,), dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>#dataset = dataset.apply(tf.data.experimental.unbatch()) # Now deprecated
dataset = dataset.unbatch()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset = dataset.filter(lambda x: x &lt; 10)  # keep only items &lt; 10
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for item in dataset.take(3):
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(0, shape=(), dtype=int64)
tf.Tensor(2, shape=(), dtype=int64)
tf.Tensor(4, shape=(), dtype=int64)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tf.random.set_seed(42)

dataset = tf.data.Dataset.range(10).repeat(3)
dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)
for item in dataset:
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)
tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)
tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)
tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)
tf.Tensor([6 9], shape=(2,), dtype=int64)
</pre></div>
</div>
</div>
</div>
</section>
<section id="split-the-california-dataset-to-multiple-csv-files">
<h2>Split the California dataset to multiple CSV files<a class="headerlink" href="#split-the-california-dataset-to-multiple-csv-files" title="Permalink to this headline">#</a></h2>
<p>Let’s start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

housing = fetch_california_housing()
X_train_full, X_test, y_train_full, y_test = train_test_split(
    housing.data, housing.target.reshape(-1, 1), random_state=42)
X_train, X_valid, y_train, y_valid = train_test_split(
    X_train_full, y_train_full, random_state=42)

scaler = StandardScaler()
scaler.fit(X_train)
X_mean = scaler.mean_
X_std = scaler.scale_
</pre></div>
</div>
</div>
</div>
<p>For a very large dataset that does not fit in memory, you will typically want to split it into many files first, then have TensorFlow read these files in parallel. To demonstrate this, let’s start by splitting the housing dataset and save it to 20 CSV files:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):
    housing_dir = os.path.join(&quot;datasets&quot;, &quot;housing&quot;)
    os.makedirs(housing_dir, exist_ok=True)
    path_format = os.path.join(housing_dir, &quot;my_{}_{:02d}.csv&quot;)

    filepaths = []
    m = len(data)
    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):
        part_csv = path_format.format(name_prefix, file_idx)
        filepaths.append(part_csv)
        with open(part_csv, &quot;wt&quot;, encoding=&quot;utf-8&quot;) as f:
            if header is not None:
                f.write(header)
                f.write(&quot;\n&quot;)
            for row_idx in row_indices:
                f.write(&quot;,&quot;.join([repr(col) for col in data[row_idx]]))
                f.write(&quot;\n&quot;)
    return filepaths
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_data = np.c_[X_train, y_train]
valid_data = np.c_[X_valid, y_valid]
test_data = np.c_[X_test, y_test]
header_cols = housing.feature_names + [&quot;MedianHouseValue&quot;]
header = &quot;,&quot;.join(header_cols)

train_filepaths = save_to_multiple_csv_files(train_data, &quot;train&quot;, header, n_parts=20)
valid_filepaths = save_to_multiple_csv_files(valid_data, &quot;valid&quot;, header, n_parts=10)
test_filepaths = save_to_multiple_csv_files(test_data, &quot;test&quot;, header, n_parts=10)
</pre></div>
</div>
</div>
</div>
<p>Okay, now let’s take a peek at the first few lines of one of these CSV files:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import pandas as pd

pd.read_csv(train_filepaths[0]).head()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MedInc</th>
      <th>HouseAge</th>
      <th>AveRooms</th>
      <th>AveBedrms</th>
      <th>Population</th>
      <th>AveOccup</th>
      <th>Latitude</th>
      <th>Longitude</th>
      <th>MedianHouseValue</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.5214</td>
      <td>15.0</td>
      <td>3.049945</td>
      <td>1.106548</td>
      <td>1447.0</td>
      <td>1.605993</td>
      <td>37.63</td>
      <td>-122.43</td>
      <td>1.442</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.3275</td>
      <td>5.0</td>
      <td>6.490060</td>
      <td>0.991054</td>
      <td>3464.0</td>
      <td>3.443340</td>
      <td>33.69</td>
      <td>-117.39</td>
      <td>1.687</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.1000</td>
      <td>29.0</td>
      <td>7.542373</td>
      <td>1.591525</td>
      <td>1328.0</td>
      <td>2.250847</td>
      <td>38.44</td>
      <td>-122.98</td>
      <td>1.621</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.1736</td>
      <td>12.0</td>
      <td>6.289003</td>
      <td>0.997442</td>
      <td>1054.0</td>
      <td>2.695652</td>
      <td>33.55</td>
      <td>-117.70</td>
      <td>2.621</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0549</td>
      <td>13.0</td>
      <td>5.312457</td>
      <td>1.085092</td>
      <td>3297.0</td>
      <td>2.244384</td>
      <td>33.93</td>
      <td>-116.93</td>
      <td>0.956</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Or in text mode:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with open(train_filepaths[0]) as f:
    for i in range(5):
        print(f.readline(), end=&quot;&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue
3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442
5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687
3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621
7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_filepaths
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;datasets/housing/my_train_00.csv&#39;,
 &#39;datasets/housing/my_train_01.csv&#39;,
 &#39;datasets/housing/my_train_02.csv&#39;,
 &#39;datasets/housing/my_train_03.csv&#39;,
 &#39;datasets/housing/my_train_04.csv&#39;,
 &#39;datasets/housing/my_train_05.csv&#39;,
 &#39;datasets/housing/my_train_06.csv&#39;,
 &#39;datasets/housing/my_train_07.csv&#39;,
 &#39;datasets/housing/my_train_08.csv&#39;,
 &#39;datasets/housing/my_train_09.csv&#39;,
 &#39;datasets/housing/my_train_10.csv&#39;,
 &#39;datasets/housing/my_train_11.csv&#39;,
 &#39;datasets/housing/my_train_12.csv&#39;,
 &#39;datasets/housing/my_train_13.csv&#39;,
 &#39;datasets/housing/my_train_14.csv&#39;,
 &#39;datasets/housing/my_train_15.csv&#39;,
 &#39;datasets/housing/my_train_16.csv&#39;,
 &#39;datasets/housing/my_train_17.csv&#39;,
 &#39;datasets/housing/my_train_18.csv&#39;,
 &#39;datasets/housing/my_train_19.csv&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="building-an-input-pipeline">
<h2>Building an Input Pipeline<a class="headerlink" href="#building-an-input-pipeline" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for filepath in filepath_dataset:
    print(filepath)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(b&#39;datasets/housing/my_train_15.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_08.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_03.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_01.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_10.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_05.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_19.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_16.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_02.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_09.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_00.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_07.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_12.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_04.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_17.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_11.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_14.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_18.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_06.csv&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;datasets/housing/my_train_13.csv&#39;, shape=(), dtype=string)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_readers = 5
dataset = filepath_dataset.interleave(
    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),
    cycle_length=n_readers)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for line in dataset.take(5):
    print(line.numpy())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b&#39;4.6477,38.0,5.03728813559322,0.911864406779661,745.0,2.5254237288135593,32.64,-117.07,1.504&#39;
b&#39;8.72,44.0,6.163179916317992,1.0460251046025104,668.0,2.794979079497908,34.2,-118.18,4.159&#39;
b&#39;3.8456,35.0,5.461346633416459,0.9576059850374065,1154.0,2.8778054862842892,37.96,-122.05,1.598&#39;
b&#39;3.3456,37.0,4.514084507042254,0.9084507042253521,458.0,3.2253521126760565,36.67,-121.7,2.526&#39;
b&#39;3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625&#39;
</pre></div>
</div>
</div>
</div>
<p>Notice that field 4 is interpreted as a string.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>record_defaults=[0, np.nan, tf.constant(np.nan, dtype=tf.float64), &quot;Hello&quot;, tf.constant([])]
parsed_fields = tf.io.decode_csv(&#39;1,2,3,4,5&#39;, record_defaults)
parsed_fields
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;,
 &lt;tf.Tensor: shape=(), dtype=float32, numpy=2.0&gt;,
 &lt;tf.Tensor: shape=(), dtype=float64, numpy=3.0&gt;,
 &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;4&#39;&gt;,
 &lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;]
</pre></div>
</div>
</div>
</div>
<p>Notice that all missing fields are replaced with their default value, when provided:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_fields = tf.io.decode_csv(&#39;,,,,5&#39;, record_defaults)
parsed_fields
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;,
 &lt;tf.Tensor: shape=(), dtype=float32, numpy=nan&gt;,
 &lt;tf.Tensor: shape=(), dtype=float64, numpy=nan&gt;,
 &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;Hello&#39;&gt;,
 &lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;]
</pre></div>
</div>
</div>
</div>
<p>The 5th field is compulsory (since we provided <code class="docutils literal notranslate"><span class="pre">tf.constant([])</span></code> as the “default value”), so we get an exception if we do not provide it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>try:
    parsed_fields = tf.io.decode_csv(&#39;,,,,&#39;, record_defaults)
except tf.errors.InvalidArgumentError as ex:
    print(ex)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Field 4 is required but missing in record 0! [Op:DecodeCSV]
</pre></div>
</div>
</div>
</div>
<p>The number of fields should match exactly the number of fields in the <code class="docutils literal notranslate"><span class="pre">record_defaults</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>try:
    parsed_fields = tf.io.decode_csv(&#39;1,2,3,4,5,6,7&#39;, record_defaults)
except tf.errors.InvalidArgumentError as ex:
    print(ex)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Expect 5 fields but have 7 in record 0 [Op:DecodeCSV]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_inputs = 8 # X_train.shape[-1]

@tf.function
def preprocess(line):
    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]
    fields = tf.io.decode_csv(line, record_defaults=defs)
    x = tf.stack(fields[:-1])
    y = tf.stack(fields[-1:])
    return (x - X_mean) / X_std, y
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>preprocess(b&#39;4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782&#39;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;tf.Tensor: shape=(8,), dtype=float32, numpy=
 array([ 0.16579157,  1.216324  , -0.05204565, -0.39215982, -0.5277444 ,
        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)&gt;,
 &lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def csv_reader_dataset(filepaths, repeat=1, n_readers=5,
                       n_read_threads=None, shuffle_buffer_size=10000,
                       n_parse_threads=5, batch_size=32):
    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)
    dataset = dataset.interleave(
        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),
        cycle_length=n_readers, num_parallel_calls=n_read_threads)
    dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)
    dataset = dataset.batch(batch_size)
    return dataset.prefetch(1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tf.random.set_seed(42)

train_set = csv_reader_dataset(train_filepaths, batch_size=3)
for X_batch, y_batch in train_set.take(2):
    print(&quot;X =&quot;, X_batch)
    print(&quot;y =&quot;, y_batch)
    print()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X = tf.Tensor(
[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472
   1.2525111  -1.3671792 ]
 [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987
   0.7231292  -1.0023477 ]
 [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365
  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)
y = tf.Tensor(
[[1.752]
 [1.313]
 [1.535]], shape=(3, 1), dtype=float32)

X = tf.Tensor(
[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526
   0.9807942  -0.67250353]
 [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751
   1.107282   -0.8674123 ]
 [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953
  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)
y = tf.Tensor(
[[0.919]
 [1.028]
 [2.182]], shape=(3, 1), dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_set = csv_reader_dataset(train_filepaths, repeat=None)
valid_set = csv_reader_dataset(valid_filepaths)
test_set = csv_reader_dataset(test_filepaths)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

model = keras.models.Sequential([
    keras.layers.Dense(30, activation=&quot;relu&quot;, input_shape=X_train.shape[1:]),
    keras.layers.Dense(1),
])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.compile(loss=&quot;mse&quot;, optimizer=keras.optimizers.SGD(learning_rate=1e-3))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>batch_size = 32
model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,
          validation_data=valid_set)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
362/362 [==============================] - 1s 3ms/step - loss: 2.0914 - val_loss: 21.5124
Epoch 2/10
362/362 [==============================] - 0s 1ms/step - loss: 0.8428 - val_loss: 0.6648
Epoch 3/10
362/362 [==============================] - 0s 1ms/step - loss: 0.6329 - val_loss: 0.6196
Epoch 4/10
362/362 [==============================] - 0s 1ms/step - loss: 0.5922 - val_loss: 0.5669
Epoch 5/10
362/362 [==============================] - 0s 1ms/step - loss: 0.5622 - val_loss: 0.5402
Epoch 6/10
362/362 [==============================] - 0s 1ms/step - loss: 0.5698 - val_loss: 0.5209
Epoch 7/10
362/362 [==============================] - 0s 1ms/step - loss: 0.5195 - val_loss: 0.6130
Epoch 8/10
362/362 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.4818
Epoch 9/10
362/362 [==============================] - 0s 1ms/step - loss: 0.4965 - val_loss: 0.4904
Epoch 10/10
362/362 [==============================] - 0s 1ms/step - loss: 0.4925 - val_loss: 0.4585
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fd68051ec50&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.evaluate(test_set, steps=len(X_test) // batch_size)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>161/161 [==============================] - 0s 589us/step - loss: 0.4788
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.4787752032279968
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>new_set = test_set.map(lambda X, y: X) # we could instead just pass test_set, Keras would ignore the labels
X_new = X_test
model.predict(new_set, steps=len(X_new) // batch_size)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[2.3576407],
       [2.255291 ],
       [1.4437605],
       ...,
       [0.5654393],
       [3.9442453],
       [1.0232248]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>optimizer = keras.optimizers.Nadam(learning_rate=0.01)
loss_fn = keras.losses.mean_squared_error

n_epochs = 5
batch_size = 32
n_steps_per_epoch = len(X_train) // batch_size
total_steps = n_epochs * n_steps_per_epoch
global_step = 0
for X_batch, y_batch in train_set.take(total_steps):
    global_step += 1
    print(&quot;\rGlobal step {}/{}&quot;.format(global_step, total_steps), end=&quot;&quot;)
    with tf.GradientTape() as tape:
        y_pred = model(X_batch)
        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))
        loss = tf.add_n([main_loss] + model.losses)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Global step 1810/1810
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>optimizer = keras.optimizers.Nadam(learning_rate=0.01)
loss_fn = keras.losses.mean_squared_error

@tf.function
def train(model, n_epochs, batch_size=32,
          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):
    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,
                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,
                       n_parse_threads=n_parse_threads, batch_size=batch_size)
    for X_batch, y_batch in train_set:
        with tf.GradientTape() as tape:
            y_pred = model(X_batch)
            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))
            loss = tf.add_n([main_loss] + model.losses)
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))

train(model, 5)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>optimizer = keras.optimizers.Nadam(learning_rate=0.01)
loss_fn = keras.losses.mean_squared_error

@tf.function
def train(model, n_epochs, batch_size=32,
          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):
    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,
                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,
                       n_parse_threads=n_parse_threads, batch_size=batch_size)
    n_steps_per_epoch = len(X_train) // batch_size
    total_steps = n_epochs * n_steps_per_epoch
    global_step = 0
    for X_batch, y_batch in train_set.take(total_steps):
        global_step += 1
        if tf.equal(global_step % 100, 0):
            tf.print(&quot;\rGlobal step&quot;, global_step, &quot;/&quot;, total_steps)
        with tf.GradientTape() as tape:
            y_pred = model(X_batch)
            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))
            loss = tf.add_n([main_loss] + model.losses)
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))

train(model, 5)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Global step 100 / 1810
Global step 200 / 1810
Global step 300 / 1810
Global step 400 / 1810
Global step 500 / 1810
Global step 600 / 1810
Global step 700 / 1810
Global step 800 / 1810
Global step 900 / 1810
Global step 1000 / 1810
Global step 1100 / 1810
Global step 1200 / 1810
Global step 1300 / 1810
Global step 1400 / 1810
Global step 1500 / 1810
Global step 1600 / 1810
Global step 1700 / 1810
Global step 1800 / 1810
</pre></div>
</div>
</div>
</div>
<p>Here is a short description of each method in the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for m in dir(tf.data.Dataset):
    if not (m.startswith(&quot;_&quot;) or m.endswith(&quot;_&quot;)):
        func = getattr(tf.data.Dataset, m)
        if hasattr(func, &quot;__doc__&quot;):
            print(&quot;● {:21s}{}&quot;.format(m + &quot;()&quot;, func.__doc__.split(&quot;\n&quot;)[0]))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>● apply()              Applies a transformation function to this dataset.
● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.
● batch()              Combines consecutive elements of this dataset into batches.
● cache()              Caches the elements in this dataset.
● cardinality()        Returns the cardinality of the dataset, if known.
● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.
● element_spec()       The type specification of an element of this dataset.
● enumerate()          Enumerates the elements of this dataset.
● filter()             Filters this dataset according to `predicate`.
● flat_map()           Maps `map_func` across this dataset and flattens the result.
● from_generator()     Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)
● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.
● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.
● interleave()         Maps `map_func` across this dataset, and interleaves the results.
● list_files()         A dataset of all files matching one or more glob patterns.
● map()                Maps `map_func` across the elements of this dataset.
● options()            Returns the options for this dataset and its inputs.
● padded_batch()       Combines consecutive elements of this dataset into padded batches.
● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.
● range()              Creates a `Dataset` of a step-separated range of values.
● reduce()             Reduces the input dataset to a single element.
● repeat()             Repeats this dataset so each original value is seen `count` times.
● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.
● shuffle()            Randomly shuffles the elements of this dataset.
● skip()               Creates a `Dataset` that skips `count` elements from this dataset.
● take()               Creates a `Dataset` with at most `count` elements from this dataset.
● unbatch()            Splits elements of a dataset into multiple elements.
● window()             Combines (nests of) input elements into a dataset of (nests of) windows.
● with_options()       Returns a new `tf.data.Dataset` with the given options set.
● zip()                Creates a `Dataset` by zipping together the given datasets.
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-tfrecord-binary-format">
<h2>The <code class="docutils literal notranslate"><span class="pre">TFRecord</span></code> binary format<a class="headerlink" href="#the-tfrecord-binary-format" title="Permalink to this headline">#</a></h2>
<p>A TFRecord file is just a list of binary records. You can create one using a <code class="docutils literal notranslate"><span class="pre">tf.io.TFRecordWriter</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with tf.io.TFRecordWriter(&quot;my_data.tfrecord&quot;) as f:
    f.write(b&quot;This is the first record&quot;)
    f.write(b&quot;And this is the second record&quot;)
</pre></div>
</div>
</div>
</div>
<p>And you can read it using a <code class="docutils literal notranslate"><span class="pre">tf.data.TFRecordDataset</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>filepaths = [&quot;my_data.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filepaths)
for item in dataset:
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(b&#39;This is the first record&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;And this is the second record&#39;, shape=(), dtype=string)
</pre></div>
</div>
</div>
</div>
<p>You can read multiple TFRecord files with just one <code class="docutils literal notranslate"><span class="pre">TFRecordDataset</span></code>. By default it will read them one at a time, but if you set <code class="docutils literal notranslate"><span class="pre">num_parallel_reads=3</span></code>, it will read 3 at a time in parallel and interleave their records:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>filepaths = [&quot;my_test_{}.tfrecord&quot;.format(i) for i in range(5)]
for i, filepath in enumerate(filepaths):
    with tf.io.TFRecordWriter(filepath) as f:
        for j in range(3):
            f.write(&quot;File {} record {}&quot;.format(i, j).encode(&quot;utf-8&quot;))

dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=3)
for item in dataset:
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(b&#39;File 0 record 0&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 1 record 0&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 2 record 0&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 0 record 1&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 1 record 1&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 2 record 1&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 0 record 2&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 1 record 2&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 2 record 2&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 3 record 0&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 4 record 0&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 3 record 1&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 4 record 1&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 3 record 2&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;File 4 record 2&#39;, shape=(), dtype=string)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>options = tf.io.TFRecordOptions(compression_type=&quot;GZIP&quot;)
with tf.io.TFRecordWriter(&quot;my_compressed.tfrecord&quot;, options) as f:
    f.write(b&quot;This is the first record&quot;)
    f.write(b&quot;And this is the second record&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset = tf.data.TFRecordDataset([&quot;my_compressed.tfrecord&quot;],
                                  compression_type=&quot;GZIP&quot;)
for item in dataset:
    print(item)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(b&#39;This is the first record&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;And this is the second record&#39;, shape=(), dtype=string)
</pre></div>
</div>
</div>
</div>
<section id="a-brief-intro-to-protocol-buffers">
<h3>A Brief Intro to Protocol Buffers<a class="headerlink" href="#a-brief-intro-to-protocol-buffers" title="Permalink to this headline">#</a></h3>
<p>For this section you need to <a class="reference external" href="https://developers.google.com/protocol-buffers/docs/downloads">install protobuf</a>. In general you will not have to do so when using TensorFlow, as it comes with functions to create and parse protocol buffers of type <code class="docutils literal notranslate"><span class="pre">tf.train.Example</span></code>, which are generally sufficient. However, in this section we will learn about protocol buffers by creating our own simple protobuf definition, so we need the protobuf compiler (<code class="docutils literal notranslate"><span class="pre">protoc</span></code>): we will use it to compile the protobuf definition to a Python module that we can then use in our code.</p>
<p>First let’s write a simple protobuf definition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%writefile person.proto
syntax = &quot;proto3&quot;;
message Person {
  string name = 1;
  int32 id = 2;
  repeated string email = 3;
}
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting person.proto
</pre></div>
</div>
</div>
</div>
<p>And let’s compile it (the <code class="docutils literal notranslate"><span class="pre">--descriptor_set_out</span></code> and <code class="docutils literal notranslate"><span class="pre">--include_imports</span></code> options are only required for the <code class="docutils literal notranslate"><span class="pre">tf.io.decode_proto()</span></code> example below):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!ls person*
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>person.desc   person.proto  person_pb2.py
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from person_pb2 import Person

person = Person(name=&quot;Al&quot;, id=123, email=[&quot;a@b.com&quot;])  # create a Person
print(person)  # display the Person
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>name: &quot;Al&quot;
id: 123
email: &quot;a@b.com&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>person.name  # read a field
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Al&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>person.name = &quot;Alice&quot;  # modify a field
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>person.email[0]  # repeated fields can be accessed like arrays
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;a@b.com&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>person.email.append(&quot;c@d.com&quot;)  # add an email address
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>s = person.SerializeToString()  # serialize to a byte string
s
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>b&#39;\n\x05Alice\x10{\x1a\x07a@b.com\x1a\x07c@d.com&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>person2 = Person()  # create a new Person
person2.ParseFromString(s)  # parse the byte string (27 bytes)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>27
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>person == person2  # now they are equal
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<section id="custom-protobuf">
<h4>Custom protobuf<a class="headerlink" href="#custom-protobuf" title="Permalink to this headline">#</a></h4>
<p>In rare cases, you may want to parse a custom protobuf (like the one we just created) in TensorFlow. For this you can use the <code class="docutils literal notranslate"><span class="pre">tf.io.decode_proto()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>person_tf = tf.io.decode_proto(
    bytes=s,
    message_type=&quot;Person&quot;,
    field_names=[&quot;name&quot;, &quot;id&quot;, &quot;email&quot;],
    output_types=[tf.string, tf.int32, tf.string],
    descriptor_source=&quot;person.desc&quot;)

person_tf.values
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Tensor: shape=(1,), dtype=string, numpy=array([b&#39;Alice&#39;], dtype=object)&gt;,
 &lt;tf.Tensor: shape=(1,), dtype=int32, numpy=array([123], dtype=int32)&gt;,
 &lt;tf.Tensor: shape=(2,), dtype=string, numpy=array([b&#39;a@b.com&#39;, b&#39;c@d.com&#39;], dtype=object)&gt;]
</pre></div>
</div>
</div>
</div>
<p>For more details, see the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/io/decode_proto"><code class="docutils literal notranslate"><span class="pre">tf.io.decode_proto()</span></code></a> documentation.</p>
</section>
</section>
<section id="tensorflow-protobufs">
<h3>TensorFlow Protobufs<a class="headerlink" href="#tensorflow-protobufs" title="Permalink to this headline">#</a></h3>
<p>Here is the definition of the tf.train.Example protobuf:</p>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="k">syntax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;proto3&quot;</span><span class="p">;</span>

<span class="kd">message</span><span class="w"> </span><span class="nc">BytesList</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">repeated</span><span class="w"> </span><span class="kt">bytes</span><span class="w"> </span><span class="na">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="kd">message</span><span class="w"> </span><span class="nc">FloatList</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">repeated</span><span class="w"> </span><span class="kt">float</span><span class="w"> </span><span class="na">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">[</span><span class="k">packed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">];</span><span class="w"> </span><span class="p">}</span>
<span class="kd">message</span><span class="w"> </span><span class="nc">Int64List</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">repeated</span><span class="w"> </span><span class="kt">int64</span><span class="w"> </span><span class="na">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="p">[</span><span class="k">packed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">true</span><span class="p">];</span><span class="w"> </span><span class="p">}</span>
<span class="kd">message</span><span class="w"> </span><span class="nc">Feature</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">oneof</span><span class="w"> </span><span class="n">kind</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">BytesList</span><span class="w"> </span><span class="na">bytes_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">        </span><span class="n">FloatList</span><span class="w"> </span><span class="na">float_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">        </span><span class="n">Int64List</span><span class="w"> </span><span class="na">int64_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">};</span>
<span class="kd">message</span><span class="w"> </span><span class="nc">Features</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">map</span><span class="p">&lt;</span><span class="kt">string</span><span class="p">,</span><span class="w"> </span><span class="n">Feature</span><span class="p">&gt;</span><span class="w"> </span><span class="na">feature</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="p">};</span>
<span class="kd">message</span><span class="w"> </span><span class="nc">Example</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">Features</span><span class="w"> </span><span class="na">features</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="p">};</span>
</pre></div>
</div>
<p><strong>Warning</strong>: in TensorFlow 2.0 and 2.1, there was a bug preventing <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">tensorflow.train</span> <span class="pre">import</span> <span class="pre">X</span></code> so we work around it by writing <code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">tf.train.X</span></code>. See <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues/33289">https://github.com/tensorflow/tensorflow/issues/33289</a> for more details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>#from tensorflow.train import BytesList, FloatList, Int64List
#from tensorflow.train import Feature, Features, Example
BytesList = tf.train.BytesList
FloatList = tf.train.FloatList
Int64List = tf.train.Int64List
Feature = tf.train.Feature
Features = tf.train.Features
Example = tf.train.Example

person_example = Example(
    features=Features(
        feature={
            &quot;name&quot;: Feature(bytes_list=BytesList(value=[b&quot;Alice&quot;])),
            &quot;id&quot;: Feature(int64_list=Int64List(value=[123])),
            &quot;emails&quot;: Feature(bytes_list=BytesList(value=[b&quot;a@b.com&quot;, b&quot;c@d.com&quot;]))
        }))

with tf.io.TFRecordWriter(&quot;my_contacts.tfrecord&quot;) as f:
    f.write(person_example.SerializeToString())
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>feature_description = {
    &quot;name&quot;: tf.io.FixedLenFeature([], tf.string, default_value=&quot;&quot;),
    &quot;id&quot;: tf.io.FixedLenFeature([], tf.int64, default_value=0),
    &quot;emails&quot;: tf.io.VarLenFeature(tf.string),
}
for serialized_example in tf.data.TFRecordDataset([&quot;my_contacts.tfrecord&quot;]):
    parsed_example = tf.io.parse_single_example(serialized_example,
                                                feature_description)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_example
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;emails&#39;: &lt;tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fd640710890&gt;,
 &#39;id&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=123&gt;,
 &#39;name&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;Alice&#39;&gt;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_example
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;emails&#39;: &lt;tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fd640710890&gt;,
 &#39;id&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=123&gt;,
 &#39;name&#39;: &lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;Alice&#39;&gt;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_example[&quot;emails&quot;].values[0]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;a@b.com&#39;&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tf.sparse.to_dense(parsed_example[&quot;emails&quot;], default_value=b&quot;&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2,), dtype=string, numpy=array([b&#39;a@b.com&#39;, b&#39;c@d.com&#39;], dtype=object)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_example[&quot;emails&quot;].values
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2,), dtype=string, numpy=array([b&#39;a@b.com&#39;, b&#39;c@d.com&#39;], dtype=object)&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="putting-images-in-tfrecords">
<h3>Putting Images in TFRecords<a class="headerlink" href="#putting-images-in-tfrecords" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.datasets import load_sample_images

img = load_sample_images()[&quot;images&quot;][0]
plt.imshow(img)
plt.axis(&quot;off&quot;)
plt.title(&quot;Original Image&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/13_loading_and_preprocessing_data_97_0.png" src="../../_images/13_loading_and_preprocessing_data_97_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>data = tf.io.encode_jpeg(img)
example_with_image = Example(features=Features(feature={
    &quot;image&quot;: Feature(bytes_list=BytesList(value=[data.numpy()]))}))
serialized_example = example_with_image.SerializeToString()
# then save to TFRecord
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>feature_description = { &quot;image&quot;: tf.io.VarLenFeature(tf.string) }
example_with_image = tf.io.parse_single_example(serialized_example, feature_description)
decoded_img = tf.io.decode_jpeg(example_with_image[&quot;image&quot;].values[0])
</pre></div>
</div>
</div>
</div>
<p>Or use <code class="docutils literal notranslate"><span class="pre">decode_image()</span></code> which supports BMP, GIF, JPEG and PNG formats:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>decoded_img = tf.io.decode_image(example_with_image[&quot;image&quot;].values[0])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.imshow(decoded_img)
plt.title(&quot;Decoded Image&quot;)
plt.axis(&quot;off&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/13_loading_and_preprocessing_data_102_0.png" src="../../_images/13_loading_and_preprocessing_data_102_0.png" />
</div>
</div>
</section>
<section id="putting-tensors-and-sparse-tensors-in-tfrecords">
<h3>Putting Tensors and Sparse Tensors in TFRecords<a class="headerlink" href="#putting-tensors-and-sparse-tensors-in-tfrecords" title="Permalink to this headline">#</a></h3>
<p>Tensors can be serialized and parsed easily using <code class="docutils literal notranslate"><span class="pre">tf.io.serialize_tensor()</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.io.parse_tensor()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>t = tf.constant([[0., 1.], [2., 3.], [4., 5.]])
s = tf.io.serialize_tensor(t)
s
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(), dtype=string, numpy=b&#39;\x08\x01\x12\x08\x12\x02\x08\x03\x12\x02\x08\x02&quot;\x18\x00\x00\x00\x00\x00\x00\x80?\x00\x00\x00@\x00\x00@@\x00\x00\x80@\x00\x00\xa0@&#39;&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tf.io.parse_tensor(s, out_type=tf.float32)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(3, 2), dtype=float32, numpy=
array([[0., 1.],
       [2., 3.],
       [4., 5.]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>serialized_sparse = tf.io.serialize_sparse(parsed_example[&quot;emails&quot;])
serialized_sparse
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(3,), dtype=string, numpy=
array([b&#39;\x08\t\x12\x08\x12\x02\x08\x02\x12\x02\x08\x01&quot;\x10\x00\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00&#39;,
       b&#39;\x08\x07\x12\x04\x12\x02\x08\x02&quot;\x10\x07\x07a@b.comc@d.com&#39;,
       b&#39;\x08\t\x12\x04\x12\x02\x08\x01&quot;\x08\x02\x00\x00\x00\x00\x00\x00\x00&#39;],
      dtype=object)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>BytesList(value=serialized_sparse.numpy())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>value: &quot;\010\t\022\010\022\002\010\002\022\002\010\001\&quot;\020\000\000\000\000\000\000\000\000\001\000\000\000\000\000\000\000&quot;
value: &quot;\010\007\022\004\022\002\010\002\&quot;\020\007\007a@b.comc@d.com&quot;
value: &quot;\010\t\022\004\022\002\010\001\&quot;\010\002\000\000\000\000\000\000\000&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>dataset = tf.data.TFRecordDataset([&quot;my_contacts.tfrecord&quot;]).batch(10)
for serialized_examples in dataset:
    parsed_examples = tf.io.parse_example(serialized_examples,
                                          feature_description)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_examples
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;image&#39;: &lt;tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fd6406f5d50&gt;}
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="handling-sequential-data-using-sequenceexample">
<h2>Handling Sequential Data Using <code class="docutils literal notranslate"><span class="pre">SequenceExample</span></code><a class="headerlink" href="#handling-sequential-data-using-sequenceexample" title="Permalink to this headline">#</a></h2>
<div class="highlight-proto notranslate"><div class="highlight"><pre><span></span><span class="k">syntax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;proto3&quot;</span><span class="p">;</span>

<span class="kd">message</span><span class="w"> </span><span class="nc">FeatureList</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">repeated</span><span class="w"> </span><span class="n">Feature</span><span class="w"> </span><span class="na">feature</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="p">};</span>
<span class="kd">message</span><span class="w"> </span><span class="nc">FeatureLists</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">map</span><span class="p">&lt;</span><span class="kt">string</span><span class="p">,</span><span class="w"> </span><span class="n">FeatureList</span><span class="p">&gt;</span><span class="w"> </span><span class="na">feature_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="p">};</span>
<span class="kd">message</span><span class="w"> </span><span class="nc">SequenceExample</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">Features</span><span class="w"> </span><span class="na">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="n">FeatureLists</span><span class="w"> </span><span class="na">feature_lists</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
<p><strong>Warning</strong>: in TensorFlow 2.0 and 2.1, there was a bug preventing <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">tensorflow.train</span> <span class="pre">import</span> <span class="pre">X</span></code> so we work around it by writing <code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">tf.train.X</span></code>. See <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues/33289">https://github.com/tensorflow/tensorflow/issues/33289</a> for more details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>#from tensorflow.train import FeatureList, FeatureLists, SequenceExample
FeatureList = tf.train.FeatureList
FeatureLists = tf.train.FeatureLists
SequenceExample = tf.train.SequenceExample

context = Features(feature={
    &quot;author_id&quot;: Feature(int64_list=Int64List(value=[123])),
    &quot;title&quot;: Feature(bytes_list=BytesList(value=[b&quot;A&quot;, b&quot;desert&quot;, b&quot;place&quot;, b&quot;.&quot;])),
    &quot;pub_date&quot;: Feature(int64_list=Int64List(value=[1623, 12, 25]))
})

content = [[&quot;When&quot;, &quot;shall&quot;, &quot;we&quot;, &quot;three&quot;, &quot;meet&quot;, &quot;again&quot;, &quot;?&quot;],
           [&quot;In&quot;, &quot;thunder&quot;, &quot;,&quot;, &quot;lightning&quot;, &quot;,&quot;, &quot;or&quot;, &quot;in&quot;, &quot;rain&quot;, &quot;?&quot;]]
comments = [[&quot;When&quot;, &quot;the&quot;, &quot;hurlyburly&quot;, &quot;&#39;s&quot;, &quot;done&quot;, &quot;.&quot;],
            [&quot;When&quot;, &quot;the&quot;, &quot;battle&quot;, &quot;&#39;s&quot;, &quot;lost&quot;, &quot;and&quot;, &quot;won&quot;, &quot;.&quot;]]

def words_to_feature(words):
    return Feature(bytes_list=BytesList(value=[word.encode(&quot;utf-8&quot;)
                                               for word in words]))

content_features = [words_to_feature(sentence) for sentence in content]
comments_features = [words_to_feature(comment) for comment in comments]
            
sequence_example = SequenceExample(
    context=context,
    feature_lists=FeatureLists(feature_list={
        &quot;content&quot;: FeatureList(feature=content_features),
        &quot;comments&quot;: FeatureList(feature=comments_features)
    }))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sequence_example
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>context {
  feature {
    key: &quot;author_id&quot;
    value {
      int64_list {
        value: 123
      }
    }
  }
  feature {
    key: &quot;pub_date&quot;
    value {
      int64_list {
        value: 1623
        value: 12
        value: 25
      }
    }
  }
  feature {
    key: &quot;title&quot;
    value {
      bytes_list {
        value: &quot;A&quot;
        value: &quot;desert&quot;
        value: &quot;place&quot;
        value: &quot;.&quot;
      }
    }
  }
}
feature_lists {
  feature_list {
    key: &quot;comments&quot;
    value {
      feature {
        bytes_list {
          value: &quot;When&quot;
          value: &quot;the&quot;
          value: &quot;hurlyburly&quot;
          value: &quot;\&#39;s&quot;
          value: &quot;done&quot;
          value: &quot;.&quot;
        }
      }
      feature {
        bytes_list {
          value: &quot;When&quot;
          value: &quot;the&quot;
          value: &quot;battle&quot;
          value: &quot;\&#39;s&quot;
          value: &quot;lost&quot;
          value: &quot;and&quot;
          value: &quot;won&quot;
          value: &quot;.&quot;
        }
      }
    }
  }
  feature_list {
    key: &quot;content&quot;
    value {
      feature {
        bytes_list {
          value: &quot;When&quot;
          value: &quot;shall&quot;
          value: &quot;we&quot;
          value: &quot;three&quot;
          value: &quot;meet&quot;
          value: &quot;again&quot;
          value: &quot;?&quot;
        }
      }
      feature {
        bytes_list {
          value: &quot;In&quot;
          value: &quot;thunder&quot;
          value: &quot;,&quot;
          value: &quot;lightning&quot;
          value: &quot;,&quot;
          value: &quot;or&quot;
          value: &quot;in&quot;
          value: &quot;rain&quot;
          value: &quot;?&quot;
        }
      }
    }
  }
}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>serialized_sequence_example = sequence_example.SerializeToString()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>context_feature_descriptions = {
    &quot;author_id&quot;: tf.io.FixedLenFeature([], tf.int64, default_value=0),
    &quot;title&quot;: tf.io.VarLenFeature(tf.string),
    &quot;pub_date&quot;: tf.io.FixedLenFeature([3], tf.int64, default_value=[0, 0, 0]),
}
sequence_feature_descriptions = {
    &quot;content&quot;: tf.io.VarLenFeature(tf.string),
    &quot;comments&quot;: tf.io.VarLenFeature(tf.string),
}
parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(
    serialized_sequence_example, context_feature_descriptions,
    sequence_feature_descriptions)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_context
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;title&#39;: &lt;tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fd621092610&gt;,
 &#39;author_id&#39;: &lt;tf.Tensor: shape=(), dtype=int64, numpy=123&gt;,
 &#39;pub_date&#39;: &lt;tf.Tensor: shape=(3,), dtype=int64, numpy=array([1623,   12,   25])&gt;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_context[&quot;title&quot;].values
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(4,), dtype=string, numpy=array([b&#39;A&#39;, b&#39;desert&#39;, b&#39;place&#39;, b&#39;.&#39;], dtype=object)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>parsed_feature_lists
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;comments&#39;: &lt;tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fd621092790&gt;,
 &#39;content&#39;: &lt;tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fd621092b50&gt;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(tf.RaggedTensor.from_sparse(parsed_feature_lists[&quot;content&quot;]))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.RaggedTensor [[b&#39;When&#39;, b&#39;shall&#39;, b&#39;we&#39;, b&#39;three&#39;, b&#39;meet&#39;, b&#39;again&#39;, b&#39;?&#39;], [b&#39;In&#39;, b&#39;thunder&#39;, b&#39;,&#39;, b&#39;lightning&#39;, b&#39;,&#39;, b&#39;or&#39;, b&#39;in&#39;, b&#39;rain&#39;, b&#39;?&#39;]]&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="the-features-api">
<h1>The Features API<a class="headerlink" href="#the-features-api" title="Permalink to this headline">#</a></h1>
<p>Let’s use the variant of the California housing dataset that we used in Chapter 2, since it contains categorical features and missing values:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import tarfile
import urllib.request

DOWNLOAD_ROOT = &quot;https://raw.githubusercontent.com/ageron/handson-ml2/master/&quot;
HOUSING_PATH = os.path.join(&quot;datasets&quot;, &quot;housing&quot;)
HOUSING_URL = DOWNLOAD_ROOT + &quot;datasets/housing/housing.tgz&quot;

def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):
    os.makedirs(housing_path, exist_ok=True)
    tgz_path = os.path.join(housing_path, &quot;housing.tgz&quot;)
    urllib.request.urlretrieve(housing_url, tgz_path)
    housing_tgz = tarfile.open(tgz_path)
    housing_tgz.extractall(path=housing_path)
    housing_tgz.close()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fetch_housing_data()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import pandas as pd

def load_housing_data(housing_path=HOUSING_PATH):
    csv_path = os.path.join(housing_path, &quot;housing.csv&quot;)
    return pd.read_csv(csv_path)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>housing = load_housing_data()
housing.head()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>housing_median_age = tf.feature_column.numeric_column(&quot;housing_median_age&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>age_mean, age_std = X_mean[1], X_std[1]  # The median age is column in 1
housing_median_age = tf.feature_column.numeric_column(
    &quot;housing_median_age&quot;, normalizer_fn=lambda x: (x - age_mean) / age_std)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>median_income = tf.feature_column.numeric_column(&quot;median_income&quot;)
bucketized_income = tf.feature_column.bucketized_column(
    median_income, boundaries=[1.5, 3., 4.5, 6.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>bucketized_income
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BucketizedColumn(source_column=NumericColumn(key=&#39;median_income&#39;, shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ocean_prox_vocab = [&#39;&lt;1H OCEAN&#39;, &#39;INLAND&#39;, &#39;ISLAND&#39;, &#39;NEAR BAY&#39;, &#39;NEAR OCEAN&#39;]
ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(
    &quot;ocean_proximity&quot;, ocean_prox_vocab)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ocean_proximity
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>VocabularyListCategoricalColumn(key=&#39;ocean_proximity&#39;, vocabulary_list=(&#39;&lt;1H OCEAN&#39;, &#39;INLAND&#39;, &#39;ISLAND&#39;, &#39;NEAR BAY&#39;, &#39;NEAR OCEAN&#39;), dtype=tf.string, default_value=-1, num_oov_buckets=0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Just an example, it&#39;s not used later on
city_hash = tf.feature_column.categorical_column_with_hash_bucket(
    &quot;city&quot;, hash_bucket_size=1000)
city_hash
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>HashedCategoricalColumn(key=&#39;city&#39;, hash_bucket_size=1000, dtype=tf.string)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>bucketized_age = tf.feature_column.bucketized_column(
    housing_median_age, boundaries=[-1., -0.5, 0., 0.5, 1.]) # age was scaled
age_and_ocean_proximity = tf.feature_column.crossed_column(
    [bucketized_age, ocean_proximity], hash_bucket_size=100)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>latitude = tf.feature_column.numeric_column(&quot;latitude&quot;)
longitude = tf.feature_column.numeric_column(&quot;longitude&quot;)
bucketized_latitude = tf.feature_column.bucketized_column(
    latitude, boundaries=list(np.linspace(32., 42., 20 - 1)))
bucketized_longitude = tf.feature_column.bucketized_column(
    longitude, boundaries=list(np.linspace(-125., -114., 20 - 1)))
location = tf.feature_column.crossed_column(
    [bucketized_latitude, bucketized_longitude], hash_bucket_size=1000)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ocean_proximity_one_hot = tf.feature_column.indicator_column(ocean_proximity)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>ocean_proximity_embed = tf.feature_column.embedding_column(ocean_proximity,
                                                           dimension=2)
</pre></div>
</div>
</div>
</div>
<section id="using-feature-columns-for-parsing">
<h2>Using Feature Columns for Parsing<a class="headerlink" href="#using-feature-columns-for-parsing" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>median_house_value = tf.feature_column.numeric_column(&quot;median_house_value&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>columns = [housing_median_age, median_house_value]
feature_descriptions = tf.feature_column.make_parse_example_spec(columns)
feature_descriptions
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;housing_median_age&#39;: FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None),
 &#39;median_house_value&#39;: FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>with tf.io.TFRecordWriter(&quot;my_data_with_features.tfrecords&quot;) as f:
    for x, y in zip(X_train[:, 1:2], y_train):
        example = Example(features=Features(feature={
            &quot;housing_median_age&quot;: Feature(float_list=FloatList(value=[x])),
            &quot;median_house_value&quot;: Feature(float_list=FloatList(value=[y]))
        }))
        f.write(example.SerializeToString())
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def parse_examples(serialized_examples):
    examples = tf.io.parse_example(serialized_examples, feature_descriptions)
    targets = examples.pop(&quot;median_house_value&quot;) # separate the targets
    return examples, targets

batch_size = 32
dataset = tf.data.TFRecordDataset([&quot;my_data_with_features.tfrecords&quot;])
dataset = dataset.repeat().shuffle(10000).batch(batch_size).map(parse_examples)
</pre></div>
</div>
</div>
</div>
<p><strong>Warning</strong>: the <code class="docutils literal notranslate"><span class="pre">DenseFeatures</span></code> layer currently does not work with the Functional API, see <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues/27416">TF issue #27416</a>. Hopefully this will be resolved before the final release of TF 2.0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>columns_without_target = columns[:-1]
model = keras.models.Sequential([
    keras.layers.DenseFeatures(feature_columns=columns_without_target),
    keras.layers.Dense(1)
])
model.compile(loss=&quot;mse&quot;,
              optimizer=keras.optimizers.SGD(learning_rate=1e-3),
              metrics=[&quot;accuracy&quot;])
model.fit(dataset, steps_per_epoch=len(X_train) // batch_size, epochs=5)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;housing_median_age&#39;: &lt;tf.Tensor &#39;IteratorGetNext:0&#39; shape=(None, 1) dtype=float32&gt;}
Consider rewriting this model with the Functional API.
WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a &lt;class &#39;dict&#39;&gt; input: {&#39;housing_median_age&#39;: &lt;tf.Tensor &#39;IteratorGetNext:0&#39; shape=(None, 1) dtype=float32&gt;}
Consider rewriting this model with the Functional API.
362/362 [==============================] - 0s 675us/step - loss: 4.7553 - accuracy: 8.8428e-04
Epoch 2/5
362/362 [==============================] - 0s 622us/step - loss: 2.1622 - accuracy: 0.0021
Epoch 3/5
362/362 [==============================] - 0s 583us/step - loss: 1.4673 - accuracy: 0.0032
Epoch 4/5
362/362 [==============================] - 0s 543us/step - loss: 1.3786 - accuracy: 0.0033
Epoch 5/5
362/362 [==============================] - 0s 537us/step - loss: 1.3404 - accuracy: 0.0034
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fd532a6ffd0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>some_columns = [ocean_proximity_embed, bucketized_income]
dense_features = keras.layers.DenseFeatures(some_columns)
dense_features({
    &quot;ocean_proximity&quot;: [[&quot;NEAR OCEAN&quot;], [&quot;INLAND&quot;], [&quot;INLAND&quot;]],
    &quot;median_income&quot;: [[3.], [7.2], [1.]]
})
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(3, 7), dtype=float32, numpy=
array([[ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,
        -0.14504611,  0.7563394 ],
       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.        ,
        -1.1119912 ,  0.56957847],
       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        -1.1119912 ,  0.56957847]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="tf-transform">
<h1>TF Transform<a class="headerlink" href="#tf-transform" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>try:
    import tensorflow_transform as tft

    def preprocess(inputs):  # inputs is a batch of input features
        median_age = inputs[&quot;housing_median_age&quot;]
        ocean_proximity = inputs[&quot;ocean_proximity&quot;]
        standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))
        ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)
        return {
            &quot;standardized_median_age&quot;: standardized_age,
            &quot;ocean_proximity_id&quot;: ocean_proximity_id
        }
except ImportError:
    print(&quot;TF Transform is not installed. Try running: pip3 install -U tensorflow-transform&quot;)
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="tensorflow-datasets">
<h1>TensorFlow Datasets<a class="headerlink" href="#tensorflow-datasets" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import tensorflow_datasets as tfds

datasets = tfds.load(name=&quot;mnist&quot;)
mnist_train, mnist_test = datasets[&quot;train&quot;], datasets[&quot;test&quot;]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:absl:Found a different version of the requested dataset:
/Users/ageron/tensorflow_datasets/mnist/3.0.0
Using /Users/ageron/tensorflow_datasets/mnist/3.0.1 instead.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">Downloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/ageron/tensorflow_datasets/mnist/3.0.1...</span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your
local data directory. If you&#39;d instead prefer to read directly from our public
GCS bucket (recommended if you&#39;re running on GCP), you can instead set
data_dir=gs://tfds-data/datasets.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "766787dcfced4b7db1d4d66559378f1b", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">Dataset mnist downloaded and prepared to /Users/ageron/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(tfds.list_builders())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;abstract_reasoning&#39;, &#39;aeslc&#39;, &#39;aflw2k3d&#39;, &#39;amazon_us_reviews&#39;, &#39;arc&#39;, &#39;bair_robot_pushing_small&#39;, &#39;beans&#39;, &#39;big_patent&#39;, &#39;bigearthnet&#39;, &#39;billsum&#39;, &#39;binarized_mnist&#39;, &#39;binary_alpha_digits&#39;, &#39;blimp&#39;, &#39;c4&#39;, &#39;caltech101&#39;, &#39;caltech_birds2010&#39;, &#39;caltech_birds2011&#39;, &#39;cars196&#39;, &#39;cassava&#39;, &#39;cats_vs_dogs&#39;, &#39;celeb_a&#39;, &#39;celeb_a_hq&#39;, &#39;cfq&#39;, &#39;chexpert&#39;, &#39;cifar10&#39;, &#39;cifar100&#39;, &#39;cifar10_1&#39;, &#39;cifar10_corrupted&#39;, &#39;citrus_leaves&#39;, &#39;cityscapes&#39;, &#39;civil_comments&#39;, &#39;clevr&#39;, &#39;cmaterdb&#39;, &#39;cnn_dailymail&#39;, &#39;coco&#39;, &#39;coil100&#39;, &#39;colorectal_histology&#39;, &#39;colorectal_histology_large&#39;, &#39;common_voice&#39;, &#39;cos_e&#39;, &#39;crema_d&#39;, &#39;curated_breast_imaging_ddsm&#39;, &#39;cycle_gan&#39;, &#39;deep_weeds&#39;, &#39;definite_pronoun_resolution&#39;, &#39;dementiabank&#39;, &#39;diabetic_retinopathy_detection&#39;, &#39;div2k&#39;, &#39;dmlab&#39;, &#39;downsampled_imagenet&#39;, &#39;dsprites&#39;, &#39;dtd&#39;, &#39;duke_ultrasound&#39;, &#39;emnist&#39;, &#39;eraser_multi_rc&#39;, &#39;esnli&#39;, &#39;eurosat&#39;, &#39;fashion_mnist&#39;, &#39;flic&#39;, &#39;flores&#39;, &#39;food101&#39;, &#39;forest_fires&#39;, &#39;gap&#39;, &#39;geirhos_conflict_stimuli&#39;, &#39;german_credit_numeric&#39;, &#39;gigaword&#39;, &#39;glue&#39;, &#39;groove&#39;, &#39;higgs&#39;, &#39;horses_or_humans&#39;, &#39;i_naturalist2017&#39;, &#39;image_label_folder&#39;, &#39;imagenet2012&#39;, &#39;imagenet2012_corrupted&#39;, &#39;imagenet2012_subset&#39;, &#39;imagenet_resized&#39;, &#39;imagenette&#39;, &#39;imagewang&#39;, &#39;imdb_reviews&#39;, &#39;iris&#39;, &#39;kitti&#39;, &#39;kmnist&#39;, &#39;lfw&#39;, &#39;librispeech&#39;, &#39;librispeech_lm&#39;, &#39;libritts&#39;, &#39;ljspeech&#39;, &#39;lm1b&#39;, &#39;lost_and_found&#39;, &#39;lsun&#39;, &#39;malaria&#39;, &#39;math_dataset&#39;, &#39;mnist&#39;, &#39;mnist_corrupted&#39;, &#39;movie_rationales&#39;, &#39;moving_mnist&#39;, &#39;multi_news&#39;, &#39;multi_nli&#39;, &#39;multi_nli_mismatch&#39;, &#39;natural_questions&#39;, &#39;newsroom&#39;, &#39;nsynth&#39;, &#39;omniglot&#39;, &#39;open_images_challenge2019_detection&#39;, &#39;open_images_v4&#39;, &#39;opinosis&#39;, &#39;oxford_flowers102&#39;, &#39;oxford_iiit_pet&#39;, &#39;para_crawl&#39;, &#39;patch_camelyon&#39;, &#39;pet_finder&#39;, &#39;places365_small&#39;, &#39;plant_leaves&#39;, &#39;plant_village&#39;, &#39;plantae_k&#39;, &#39;qa4mre&#39;, &#39;quickdraw_bitmap&#39;, &#39;reddit&#39;, &#39;reddit_tifu&#39;, &#39;resisc45&#39;, &#39;robonet&#39;, &#39;rock_paper_scissors&#39;, &#39;rock_you&#39;, &#39;savee&#39;, &#39;scan&#39;, &#39;scene_parse150&#39;, &#39;scicite&#39;, &#39;scientific_papers&#39;, &#39;shapes3d&#39;, &#39;smallnorb&#39;, &#39;snli&#39;, &#39;so2sat&#39;, &#39;speech_commands&#39;, &#39;squad&#39;, &#39;stanford_dogs&#39;, &#39;stanford_online_products&#39;, &#39;starcraft_video&#39;, &#39;stl10&#39;, &#39;sun397&#39;, &#39;super_glue&#39;, &#39;svhn_cropped&#39;, &#39;ted_hrlr_translate&#39;, &#39;ted_multi_translate&#39;, &#39;tedlium&#39;, &#39;tf_flowers&#39;, &#39;the300w_lp&#39;, &#39;tiny_shakespeare&#39;, &#39;titanic&#39;, &#39;trivia_qa&#39;, &#39;uc_merced&#39;, &#39;ucf101&#39;, &#39;vgg_face2&#39;, &#39;visual_domain_decathlon&#39;, &#39;voc&#39;, &#39;voxceleb&#39;, &#39;waymo_open_dataset&#39;, &#39;web_questions&#39;, &#39;wider_face&#39;, &#39;wiki40b&#39;, &#39;wikihow&#39;, &#39;wikipedia&#39;, &#39;wmt14_translate&#39;, &#39;wmt15_translate&#39;, &#39;wmt16_translate&#39;, &#39;wmt17_translate&#39;, &#39;wmt18_translate&#39;, &#39;wmt19_translate&#39;, &#39;wmt_t2t_translate&#39;, &#39;wmt_translate&#39;, &#39;xnli&#39;, &#39;xsum&#39;, &#39;yelp_polarity_reviews&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.figure(figsize=(6,3))
mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)
for item in mnist_train:
    images = item[&quot;image&quot;]
    labels = item[&quot;label&quot;]
    for index in range(5):
        plt.subplot(1, 5, index + 1)
        image = images[index, ..., 0]
        label = labels[index].numpy()
        plt.imshow(image, cmap=&quot;binary&quot;)
        plt.title(label)
        plt.axis(&quot;off&quot;)
    break # just showing part of the first batch
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/13_loading_and_preprocessing_data_153_0.png" src="../../_images/13_loading_and_preprocessing_data_153_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>datasets = tfds.load(name=&quot;mnist&quot;)
mnist_train, mnist_test = datasets[&quot;train&quot;], datasets[&quot;test&quot;]
mnist_train = mnist_train.repeat(5).batch(32)
mnist_train = mnist_train.map(lambda items: (items[&quot;image&quot;], items[&quot;label&quot;]))
mnist_train = mnist_train.prefetch(1)
for images, labels in mnist_train.take(1):
    print(images.shape)
    print(labels.numpy())
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(32, 28, 28, 1)
[4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>datasets = tfds.load(name=&quot;mnist&quot;, batch_size=32, as_supervised=True)
mnist_train = datasets[&quot;train&quot;].repeat().prefetch(1)
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28, 1]),
    keras.layers.Lambda(lambda images: tf.cast(images, tf.float32)),
    keras.layers.Dense(10, activation=&quot;softmax&quot;)])
model.compile(loss=&quot;sparse_categorical_crossentropy&quot;,
              optimizer=keras.optimizers.SGD(learning_rate=1e-3),
              metrics=[&quot;accuracy&quot;])
model.fit(mnist_train, steps_per_epoch=60000 // 32, epochs=5)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
1875/1875 [==============================] - 2s 997us/step - loss: 42.8499 - accuracy: 0.8034
Epoch 2/5
1875/1875 [==============================] - 1s 481us/step - loss: 25.1669 - accuracy: 0.8687
Epoch 3/5
1875/1875 [==============================] - 1s 460us/step - loss: 24.1730 - accuracy: 0.8744
Epoch 4/5
1875/1875 [==============================] - 1s 446us/step - loss: 23.7216 - accuracy: 0.8760
Epoch 5/5
1875/1875 [==============================] - 1s 444us/step - loss: 23.1382 - accuracy: 0.8786
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fd515158c90&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="tensorflow-hub">
<h1>TensorFlow Hub<a class="headerlink" href="#tensorflow-hub" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import tensorflow_hub as hub

hub_layer = hub.KerasLayer(&quot;https://tfhub.dev/google/nnlm-en-dim50/2&quot;,
                           output_shape=[50], input_shape=[], dtype=tf.string)

model = keras.Sequential()
model.add(hub_layer)
model.add(keras.layers.Dense(16, activation=&#39;relu&#39;))
model.add(keras.layers.Dense(1, activation=&#39;sigmoid&#39;))

model.summary()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
keras_layer (KerasLayer)     (None, 50)                48190600  
_________________________________________________________________
dense (Dense)                (None, 16)                816       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 48,191,433
Trainable params: 833
Non-trainable params: 48,190,600
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sentences = tf.constant([&quot;It was a great movie&quot;, &quot;The actors were amazing&quot;])
embeddings = hub_layer(sentences)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>embeddings
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 50), dtype=float32, numpy=
array([[ 7.45939985e-02,  2.76720114e-02,  9.38646123e-02,
         1.25124469e-01,  5.40293928e-04, -1.09435350e-01,
         1.34755149e-01, -9.57818255e-02, -1.85177118e-01,
        -1.69703495e-02,  1.75612606e-02, -9.06603858e-02,
         1.12110220e-01,  1.04646273e-01,  3.87700424e-02,
        -7.71859884e-02, -3.12189370e-01,  6.99466765e-02,
        -4.88970093e-02, -2.99049795e-01,  1.31183028e-01,
        -2.12630898e-01,  6.96169436e-02,  1.63592950e-01,
         1.05169769e-02,  7.79720694e-02, -2.55230188e-01,
        -1.80790052e-01,  2.93739915e-01,  1.62875261e-02,
        -2.80566931e-01,  1.60284728e-01,  9.87277832e-03,
         8.44555616e-04,  8.39456245e-02,  3.24002892e-01,
         1.53253034e-01, -3.01048346e-02,  8.94618109e-02,
        -2.39153411e-02, -1.50188789e-01, -1.81733668e-02,
        -1.20483577e-01,  1.32937476e-01, -3.35325629e-01,
        -1.46504581e-01, -1.25251599e-02, -1.64428815e-01,
        -7.00765476e-02,  3.60923223e-02],
       [-1.56998575e-01,  4.24599349e-02, -5.57703003e-02,
        -8.08446854e-03,  1.23733155e-01,  3.89427543e-02,
        -4.37901802e-02, -1.86987907e-01, -2.29341656e-01,
        -1.27766818e-01,  3.83025259e-02, -1.07057482e-01,
        -6.11584112e-02,  2.49654502e-01, -1.39712945e-01,
        -3.91289443e-02, -1.35873526e-01, -3.58613044e-01,
         2.53462754e-02, -1.58370987e-01, -1.38350084e-01,
        -3.90771806e-01, -6.63642734e-02, -3.24838236e-02,
        -2.20453963e-02, -1.68282315e-01, -7.40613639e-02,
        -2.49074101e-02,  2.46460736e-01,  9.87201929e-05,
        -1.85390845e-01, -4.92824614e-02,  1.09015472e-01,
        -9.54203904e-02, -1.60352528e-01, -2.59811729e-02,
         1.13778859e-01, -2.09578887e-01,  2.18261331e-01,
        -3.11211571e-02, -6.12562597e-02, -8.66057724e-02,
        -1.10762455e-01, -5.73977083e-03, -1.08923554e-01,
        -1.72919363e-01,  1.00515485e-01, -5.64153939e-02,
        -4.97694984e-02, -1.07776590e-01]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercises">
<h1>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">#</a></h1>
<section id="to-8">
<h2>1. to 8.<a class="headerlink" href="#to-8" title="Permalink to this headline">#</a></h2>
<p>See Appendix A</p>
</section>
<section id="id1">
<h2>9.<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h2>
<section id="a">
<h3>a.<a class="headerlink" href="#a" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized <code class="docutils literal notranslate"><span class="pre">Example</span></code> protobuf with two features: the serialized image (use <code class="docutils literal notranslate"><span class="pre">tf.io.serialize_tensor()</span></code> to serialize each image), and the label. Note: for large images, you could use <code class="docutils literal notranslate"><span class="pre">tf.io.encode_jpeg()</span></code> instead. This would save a lot of space, but it would lose a bit of image quality.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()
X_valid, X_train = X_train_full[:5000], X_train_full[5000:]
y_valid, y_train = y_train_full[:5000], y_train_full[5000:]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))
valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))
test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def create_example(image, label):
    image_data = tf.io.serialize_tensor(image)
    #image_data = tf.io.encode_jpeg(image[..., np.newaxis])
    return Example(
        features=Features(
            feature={
                &quot;image&quot;: Feature(bytes_list=BytesList(value=[image_data.numpy()])),
                &quot;label&quot;: Feature(int64_list=Int64List(value=[label])),
            }))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for image, label in valid_set.take(1):
    print(create_example(image, label))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>features {
  feature {
    key: &quot;image&quot;
    value {
      bytes_list {
        value: &quot;\010\004\022\010\022\002\010\034\022\002\010\034\&quot;\220\006\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\001\000\000\rI\000\000\001\004\000\000\000\000\001\001\000\000\000\000\000\000\000\000\000\000\000\000\000\003\000$\210\177&gt;6\000\000\000\001\003\004\000\000\003\000\000\000\000\000\000\000\000\000\000\000\000\006\000f\314\260\206\220{\027\000\000\000\000\014\n\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\233\354\317\262k\234\241m@\027M\202H\017\000\000\000\000\000\000\000\000\000\000\000\001\000E\317\337\332\330\330\243\177yz\222\215X\254B\000\000\000\000\000\000\000\000\000\001\001\001\000\310\350\350\351\345\337\337\327\325\244\177{\304\345\000\000\000\000\000\000\000\000\000\000\000\000\000\000\267\341\330\337\344\353\343\340\336\340\335\337\365\255\000\000\000\000\000\000\000\000\000\000\000\000\000\000\301\344\332\325\306\264\324\322\323\325\337\334\363\312\000\000\000\000\000\000\000\000\000\000\001\003\000\014\333\334\324\332\300\251\343\320\332\340\324\342\305\3214\000\000\000\000\000\000\000\000\000\000\006\000c\364\336\334\332\313\306\335\327\325\336\334\365w\2478\000\000\000\000\000\000\000\000\000\004\000\0007\354\344\346\344\360\350\325\332\337\352\331\331\321\\\000\000\000\001\004\006\007\002\000\000\000\000\000\355\342\331\337\336\333\336\335\330\337\345\327\332\377M\000\000\003\000\000\000\000\000\000\000&gt;\221\314\344\317\325\335\332\320\323\332\340\337\333\327\340\364\237\000\000\000\000\000\022,Rk\275\344\334\336\331\342\310\315\323\346\340\352\260\274\372\370\351\356\327\000\0009\273\320\340\335\340\320\314\326\320\321\310\237\365\301\316\337\377\377\335\352\335\323\334\350\366\000\003\312\344\340\335\323\323\326\315\315\315\334\360P\226\377\345\335\274\232\277\322\314\321\336\344\341\000b\351\306\322\336\345\345\352\371\334\302\327\331\361AIju\250\333\335\327\331\337\337\340\345\035K\314\324\314\301\315\323\341\330\271\305\316\306\325\360\303\343\365\357\337\332\324\321\336\334\335\346C0\313\267\302\325\305\271\276\302\300\312\326\333\335\334\354\341\330\307\316\272\265\261\254\265\315\316s\000z\333\301\263\253\267\304\314\322\325\317\323\322\310\304\302\277\303\277\306\300\260\234\247\261\322\\\000\000J\275\324\277\257\254\257\265\271\274\275\274\301\306\314\321\322\322\323\274\274\302\300\330\252\000\002\000\000\000B\310\336\355\357\362\366\363\364\335\334\301\277\263\266\266\265\260\246\250c:\000\000\000\000\000\000\000\000\000(=,H)#\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000&quot;
      }
    }
  }
  feature {
    key: &quot;label&quot;
    value {
      int64_list {
        value: 9
      }
    }
  }
}
</pre></div>
</div>
</div>
</div>
<p>The following function saves a given dataset to a set of TFRecord files. The examples are written to the files in a round-robin fashion. To do this, we enumerate all the examples using the <code class="docutils literal notranslate"><span class="pre">dataset.enumerate()</span></code> method, and we compute <code class="docutils literal notranslate"><span class="pre">index</span> <span class="pre">%</span> <span class="pre">n_shards</span></code> to decide which file to write to. We use the standard <code class="docutils literal notranslate"><span class="pre">contextlib.ExitStack</span></code> class to make sure that all writers are properly closed whether or not an I/O error occurs while writing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from contextlib import ExitStack

def write_tfrecords(name, dataset, n_shards=10):
    paths = [&quot;{}.tfrecord-{:05d}-of-{:05d}&quot;.format(name, index, n_shards)
             for index in range(n_shards)]
    with ExitStack() as stack:
        writers = [stack.enter_context(tf.io.TFRecordWriter(path))
                   for path in paths]
        for index, (image, label) in dataset.enumerate():
            shard = index % n_shards
            example = create_example(image, label)
            writers[shard].write(example.SerializeToString())
    return paths
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_filepaths = write_tfrecords(&quot;my_fashion_mnist.train&quot;, train_set)
valid_filepaths = write_tfrecords(&quot;my_fashion_mnist.valid&quot;, valid_set)
test_filepaths = write_tfrecords(&quot;my_fashion_mnist.test&quot;, test_set)
</pre></div>
</div>
</div>
</div>
</section>
<section id="b">
<h3>b.<a class="headerlink" href="#b" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def preprocess(tfrecord):
    feature_descriptions = {
        &quot;image&quot;: tf.io.FixedLenFeature([], tf.string, default_value=&quot;&quot;),
        &quot;label&quot;: tf.io.FixedLenFeature([], tf.int64, default_value=-1)
    }
    example = tf.io.parse_single_example(tfrecord, feature_descriptions)
    image = tf.io.parse_tensor(example[&quot;image&quot;], out_type=tf.uint8)
    #image = tf.io.decode_jpeg(example[&quot;image&quot;])
    image = tf.reshape(image, shape=[28, 28])
    return image, example[&quot;label&quot;]

def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,
                  n_parse_threads=5, batch_size=32, cache=True):
    dataset = tf.data.TFRecordDataset(filepaths,
                                      num_parallel_reads=n_read_threads)
    if cache:
        dataset = dataset.cache()
    if shuffle_buffer_size:
        dataset = dataset.shuffle(shuffle_buffer_size)
    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)
    dataset = dataset.batch(batch_size)
    return dataset.prefetch(1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)
valid_set = mnist_dataset(valid_filepaths)
test_set = mnist_dataset(test_filepaths)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for X, y in train_set.take(1):
    for i in range(5):
        plt.subplot(1, 5, i + 1)
        plt.imshow(X[i].numpy(), cmap=&quot;binary&quot;)
        plt.axis(&quot;off&quot;)
        plt.title(str(y[i].numpy()))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/13_loading_and_preprocessing_data_174_0.png" src="../../_images/13_loading_and_preprocessing_data_174_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>keras.backend.clear_session()
tf.random.set_seed(42)
np.random.seed(42)

class Standardization(keras.layers.Layer):
    def adapt(self, data_sample):
        self.means_ = np.mean(data_sample, axis=0, keepdims=True)
        self.stds_ = np.std(data_sample, axis=0, keepdims=True)
    def call(self, inputs):
        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())

standardization = Standardization(input_shape=[28, 28])
# or perhaps soon:
#standardization = keras.layers.Normalization()

sample_image_batches = train_set.take(100).map(lambda image, label: image)
sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),
                               axis=0).astype(np.float32)
standardization.adapt(sample_images)

model = keras.models.Sequential([
    standardization,
    keras.layers.Flatten(),
    keras.layers.Dense(100, activation=&quot;relu&quot;),
    keras.layers.Dense(10, activation=&quot;softmax&quot;)
])
model.compile(loss=&quot;sparse_categorical_crossentropy&quot;,
              optimizer=&quot;nadam&quot;, metrics=[&quot;accuracy&quot;])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from datetime import datetime
logs = os.path.join(os.curdir, &quot;my_logs&quot;,
                    &quot;run_&quot; + datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;))

tensorboard_cb = tf.keras.callbacks.TensorBoard(
    log_dir=logs, histogram_freq=1, profile_batch=10)

model.fit(train_set, epochs=5, validation_data=valid_set,
          callbacks=[tensorboard_cb])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
1719/1719 [==============================] - 4s 2ms/step - loss: 656.6687 - accuracy: 0.8038 - val_loss: 82.8087 - val_accuracy: 0.8806
Epoch 2/5
1719/1719 [==============================] - 4s 2ms/step - loss: 209.0040 - accuracy: 0.8781 - val_loss: 147.8434 - val_accuracy: 0.8906
Epoch 3/5
1719/1719 [==============================] - 3s 2ms/step - loss: 146.5866 - accuracy: 0.8914 - val_loss: 361.5933 - val_accuracy: 0.9058
Epoch 4/5
1719/1719 [==============================] - 3s 2ms/step - loss: 110.8240 - accuracy: 0.9014 - val_loss: 150.4520 - val_accuracy: 0.9143
Epoch 5/5
1719/1719 [==============================] - 3s 2ms/step - loss: 175.6303 - accuracy: 0.9106 - val_loss: 42.5092 - val_accuracy: 0.9141
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fd521498890&gt;
</pre></div>
</div>
</div>
</div>
<p><strong>Warning:</strong> The profiling tab in TensorBoard works if you use TensorFlow 2.2+. You also need to make sure <code class="docutils literal notranslate"><span class="pre">tensorboard_plugin_profile</span></code> is installed (and restart Jupyter if necessary).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%load_ext tensorboard
%tensorboard --logdir=./my_logs --port=6006
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe id="tensorboard-frame-bb24df699b31a9fa" width="100%" height="800" frameborder="0">
</iframe>
<script>
  (function() {
    const frame = document.getElementById("tensorboard-frame-bb24df699b31a9fa");
    const url = new URL("/", window.location);
    const port = 6006;
    if (port) {
      url.port = port;
    }
    frame.src = url;
  })();
</script>
</div></div>
</div>
</section>
</section>
<section id="id2">
<h2>10.<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<p><em>Exercise: In this exercise you will download a dataset, split it, create a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> to load it and preprocess it efficiently, then build and train a binary classification model containing an <code class="docutils literal notranslate"><span class="pre">Embedding</span></code> layer.</em></p>
<section id="id3">
<h3>a.<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Download the <a class="reference external" href="https://homl.info/imdb">Large Movie Review Dataset</a>, which contains 50,000 movies reviews from the <a class="reference external" href="https://imdb.com/">Internet Movie Database</a>. The data is organized in two directories, <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code>, each containing a <code class="docutils literal notranslate"><span class="pre">pos</span></code> subdirectory with 12,500 positive reviews and a <code class="docutils literal notranslate"><span class="pre">neg</span></code> subdirectory with 12,500 negative reviews. Each review is stored in a separate text file. There are other files and folders (including preprocessed bag-of-words), but we will ignore them in this exercise.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from pathlib import Path

DOWNLOAD_ROOT = &quot;http://ai.stanford.edu/~amaas/data/sentiment/&quot;
FILENAME = &quot;aclImdb_v1.tar.gz&quot;
filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)
path = Path(filepath).parent / &quot;aclImdb&quot;
path
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
84131840/84125825 [==============================] - 12s 0us/step
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PosixPath(&#39;/Users/ageron/.keras/datasets/aclImdb&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for name, subdirs, files in os.walk(path):
    indent = len(Path(name).parts) - len(path.parts)
    print(&quot;    &quot; * indent + Path(name).parts[-1] + os.sep)
    for index, filename in enumerate(sorted(files)):
        if index == 3:
            print(&quot;    &quot; * (indent + 1) + &quot;...&quot;)
            break
        print(&quot;    &quot; * (indent + 1) + filename)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>aclImdb/
    README
    imdb.vocab
    imdbEr.txt
    test/
        labeledBow.feat
        urls_neg.txt
        urls_pos.txt
        neg/
            0_2.txt
            10000_4.txt
            10001_1.txt
            ...
        pos/
            0_10.txt
            10000_7.txt
            10001_9.txt
            ...
    train/
        labeledBow.feat
        unsupBow.feat
        urls_neg.txt
        ...
        neg/
            0_3.txt
            10000_4.txt
            10001_4.txt
            ...
        unsup/
            0_0.txt
            10000_0.txt
            10001_0.txt
            ...
        pos/
            0_9.txt
            10000_8.txt
            10001_10.txt
            ...
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def review_paths(dirpath):
    return [str(path) for path in dirpath.glob(&quot;*.txt&quot;)]

train_pos = review_paths(path / &quot;train&quot; / &quot;pos&quot;)
train_neg = review_paths(path / &quot;train&quot; / &quot;neg&quot;)
test_valid_pos = review_paths(path / &quot;test&quot; / &quot;pos&quot;)
test_valid_neg = review_paths(path / &quot;test&quot; / &quot;neg&quot;)

len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(12500, 12500, 12500, 12500)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h3>b.<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Split the test set into a validation set (15,000) and a test set (10,000).</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.shuffle(test_valid_pos)

test_pos = test_valid_pos[:5000]
test_neg = test_valid_neg[:5000]
valid_pos = test_valid_pos[5000:]
valid_neg = test_valid_neg[5000:]
</pre></div>
</div>
</div>
</div>
</section>
<section id="c">
<h3>c.<a class="headerlink" href="#c" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Use tf.data to create an efficient dataset for each set.</em></p>
<p>Since the dataset fits in memory, we can just load all the data using pure Python code and use <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.from_tensor_slices()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def imdb_dataset(filepaths_positive, filepaths_negative):
    reviews = []
    labels = []
    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):
        for filepath in filepaths:
            with open(filepath) as review_file:
                reviews.append(review_file.read())
            labels.append(label)
    return tf.data.Dataset.from_tensor_slices(
        (tf.constant(reviews), tf.constant(labels)))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for X, y in imdb_dataset(train_pos, train_neg).take(3):
    print(X)
    print(y)
    print()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(b&quot;Working with one of the best Shakespeare sources, this film manages to be creditable to it&#39;s source, whilst still appealing to a wider audience.&lt;br /&gt;&lt;br /&gt;Branagh steals the film from under Fishburne&#39;s nose, and there&#39;s a talented cast on good form.&quot;, shape=(), dtype=string)
tf.Tensor(0, shape=(), dtype=int32)

tf.Tensor(b&#39;Well...tremors I, the original started off in 1990 and i found the movie quite enjoyable to watch. however, they proceeded to make tremors II and III. Trust me, those movies started going downhill right after they finished the first one, i mean, ass blasters??? Now, only God himself is capable of answering the question &quot;why in Gods name would they create another one of these dumpster dives of a movie?&quot; Tremors IV cannot be considered a bad movie, in fact it cannot be even considered an epitome of a bad movie, for it lives up to more than that. As i attempted to sit though it, i noticed that my eyes started to bleed, and i hoped profusely that the little girl from the ring would crawl through the TV and kill me. did they really think that dressing the people who had stared in the other movies up as though they we\&#39;re from the wild west would make the movie (with the exact same occurrences) any better? honestly, i would never suggest buying this movie, i mean, there are cheaper ways to find things that burn well.&#39;, shape=(), dtype=string)
tf.Tensor(0, shape=(), dtype=int32)

tf.Tensor(b&quot;Ouch! This one was a bit painful to sit through. It has a cute and amusing premise, but it all goes to hell from there. Matthew Modine is almost always pedestrian and annoying, and he does not disappoint in this one. Deborah Kara Unger and John Neville turned in surprisingly decent performances. Alan Bates and Jennifer Tilly, among others, played it way over the top. I know that&#39;s the way the parts were written, and it&#39;s hard to blame actors, when the script and director have them do such schlock. If you&#39;re going to have outrageous characters, that&#39;s OK, but you gotta have good material to make it work. It didn&#39;t here. Run away screaming from this movie if at all possible.&quot;, shape=(), dtype=string)
tf.Tensor(0, shape=(), dtype=int32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>17.4 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)
</pre></div>
</div>
</div>
</div>
<p>It takes about 17 seconds to load the dataset and go through it 10 times.</p>
<p>But let’s pretend the dataset does not fit in memory, just to make things more interesting. Luckily, each review fits on just one line (they use <code class="docutils literal notranslate"><span class="pre">&lt;br</span> <span class="pre">/&gt;</span></code> to indicate line breaks), so we can read the reviews using a <code class="docutils literal notranslate"><span class="pre">TextLineDataset</span></code>. If they didn’t we would have to preprocess the input files (e.g., converting them to TFRecords). For very large datasets, it would make sense to use a tool like Apache Beam for that.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):
    dataset_neg = tf.data.TextLineDataset(filepaths_negative,
                                          num_parallel_reads=n_read_threads)
    dataset_neg = dataset_neg.map(lambda review: (review, 0))
    dataset_pos = tf.data.TextLineDataset(filepaths_positive,
                                          num_parallel_reads=n_read_threads)
    dataset_pos = dataset_pos.map(lambda review: (review, 1))
    return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>33 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)
</pre></div>
</div>
</div>
</div>
<p>Now it takes about 33 seconds to go through the dataset 10 times. That’s much slower, essentially because the dataset is not cached in RAM, so it must be reloaded at each epoch. If you add <code class="docutils literal notranslate"><span class="pre">.cache()</span></code> just before <code class="docutils literal notranslate"><span class="pre">.repeat(10)</span></code>, you will see that this implementation will be about as fast as the previous one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).cache().repeat(10): pass
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>batch_size = 32

train_set = imdb_dataset(train_pos, train_neg).shuffle(25000).batch(batch_size).prefetch(1)
valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)
test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)
</pre></div>
</div>
</div>
</div>
</section>
<section id="d">
<h3>d.<a class="headerlink" href="#d" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Create a binary classification model, using a <code class="docutils literal notranslate"><span class="pre">TextVectorization</span></code> layer to preprocess each review. If the <code class="docutils literal notranslate"><span class="pre">TextVectorization</span></code> layer is not yet available (or if you like a challenge), try to create your own custom preprocessing layer: you can use the functions in the <code class="docutils literal notranslate"><span class="pre">tf.strings</span></code> package, for example <code class="docutils literal notranslate"><span class="pre">lower()</span></code> to make everything lowercase, <code class="docutils literal notranslate"><span class="pre">regex_replace()</span></code> to replace punctuation with spaces, and <code class="docutils literal notranslate"><span class="pre">split()</span></code> to split words on spaces. You should use a lookup table to output word indices, which must be prepared in the <code class="docutils literal notranslate"><span class="pre">adapt()</span></code> method.</em></p>
<p>Let’s first write a function to preprocess the reviews, cropping them to 300 characters, converting them to lower case, then replacing <code class="docutils literal notranslate"><span class="pre">&lt;br</span> <span class="pre">/&gt;</span></code> and all non-letter characters to spaces, splitting the reviews into words, and finally padding or cropping each review so it ends up with exactly <code class="docutils literal notranslate"><span class="pre">n_words</span></code> tokens:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def preprocess(X_batch, n_words=50):
    shape = tf.shape(X_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])
    Z = tf.strings.substr(X_batch, 0, 300)
    Z = tf.strings.lower(Z)
    Z = tf.strings.regex_replace(Z, b&quot;&lt;br\\s*/?&gt;&quot;, b&quot; &quot;)
    Z = tf.strings.regex_replace(Z, b&quot;[^a-z]&quot;, b&quot; &quot;)
    Z = tf.strings.split(Z)
    return Z.to_tensor(shape=shape, default_value=b&quot;&lt;pad&gt;&quot;)

X_example = tf.constant([&quot;It&#39;s a great, great movie! I loved it.&quot;, &quot;It was terrible, run away!!!&quot;])
preprocess(X_example)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 50), dtype=string, numpy=
array([[b&#39;it&#39;, b&#39;s&#39;, b&#39;a&#39;, b&#39;great&#39;, b&#39;great&#39;, b&#39;movie&#39;, b&#39;i&#39;, b&#39;loved&#39;,
        b&#39;it&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;],
       [b&#39;it&#39;, b&#39;was&#39;, b&#39;terrible&#39;, b&#39;run&#39;, b&#39;away&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;, b&#39;&lt;pad&gt;&#39;,
        b&#39;&lt;pad&gt;&#39;]], dtype=object)&gt;
</pre></div>
</div>
</div>
</div>
<p>Now let’s write a second utility function that will take a data sample with the same format as the output of the <code class="docutils literal notranslate"><span class="pre">preprocess()</span></code> function, and will output the list of the top <code class="docutils literal notranslate"><span class="pre">max_size</span></code> most frequent words, ensuring that the padding token is first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from collections import Counter

def get_vocabulary(data_sample, max_size=1000):
    preprocessed_reviews = preprocess(data_sample).numpy()
    counter = Counter()
    for words in preprocessed_reviews:
        for word in words:
            if word != b&quot;&lt;pad&gt;&quot;:
                counter[word] += 1
    return [b&quot;&lt;pad&gt;&quot;] + [word for word, count in counter.most_common(max_size)]

get_vocabulary(X_example)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[b&#39;&lt;pad&gt;&#39;,
 b&#39;it&#39;,
 b&#39;great&#39;,
 b&#39;s&#39;,
 b&#39;a&#39;,
 b&#39;movie&#39;,
 b&#39;i&#39;,
 b&#39;loved&#39;,
 b&#39;was&#39;,
 b&#39;terrible&#39;,
 b&#39;run&#39;,
 b&#39;away&#39;]
</pre></div>
</div>
</div>
</div>
<p>Now we are ready to create the <code class="docutils literal notranslate"><span class="pre">TextVectorization</span></code> layer. Its constructor just saves the hyperparameters (<code class="docutils literal notranslate"><span class="pre">max_vocabulary_size</span></code> and <code class="docutils literal notranslate"><span class="pre">n_oov_buckets</span></code>). The <code class="docutils literal notranslate"><span class="pre">adapt()</span></code> method computes the vocabulary using the <code class="docutils literal notranslate"><span class="pre">get_vocabulary()</span></code> function, then it builds a <code class="docutils literal notranslate"><span class="pre">StaticVocabularyTable</span></code> (see Chapter 16 for more details). The <code class="docutils literal notranslate"><span class="pre">call()</span></code> method preprocesses the reviews to get a padded list of words for each review, then it uses the <code class="docutils literal notranslate"><span class="pre">StaticVocabularyTable</span></code> to lookup the index of each word in the vocabulary:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class TextVectorization(keras.layers.Layer):
    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, dtype=tf.string, **kwargs):
        super().__init__(dtype=dtype, **kwargs)
        self.max_vocabulary_size = max_vocabulary_size
        self.n_oov_buckets = n_oov_buckets

    def adapt(self, data_sample):
        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)
        words = tf.constant(self.vocab)
        word_ids = tf.range(len(self.vocab), dtype=tf.int64)
        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)
        self.table = tf.lookup.StaticVocabularyTable(vocab_init, self.n_oov_buckets)
        
    def call(self, inputs):
        preprocessed_inputs = preprocess(inputs)
        return self.table.lookup(preprocessed_inputs)
</pre></div>
</div>
</div>
</div>
<p>Let’s try it on our small <code class="docutils literal notranslate"><span class="pre">X_example</span></code> we defined earlier:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>text_vectorization = TextVectorization()

text_vectorization.adapt(X_example)
text_vectorization(X_example)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 50), dtype=int64, numpy=
array([[ 1,  3,  4,  2,  2,  5,  6,  7,  1,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0],
       [ 1,  8,  9, 10, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
         0,  0]])&gt;
</pre></div>
</div>
</div>
</div>
<p>Looks good! As you can see, each review was cleaned up and tokenized, then each word was encoded as its index in the vocabulary (all the 0s correspond to the <code class="docutils literal notranslate"><span class="pre">&lt;pad&gt;</span></code> tokens).</p>
<p>Now let’s create another <code class="docutils literal notranslate"><span class="pre">TextVectorization</span></code> layer and let’s adapt it to the full IMDB training set (if the training set did not fit in RAM, we could just use a smaller sample of the training set by calling <code class="docutils literal notranslate"><span class="pre">train_set.take(500)</span></code>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>max_vocabulary_size = 1000
n_oov_buckets = 100

sample_review_batches = train_set.map(lambda review, label: review)
sample_reviews = np.concatenate(list(sample_review_batches.as_numpy_iterator()),
                                axis=0)

text_vectorization = TextVectorization(max_vocabulary_size, n_oov_buckets,
                                       input_shape=[])
text_vectorization.adapt(sample_reviews)
</pre></div>
</div>
</div>
</div>
<p>Let’s run it on the same <code class="docutils literal notranslate"><span class="pre">X_example</span></code>, just to make sure the word IDs are larger now, since the vocabulary is bigger:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>text_vectorization(X_example)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 50), dtype=int64, numpy=
array([[  9,  14,   2,  64,  64,  12,   5, 257,   9,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],
       [  9,  13, 269, 531, 335,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]])&gt;
</pre></div>
</div>
</div>
</div>
<p>Good! Now let’s take a look at the first 10 words in the vocabulary:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>text_vectorization.vocab[:10]
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[b&#39;&lt;pad&gt;&#39;, b&#39;the&#39;, b&#39;a&#39;, b&#39;of&#39;, b&#39;and&#39;, b&#39;i&#39;, b&#39;to&#39;, b&#39;is&#39;, b&#39;this&#39;, b&#39;it&#39;]
</pre></div>
</div>
</div>
</div>
<p>These are the most common words in the reviews.</p>
<p>Now to build our model we will need to encode all these word IDs somehow. One approach is to create bags of words: for each review, and for each word in the vocabulary, we count the number of occurences of that word in the review. For example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>simple_example = tf.constant([[1, 3, 1, 0, 0], [2, 2, 0, 0, 0]])
tf.reduce_sum(tf.one_hot(simple_example, 4), axis=1)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[2., 2., 0., 1.],
       [3., 0., 2., 0.]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>The first review has 2 times the word 0, 2 times the word 1, 0 times the word 2, and 1 time the word 3, so its bag-of-words representation is <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">2,</span> <span class="pre">0,</span> <span class="pre">1]</span></code>. Similarly, the second review has 3 times the word 0, 0 times the word 1, and so on. Let’s wrap this logic in a small custom layer, and let’s test it. We’ll drop the counts for the word 0, since this corresponds to the <code class="docutils literal notranslate"><span class="pre">&lt;pad&gt;</span></code> token, which we don’t care about.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class BagOfWords(keras.layers.Layer):
    def __init__(self, n_tokens, dtype=tf.int32, **kwargs):
        super().__init__(dtype=dtype, **kwargs)
        self.n_tokens = n_tokens
    def call(self, inputs):
        one_hot = tf.one_hot(inputs, self.n_tokens)
        return tf.reduce_sum(one_hot, axis=1)[:, 1:]
</pre></div>
</div>
</div>
</div>
<p>Let’s test it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>bag_of_words = BagOfWords(n_tokens=4)
bag_of_words(simple_example)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=
array([[2., 0., 1.],
       [0., 2., 0.]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>It works fine! Now let’s create another <code class="docutils literal notranslate"><span class="pre">BagOfWord</span></code> with the right vocabulary size for our training set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n_tokens = max_vocabulary_size + n_oov_buckets + 1 # add 1 for &lt;pad&gt;
bag_of_words = BagOfWords(n_tokens)
</pre></div>
</div>
</div>
</div>
<p>We’re ready to train the model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model = keras.models.Sequential([
    text_vectorization,
    bag_of_words,
    keras.layers.Dense(100, activation=&quot;relu&quot;),
    keras.layers.Dense(1, activation=&quot;sigmoid&quot;),
])
model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;nadam&quot;,
              metrics=[&quot;accuracy&quot;])
model.fit(train_set, epochs=5, validation_data=valid_set)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
782/782 [==============================] - 5s 5ms/step - loss: 0.5834 - accuracy: 0.6784 - val_loss: 0.5116 - val_accuracy: 0.7376
Epoch 2/5
782/782 [==============================] - 5s 5ms/step - loss: 0.4647 - accuracy: 0.7738 - val_loss: 0.4998 - val_accuracy: 0.7445
Epoch 3/5
782/782 [==============================] - 5s 5ms/step - loss: 0.4141 - accuracy: 0.8062 - val_loss: 0.5025 - val_accuracy: 0.7457
Epoch 4/5
782/782 [==============================] - 5s 5ms/step - loss: 0.3506 - accuracy: 0.8536 - val_loss: 0.5308 - val_accuracy: 0.7465
Epoch 5/5
782/782 [==============================] - 5s 5ms/step - loss: 0.2642 - accuracy: 0.9039 - val_loss: 0.5681 - val_accuracy: 0.7351
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fd4f052da90&gt;
</pre></div>
</div>
</div>
</div>
<p>We get about 73.5% accuracy on the validation set after just the first epoch, but after that the model makes no significant progress. We will do better in Chapter 16. For now the point is just to perform efficient preprocessing using <code class="docutils literal notranslate"><span class="pre">tf.data</span></code> and Keras preprocessing layers.</p>
</section>
<section id="e">
<h3>e.<a class="headerlink" href="#e" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Add an <code class="docutils literal notranslate"><span class="pre">Embedding</span></code> layer and compute the mean embedding for each review, multiplied by the square root of the number of words (see Chapter 16). This rescaled mean embedding can then be passed to the rest of your model.</em></p>
<p>To compute the mean embedding for each review, and multiply it by the square root of the number of words in that review, we will need a little function. For each sentence, this function needs to compute <span class="math notranslate nohighlight">\(M \times \sqrt N\)</span>, where <span class="math notranslate nohighlight">\(M\)</span> is the mean of all the word embeddings in the sentence (excluding padding tokens), and <span class="math notranslate nohighlight">\(N\)</span> is the number of words in the sentence (also excluding padding tokens). We can rewrite <span class="math notranslate nohighlight">\(M\)</span> as <span class="math notranslate nohighlight">\(\dfrac{S}{N}\)</span>, where <span class="math notranslate nohighlight">\(S\)</span> is the sum of all word embeddings (it does not matter whether or not we include the padding tokens in this sum, since their representation is a zero vector). So the function must return <span class="math notranslate nohighlight">\(M \times \sqrt N = \dfrac{S}{N} \times \sqrt N = \dfrac{S}{\sqrt N \times \sqrt N} \times \sqrt N= \dfrac{S}{\sqrt N}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def compute_mean_embedding(inputs):
    not_pad = tf.math.count_nonzero(inputs, axis=-1)
    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)    
    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))
    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words

another_example = tf.constant([[[1., 2., 3.], [4., 5., 0.], [0., 0., 0.]],
                               [[6., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])
compute_mean_embedding(another_example)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=
array([[3.535534 , 4.9497476, 2.1213205],
       [6.       , 0.       , 0.       ]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>Let’s check that this is correct. The first review contains 2 words (the last token is a zero vector, which represents the <code class="docutils literal notranslate"><span class="pre">&lt;pad&gt;</span></code> token). Let’s compute the mean embedding for these 2 words, and multiply the result by the square root of 2:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tf.reduce_mean(another_example[0:1, :2], axis=1) * tf.sqrt(2.)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3.535534 , 4.9497476, 2.1213202]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>Looks good! Now let’s check the second review, which contains just one word (we ignore the two padding tokens):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>tf.reduce_mean(another_example[1:2, :1], axis=1) * tf.sqrt(1.)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[6., 0., 0.]], dtype=float32)&gt;
</pre></div>
</div>
</div>
</div>
<p>Perfect. Now we’re ready to train our final model. It’s the same as before, except we replaced the <code class="docutils literal notranslate"><span class="pre">BagOfWords</span></code> layer with an <code class="docutils literal notranslate"><span class="pre">Embedding</span></code> layer followed by a <code class="docutils literal notranslate"><span class="pre">Lambda</span></code> layer that calls the <code class="docutils literal notranslate"><span class="pre">compute_mean_embedding</span></code> layer:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>embedding_size = 20

model = keras.models.Sequential([
    text_vectorization,
    keras.layers.Embedding(input_dim=n_tokens,
                           output_dim=embedding_size,
                           mask_zero=True), # &lt;pad&gt; tokens =&gt; zero vectors
    keras.layers.Lambda(compute_mean_embedding),
    keras.layers.Dense(100, activation=&quot;relu&quot;),
    keras.layers.Dense(1, activation=&quot;sigmoid&quot;),
])
</pre></div>
</div>
</div>
</div>
</section>
<section id="f">
<h3>f.<a class="headerlink" href="#f" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Train the model and see what accuracy you get. Try to optimize your pipelines to make training as fast as possible.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;nadam&quot;, metrics=[&quot;accuracy&quot;])
model.fit(train_set, epochs=5, validation_data=valid_set)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
782/782 [==============================] - 3s 2ms/step - loss: 0.6053 - accuracy: 0.6568 - val_loss: 0.5151 - val_accuracy: 0.7382
Epoch 2/5
782/782 [==============================] - 2s 2ms/step - loss: 0.4922 - accuracy: 0.7569 - val_loss: 0.5081 - val_accuracy: 0.7466
Epoch 3/5
782/782 [==============================] - 2s 2ms/step - loss: 0.4827 - accuracy: 0.7628 - val_loss: 0.4978 - val_accuracy: 0.7473
Epoch 4/5
782/782 [==============================] - 2s 2ms/step - loss: 0.4761 - accuracy: 0.7656 - val_loss: 0.4959 - val_accuracy: 0.7513
Epoch 5/5
782/782 [==============================] - 3s 2ms/step - loss: 0.4737 - accuracy: 0.7687 - val_loss: 0.4978 - val_accuracy: 0.7471
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7f89584c3690&gt;
</pre></div>
</div>
</div>
</div>
<p>The model is not better using embeddings (but we will do better in Chapter 16). The pipeline looks fast enough (we optimized it earlier).</p>
</section>
<section id="g">
<h3>g.<a class="headerlink" href="#g" title="Permalink to this headline">#</a></h3>
<p><em>Exercise: Use TFDS to load the same dataset more easily: <code class="docutils literal notranslate"><span class="pre">tfds.load(&quot;imdb_reviews&quot;)</span></code>.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import tensorflow_datasets as tfds

datasets = tfds.load(name=&quot;imdb_reviews&quot;)
train_set, test_set = datasets[&quot;train&quot;], datasets[&quot;test&quot;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>for example in train_set.take(1):
    print(example[&quot;text&quot;])
    print(example[&quot;label&quot;])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor(b&quot;This was an absolutely terrible movie. Don&#39;t be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie&#39;s ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor&#39;s like Christopher Walken&#39;s good name. I could barely sit through it.&quot;, shape=(), dtype=string)
tf.Tensor(0, shape=(), dtype=int64)
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./handson-ml2/original"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="12_custom_models_and_training_with_tensorflow.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Chapter 12 – Custom Models and Training with TensorFlow</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="14_deep_computer_vision_with_cnns.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Daniel Kapitan<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>
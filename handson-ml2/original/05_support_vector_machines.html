
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Chapter 5 – Support Vector Machines &#8212; Data Science Foundation in Python</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://jads-nl.github.io/data-science-foundation-curriculum/handson-ml2/original/05_support_vector_machines.html" />
    <link rel="shortcut icon" href="../../_static/favicon-32x32.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chapter 6 – Decision Trees" href="06_decision_trees.html" />
    <link rel="prev" title="Chapter 4 – Training Models" href="04_training_linear_models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/jads-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Science Foundation in Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Why this JupyterBook?
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Statistical Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../islr/introduction.html">
   Introduction to ISLRv2
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/labs.html">
   Labs
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_02.3_introduction.html">
     Lab 2.3: Introduction to Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_03.6_linear_regression.html">
     Lab 3.6: Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_04.7_classification_methods.html">
     Lab 4.7: Classification Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_05.3_cross_validation_and_the_bootstrap.html">
     Lab 5.3: Cross-Validation and the Bootstrap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.1_subset_selection_methods.html">
     Lab 6.5.1: Subset Selection Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.2_ridge_regression_and_the_lasso.html">
     Lab 6.5.2: Ridge Regression and the Lasso
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_06.5.3_pcr_and_pls_regression.html">
     Lab 6.5.3: PCR and PLS Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_07.8_non_linear_modelling.html">
     Lab 7.8: Non-linear Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_08.3_decision_trees.html">
     Lab 8.3: Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_09.6_support_vector_machines.html">
     Lab 9.6: Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.2_multilayer_network_on_mnist_digit_data.html">
     Lab 10.9.2: A Multilayer Network on the MNIST Digit Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.3_convolutional_neural_networks.html">
     Lab 10.9.3: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.5_imdb_document_classification.html">
     Lab 10.9.5: IMDb Document Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_10.9.6_recurrent_neural_networks.html">
     Lab 10.9.6: Recurrent Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../islr/labs/lab_12.5_unsupervised_learning.html">
     Lab 12.5: Unsupervised Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../islr/exercises.html">
   Exercises
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter2/index.html">
     Chapter 2
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise1.html">
       Exercise 2.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise2.html">
       Exercise 2.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise3.html">
       Exercise 2.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise4.html">
       Exercise 2.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise5.html">
       Exercise 2.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise6.html">
       Exercise 2.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise7.html">
       Exercise 2.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise8.html">
       Exercise 2.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise9.html">
       Exercise 2.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter2/exercise10.html">
       Exercise 2.10
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter3/index.html">
     Chapter 3
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise1.html">
       Exercise 3.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise2.html">
       Exercise 3.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise3.html">
       Exercise 3.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise4.html">
       Exercise 3.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise5.html">
       Exercise 3.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise6.html">
       Exercise 3.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise7.html">
       Exercise 3.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise8.html">
       Exercise 3.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise9.html">
       Exercise 3.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise10.html">
       Exercise 3.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise11.html">
       Exercise 3.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise12.html">
       Exercise 3.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise13.html">
       Exercise 3.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise14.html">
       Exercise 3.14
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter3/exercise15.html">
       Exercise 3.15
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter4/index.html">
     Chapter 4
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise1.html">
       Exercise 4.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise2.html">
       Exercise 4.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise3.html">
       Exercise 4.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise4.html">
       Exercise 4.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise5.html">
       Exercise 4.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise6.html">
       Exercise 4.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise7.html">
       Exercise 4.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise8.html">
       Exercise 4.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise9.html">
       Exercise 4.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise10.html">
       Exercise 10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise11.html">
       Exercise 11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise12.html">
       Exercise 12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise13.html">
       Exercise 4.13
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise14.html">
       Exercise 4.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise15.html">
       Exercise 4.12
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter4/exercise16.html">
       Exercise 4.16
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter5/index.html">
     Chapter 5
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise1.html">
       Exercise 5.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise2.html">
       Exercise 5.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise3.html">
       Problem 5.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise4.html">
       Exercise 5.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise5.html">
       Exercise 5.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise6.html">
       Exercise 5.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise7.html">
       Exercise 5.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise8.html">
       Exercise 5.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter5/exercise9.html">
       Exercise 5.9
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter6/index.html">
     Chapter 6
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise1.html">
       Exercise 6.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise2.html">
       Exercise 6.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise3.html">
       Exercise 6.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise4.html">
       Exercise 6.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise5.html">
       Exercise 6.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise6.html">
       Exercise 6.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise7.html">
       Exercise 6.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise8.html">
       Exercise 6.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise9.html">
       Exercise 6.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise10.html">
       Exercise 6.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter6/exercise11.html">
       Exercise 6.11
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter7/index.html">
     Chapter 7
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise1.html">
       Exercise 7.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise2.html">
       Exercise 7.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise3.html">
       Exercise 7.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise4.html">
       Exercise 7.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise5.html">
       Exercise 7.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise6.html">
       Exercise 7.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise7.html">
       Exercise 7.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise8.html">
       Exercise 7.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise9.html">
       Exercise 7.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise10.html">
       Exercise 7.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise11.html">
       Exercise 7.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter7/exercise12.html">
       Exercise 7.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter8/index.html">
     Chapter 8
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise1.html">
       Exercise 8.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise2.html">
       Exercise 8.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise3.html">
       Exercise 8.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise4.html">
       Exercise 8.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise5.html">
       Exercise 8.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise6.html">
       Exercise 8.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise7.html">
       Exercise 8.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise8.html">
       Exercise 8.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise9.html">
       Exercise 8.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise10.html">
       Exercise 8.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise11.html">
       Exercise 8.11
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter8/exercise12.html">
       Exercise 8.12
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter9/index.html">
     Chapter 9
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise1.html">
       Exercise 9.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise2.html">
       Exercise 9.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise3.html">
       Exercise 9.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise4.html">
       Exercise 9.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise5.html">
       Exercise 9.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise6.html">
       Exercise 9.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise7.html">
       Exercise 9.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter9/exercise8.html">
       Exercise 9.8
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../islr/exercises/chapter12/index.html">
     Chapter 12
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
    <label for="toctree-checkbox-11">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise1.html">
       Exercise 12.1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise2.html">
       Exercise 12.2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise3.html">
       Exercise 12.3
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise4.html">
       Exercise 12.4
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise5.html">
       Exercise 12.5
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise6.html">
       Exercise 12.6
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise7.html">
       Exercise 12.7
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise8.html">
       Exercise 10.8
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise9.html">
       Exercise 12.9
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise10.html">
       Exercise 12.10
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../islr/exercises/chapter12/exercise11.html">
       Exercise 12.11
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Hands-on Machine Learning in Python
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../introduction.html">
   Hands-on Machine Learning with Aurélien Géron
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01_the_machine_learning_landscape.html">
     Chapter 1 – The Machine Learning landscape
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_end_to_end_machine_learning_project.html">
     Chapter 2 – End-to-end Machine Learning project
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_classification.html">
     Chapter 3 – Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_training_linear_models.html">
     Chapter 4 – Training Models
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Chapter 5 – Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06_decision_trees.html">
     Chapter 6 – Decision Trees
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07_ensemble_learning_and_random_forests.html">
     Chapter 7 – Ensemble Learning and Random Forests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08_dimensionality_reduction.html">
     Chapter 8 – Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09_unsupervised_learning.html">
     Chapter 9 – Unsupervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10_neural_nets_with_keras.html">
     Chapter 10 – Introduction to Artificial Neural Networks with Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11_training_deep_neural_networks.html">
     Chapter 11 – Training Deep Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12_custom_models_and_training_with_tensorflow.html">
     Chapter 12 – Custom Models and Training with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13_loading_and_preprocessing_data.html">
     Chapter 13 – Loading and Preprocessing Data with TensorFlow
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14_deep_computer_vision_with_cnns.html">
     Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15_processing_sequences_using_rnns_and_cnns.html">
     Chapter 15 – Processing Sequences Using RNNs and CNNs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="16_nlp_with_rnns_and_attention.html">
     Chapter 16 – Natural Language Processing with RNNs and Attention**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="17_autoencoders_and_gans.html">
     Chapter 17 – Autoencoders and GANs**
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="18_reinforcement_learning.html">
     Chapter 18 – Reinforcement Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="19_training_and_deploying_at_scale.html">
     Chapter 19 – Training and Deploying TensorFlow Models at Scale
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../extra.html">
   Miscellaneous tips &amp; tricks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="math_linear_algebra.html">
     Math primer - Linear Algebra
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="math_differential_calculus.html">
     Math primer - Differential Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_autodiff.html">
     Implementation of autodiff techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="extra_gradient_descent_comparison.html">
     Comparison of Batch, Mini-Batch and Stochastic Gradient Descent
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data visualization with Altair
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction.html">
   Data visualization with Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/introduction-to-interactive-data-visualization.html">
   Introduction to data visualization with Python
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../visualization/altair_get_started.html">
   Getting Started with Altair
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_introduction.html">
     Introduction to Altair
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_marks_encoding.html">
     Data Types, Graphical Marks, and Visual Encoding Channels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_data_transformation.html">
     Data Transformation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_scales_axes_legends.html">
     Scales, Axes, and Legends
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_view_composition.html">
     Multi-View Composition
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_interaction.html">
     Interaction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_cartographic.html">
     Cartographic Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../visualization/altair_debugging.html">
     Altair Debugging Guide
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Interpretable Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../iml/introduction.html">
   Introduction to IML
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_partial_dependence.html">
     Partial Dependence and Individual Conditional Expectation Plots
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance.html">
     Permutation Importance vs Random Forest Feature Importance (MDI)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/plot_permutation_importance_multicollinear.html">
     Permutation Importance with Multicollinear or Correlated Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../iml/interpreting-machine-learning-models.html">
     IML with Pima Indians and the Titanic datasets
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Principles of time-series forecasting
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/introduction.html">
   Introduction to FPP3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../fpp/examples-time-series-forecasting-with-python.html">
   Examples of time-series forecasting with Python
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Natural language processing with spaCy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../nlp/introduction.html">
   Introduction to NLP with spaCy
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../nlp/dutch-restaurant-reviews.html">
   Dutch restaurant reviews
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-dutch-restaurant-reviews.html">
     Analyzing Dutch restaurant reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/prepare-restoreviews-dataset.html">
     Fetch and prepare reviews
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-pipeline-example.html">
     Objective
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/language-detection-with-character-quadgrams.html">
     Extra: language detection with character quadgrams
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../nlp/nlp-model-sizes.html">
     Extra: plot of transformer model sizes
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/jads-nl/data-science-foundation-in-python/main?urlpath=tree/data_science_foundation_in_python/handson-ml2/original/05_support_vector_machines.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/jads-nl/data-science-foundation-in-python/blob/main/data_science_foundation_in_python/handson-ml2/original/05_support_vector_machines.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-in-python"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/jads-nl/data-science-foundation-in-python/issues/new?title=Issue%20on%20page%20%2Fhandson-ml2/original/05_support_vector_machines.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/handson-ml2/original/05_support_vector_machines.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 5 – Support Vector Machines
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-svm-classification">
   Linear SVM Classification
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#soft-margin-classification">
     Soft Margin Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nonlinear-svm-classification">
   Nonlinear SVM Classification
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#polynomial-kernel">
     Polynomial Kernel
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similarity-features">
     Similarity Features
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-rbf-kernel">
     Gaussian RBF Kernel
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-regression">
   SVM Regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#under-the-hood">
   Under the Hood
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-function-and-predictions">
     Decision Function and Predictions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extra-material">
   Extra material
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-time">
     Training time
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-svm-classifier-implementation-using-batch-gradient-descent">
     Linear SVM classifier implementation using Batch Gradient Descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-7">
     1. to 7.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   8.
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   9.
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     10.
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Chapter 5 – Support Vector Machines</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Chapter 5 – Support Vector Machines
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-svm-classification">
   Linear SVM Classification
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#soft-margin-classification">
     Soft Margin Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nonlinear-svm-classification">
   Nonlinear SVM Classification
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#polynomial-kernel">
     Polynomial Kernel
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#similarity-features">
     Similarity Features
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gaussian-rbf-kernel">
     Gaussian RBF Kernel
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm-regression">
   SVM Regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#under-the-hood">
   Under the Hood
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#decision-function-and-predictions">
     Decision Function and Predictions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#extra-material">
   Extra material
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-time">
     Training time
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-svm-classifier-implementation-using-batch-gradient-descent">
     Linear SVM classifier implementation using Batch Gradient Descent
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercise-solutions">
   Exercise solutions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#to-7">
     1. to 7.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   8.
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   9.
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     10.
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-5-support-vector-machines">
<h1>Chapter 5 – Support Vector Machines<a class="headerlink" href="#chapter-5-support-vector-machines" title="Permalink to this headline">#</a></h1>
<p><em>This notebook contains all the sample code and solutions to the exercises in chapter 5.</em></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">#</a></h1>
<p>First, let’s import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Python ≥3.5 is required
import sys
assert sys.version_info &gt;= (3, 5)

# Scikit-Learn ≥0.20 is required
import sklearn
assert sklearn.__version__ &gt;= &quot;0.20&quot;

# Common imports
import numpy as np
import os

# to make this notebook&#39;s output stable across runs
np.random.seed(42)

# To plot pretty figures
%matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc(&#39;axes&#39;, labelsize=14)
mpl.rc(&#39;xtick&#39;, labelsize=12)
mpl.rc(&#39;ytick&#39;, labelsize=12)

# Where to save the figures
PROJECT_ROOT_DIR = &quot;.&quot;
CHAPTER_ID = &quot;svm&quot;
IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, &quot;images&quot;, CHAPTER_ID)
os.makedirs(IMAGES_PATH, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension=&quot;png&quot;, resolution=300):
    path = os.path.join(IMAGES_PATH, fig_id + &quot;.&quot; + fig_extension)
    print(&quot;Saving figure&quot;, fig_id)
    if tight_layout:
        plt.tight_layout()
    plt.savefig(path, format=fig_extension, dpi=resolution)
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="linear-svm-classification">
<h1>Linear SVM Classification<a class="headerlink" href="#linear-svm-classification" title="Permalink to this headline">#</a></h1>
<p>The next few code cells generate the first figures in chapter 5. The first actual code sample comes after.</p>
<p><strong>Code to generate Figure 5–1. Large margin classification</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVC
from sklearn import datasets

iris = datasets.load_iris()
X = iris[&quot;data&quot;][:, (2, 3)]  # petal length, petal width
y = iris[&quot;target&quot;]

setosa_or_versicolor = (y == 0) | (y == 1)
X = X[setosa_or_versicolor]
y = y[setosa_or_versicolor]

# SVM Classifier model
svm_clf = SVC(kernel=&quot;linear&quot;, C=float(&quot;inf&quot;))
svm_clf.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVC(C=inf, kernel=&#39;linear&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Bad models
x0 = np.linspace(0, 5.5, 200)
pred_1 = 5*x0 - 20
pred_2 = x0 - 1.8
pred_3 = 0.1 * x0 + 0.5

def plot_svc_decision_boundary(svm_clf, xmin, xmax):
    w = svm_clf.coef_[0]
    b = svm_clf.intercept_[0]

    # At the decision boundary, w0*x0 + w1*x1 + b = 0
    # =&gt; x1 = -w0/w1 * x0 - b/w1
    x0 = np.linspace(xmin, xmax, 200)
    decision_boundary = -w[0]/w[1] * x0 - b/w[1]

    margin = 1/w[1]
    gutter_up = decision_boundary + margin
    gutter_down = decision_boundary - margin

    svs = svm_clf.support_vectors_
    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors=&#39;#FFAAAA&#39;)
    plt.plot(x0, decision_boundary, &quot;k-&quot;, linewidth=2)
    plt.plot(x0, gutter_up, &quot;k--&quot;, linewidth=2)
    plt.plot(x0, gutter_down, &quot;k--&quot;, linewidth=2)

fig, axes = plt.subplots(ncols=2, figsize=(10,2.7), sharey=True)

plt.sca(axes[0])
plt.plot(x0, pred_1, &quot;g--&quot;, linewidth=2)
plt.plot(x0, pred_2, &quot;m-&quot;, linewidth=2)
plt.plot(x0, pred_3, &quot;r-&quot;, linewidth=2)
plt.plot(X[:, 0][y==1], X[:, 1][y==1], &quot;bs&quot;, label=&quot;Iris versicolor&quot;)
plt.plot(X[:, 0][y==0], X[:, 1][y==0], &quot;yo&quot;, label=&quot;Iris setosa&quot;)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.legend(loc=&quot;upper left&quot;, fontsize=14)
plt.axis([0, 5.5, 0, 2])

plt.sca(axes[1])
plot_svc_decision_boundary(svm_clf, 0, 5.5)
plt.plot(X[:, 0][y==1], X[:, 1][y==1], &quot;bs&quot;)
plt.plot(X[:, 0][y==0], X[:, 1][y==0], &quot;yo&quot;)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.axis([0, 5.5, 0, 2])

save_fig(&quot;large_margin_classification_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure large_margin_classification_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_7_1.png" src="../../_images/05_support_vector_machines_7_1.png" />
</div>
</div>
<p><strong>Code to generate Figure 5–2. Sensitivity to feature scales</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>Xs = np.array([[1, 50], [5, 20], [3, 80], [5, 60]]).astype(np.float64)
ys = np.array([0, 0, 1, 1])
svm_clf = SVC(kernel=&quot;linear&quot;, C=100)
svm_clf.fit(Xs, ys)

plt.figure(figsize=(9,2.7))
plt.subplot(121)
plt.plot(Xs[:, 0][ys==1], Xs[:, 1][ys==1], &quot;bo&quot;)
plt.plot(Xs[:, 0][ys==0], Xs[:, 1][ys==0], &quot;ms&quot;)
plot_svc_decision_boundary(svm_clf, 0, 6)
plt.xlabel(&quot;$x_0$&quot;, fontsize=20)
plt.ylabel(&quot;$x_1$    &quot;, fontsize=20, rotation=0)
plt.title(&quot;Unscaled&quot;, fontsize=16)
plt.axis([0, 6, 0, 90])

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(Xs)
svm_clf.fit(X_scaled, ys)

plt.subplot(122)
plt.plot(X_scaled[:, 0][ys==1], X_scaled[:, 1][ys==1], &quot;bo&quot;)
plt.plot(X_scaled[:, 0][ys==0], X_scaled[:, 1][ys==0], &quot;ms&quot;)
plot_svc_decision_boundary(svm_clf, -2, 2)
plt.xlabel(&quot;$x&#39;_0$&quot;, fontsize=20)
plt.ylabel(&quot;$x&#39;_1$  &quot;, fontsize=20, rotation=0)
plt.title(&quot;Scaled&quot;, fontsize=16)
plt.axis([-2, 2, -2, 2])

save_fig(&quot;sensitivity_to_feature_scales_plot&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure sensitivity_to_feature_scales_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_9_1.png" src="../../_images/05_support_vector_machines_9_1.png" />
</div>
</div>
<section id="soft-margin-classification">
<h2>Soft Margin Classification<a class="headerlink" href="#soft-margin-classification" title="Permalink to this headline">#</a></h2>
<p><strong>Code to generate Figure 5–3. Hard margin sensitivity to outliers</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X_outliers = np.array([[3.4, 1.3], [3.2, 0.8]])
y_outliers = np.array([0, 0])
Xo1 = np.concatenate([X, X_outliers[:1]], axis=0)
yo1 = np.concatenate([y, y_outliers[:1]], axis=0)
Xo2 = np.concatenate([X, X_outliers[1:]], axis=0)
yo2 = np.concatenate([y, y_outliers[1:]], axis=0)

svm_clf2 = SVC(kernel=&quot;linear&quot;, C=10**9)
svm_clf2.fit(Xo2, yo2)

fig, axes = plt.subplots(ncols=2, figsize=(10,2.7), sharey=True)

plt.sca(axes[0])
plt.plot(Xo1[:, 0][yo1==1], Xo1[:, 1][yo1==1], &quot;bs&quot;)
plt.plot(Xo1[:, 0][yo1==0], Xo1[:, 1][yo1==0], &quot;yo&quot;)
plt.text(0.3, 1.0, &quot;Impossible!&quot;, fontsize=24, color=&quot;red&quot;)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.annotate(&quot;Outlier&quot;,
             xy=(X_outliers[0][0], X_outliers[0][1]),
             xytext=(2.5, 1.7),
             ha=&quot;center&quot;,
             arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.1),
             fontsize=16,
            )
plt.axis([0, 5.5, 0, 2])

plt.sca(axes[1])
plt.plot(Xo2[:, 0][yo2==1], Xo2[:, 1][yo2==1], &quot;bs&quot;)
plt.plot(Xo2[:, 0][yo2==0], Xo2[:, 1][yo2==0], &quot;yo&quot;)
plot_svc_decision_boundary(svm_clf2, 0, 5.5)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.annotate(&quot;Outlier&quot;,
             xy=(X_outliers[1][0], X_outliers[1][1]),
             xytext=(3.2, 0.08),
             ha=&quot;center&quot;,
             arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.1),
             fontsize=16,
            )
plt.axis([0, 5.5, 0, 2])

save_fig(&quot;sensitivity_to_outliers_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure sensitivity_to_outliers_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_11_1.png" src="../../_images/05_support_vector_machines_11_1.png" />
</div>
</div>
<p><strong>This is the first code example in chapter 5:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import numpy as np
from sklearn import datasets
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import LinearSVC

iris = datasets.load_iris()
X = iris[&quot;data&quot;][:, (2, 3)]  # petal length, petal width
y = (iris[&quot;target&quot;] == 2).astype(np.float64)  # Iris virginica

svm_clf = Pipeline([
        (&quot;scaler&quot;, StandardScaler()),
        (&quot;linear_svc&quot;, LinearSVC(C=1, loss=&quot;hinge&quot;, random_state=42)),
    ])

svm_clf.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;linear_svc&#39;, LinearSVC(C=1, loss=&#39;hinge&#39;, random_state=42))])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm_clf.predict([[5.5, 1.7]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.])
</pre></div>
</div>
</div>
</div>
<p><strong>Code to generate Figure 5–4. Large margin versus fewer margin violations</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>scaler = StandardScaler()
svm_clf1 = LinearSVC(C=1, loss=&quot;hinge&quot;, random_state=42)
svm_clf2 = LinearSVC(C=100, loss=&quot;hinge&quot;, random_state=42)

scaled_svm_clf1 = Pipeline([
        (&quot;scaler&quot;, scaler),
        (&quot;linear_svc&quot;, svm_clf1),
    ])
scaled_svm_clf2 = Pipeline([
        (&quot;scaler&quot;, scaler),
        (&quot;linear_svc&quot;, svm_clf2),
    ])

scaled_svm_clf1.fit(X, y)
scaled_svm_clf2.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  &quot;the number of iterations.&quot;, ConvergenceWarning)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;linear_svc&#39;,
                 LinearSVC(C=100, loss=&#39;hinge&#39;, random_state=42))])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Convert to unscaled parameters
b1 = svm_clf1.decision_function([-scaler.mean_ / scaler.scale_])
b2 = svm_clf2.decision_function([-scaler.mean_ / scaler.scale_])
w1 = svm_clf1.coef_[0] / scaler.scale_
w2 = svm_clf2.coef_[0] / scaler.scale_
svm_clf1.intercept_ = np.array([b1])
svm_clf2.intercept_ = np.array([b2])
svm_clf1.coef_ = np.array([w1])
svm_clf2.coef_ = np.array([w2])

# Find support vectors (LinearSVC does not do this automatically)
t = y * 2 - 1
support_vectors_idx1 = (t * (X.dot(w1) + b1) &lt; 1).ravel()
support_vectors_idx2 = (t * (X.dot(w2) + b2) &lt; 1).ravel()
svm_clf1.support_vectors_ = X[support_vectors_idx1]
svm_clf2.support_vectors_ = X[support_vectors_idx2]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, axes = plt.subplots(ncols=2, figsize=(10,2.7), sharey=True)

plt.sca(axes[0])
plt.plot(X[:, 0][y==1], X[:, 1][y==1], &quot;g^&quot;, label=&quot;Iris virginica&quot;)
plt.plot(X[:, 0][y==0], X[:, 1][y==0], &quot;bs&quot;, label=&quot;Iris versicolor&quot;)
plot_svc_decision_boundary(svm_clf1, 4, 5.9)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.legend(loc=&quot;upper left&quot;, fontsize=14)
plt.title(&quot;$C = {}$&quot;.format(svm_clf1.C), fontsize=16)
plt.axis([4, 5.9, 0.8, 2.8])

plt.sca(axes[1])
plt.plot(X[:, 0][y==1], X[:, 1][y==1], &quot;g^&quot;)
plt.plot(X[:, 0][y==0], X[:, 1][y==0], &quot;bs&quot;)
plot_svc_decision_boundary(svm_clf2, 4, 5.99)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.title(&quot;$C = {}$&quot;.format(svm_clf2.C), fontsize=16)
plt.axis([4, 5.9, 0.8, 2.8])

save_fig(&quot;regularization_plot&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure regularization_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_18_1.png" src="../../_images/05_support_vector_machines_18_1.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="nonlinear-svm-classification">
<h1>Nonlinear SVM Classification<a class="headerlink" href="#nonlinear-svm-classification" title="Permalink to this headline">#</a></h1>
<p><strong>Code to generate Figure 5–5. Adding features to make a dataset linearly separable</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X1D = np.linspace(-4, 4, 9).reshape(-1, 1)
X2D = np.c_[X1D, X1D**2]
y = np.array([0, 0, 1, 1, 1, 1, 1, 0, 0])

plt.figure(figsize=(10, 3))

plt.subplot(121)
plt.grid(True, which=&#39;both&#39;)
plt.axhline(y=0, color=&#39;k&#39;)
plt.plot(X1D[:, 0][y==0], np.zeros(4), &quot;bs&quot;)
plt.plot(X1D[:, 0][y==1], np.zeros(5), &quot;g^&quot;)
plt.gca().get_yaxis().set_ticks([])
plt.xlabel(r&quot;$x_1$&quot;, fontsize=20)
plt.axis([-4.5, 4.5, -0.2, 0.2])

plt.subplot(122)
plt.grid(True, which=&#39;both&#39;)
plt.axhline(y=0, color=&#39;k&#39;)
plt.axvline(x=0, color=&#39;k&#39;)
plt.plot(X2D[:, 0][y==0], X2D[:, 1][y==0], &quot;bs&quot;)
plt.plot(X2D[:, 0][y==1], X2D[:, 1][y==1], &quot;g^&quot;)
plt.xlabel(r&quot;$x_1$&quot;, fontsize=20)
plt.ylabel(r&quot;$x_2$  &quot;, fontsize=20, rotation=0)
plt.gca().get_yaxis().set_ticks([0, 4, 8, 12, 16])
plt.plot([-4.5, 4.5], [6.5, 6.5], &quot;r--&quot;, linewidth=3)
plt.axis([-4.5, 4.5, -1, 17])

plt.subplots_adjust(right=1)

save_fig(&quot;higher_dimensions_plot&quot;, tight_layout=False)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure higher_dimensions_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_21_1.png" src="../../_images/05_support_vector_machines_21_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.datasets import make_moons
X, y = make_moons(n_samples=100, noise=0.15, random_state=42)

def plot_dataset(X, y, axes):
    plt.plot(X[:, 0][y==0], X[:, 1][y==0], &quot;bs&quot;)
    plt.plot(X[:, 0][y==1], X[:, 1][y==1], &quot;g^&quot;)
    plt.axis(axes)
    plt.grid(True, which=&#39;both&#39;)
    plt.xlabel(r&quot;$x_1$&quot;, fontsize=20)
    plt.ylabel(r&quot;$x_2$&quot;, fontsize=20, rotation=0)

plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05_support_vector_machines_22_0.png" src="../../_images/05_support_vector_machines_22_0.png" />
</div>
</div>
<p><strong>Here is second code example in the chapter:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.datasets import make_moons
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures

polynomial_svm_clf = Pipeline([
        (&quot;poly_features&quot;, PolynomialFeatures(degree=3)),
        (&quot;scaler&quot;, StandardScaler()),
        (&quot;svm_clf&quot;, LinearSVC(C=10, loss=&quot;hinge&quot;, random_state=42))
    ])

polynomial_svm_clf.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  &quot;the number of iterations.&quot;, ConvergenceWarning)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;poly_features&#39;, PolynomialFeatures(degree=3)),
                (&#39;scaler&#39;, StandardScaler()),
                (&#39;svm_clf&#39;, LinearSVC(C=10, loss=&#39;hinge&#39;, random_state=42))])
</pre></div>
</div>
</div>
</div>
<p><strong>Code to generate Figure 5–6. Linear SVM classifier using polynomial features</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_predictions(clf, axes):
    x0s = np.linspace(axes[0], axes[1], 100)
    x1s = np.linspace(axes[2], axes[3], 100)
    x0, x1 = np.meshgrid(x0s, x1s)
    X = np.c_[x0.ravel(), x1.ravel()]
    y_pred = clf.predict(X).reshape(x0.shape)
    y_decision = clf.decision_function(X).reshape(x0.shape)
    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)
    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)

plot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])
plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])

save_fig(&quot;moons_polynomial_svc_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure moons_polynomial_svc_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_26_1.png" src="../../_images/05_support_vector_machines_26_1.png" />
</div>
</div>
<section id="polynomial-kernel">
<h2>Polynomial Kernel<a class="headerlink" href="#polynomial-kernel" title="Permalink to this headline">#</a></h2>
<p><strong>Next code example:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVC

poly_kernel_svm_clf = Pipeline([
        (&quot;scaler&quot;, StandardScaler()),
        (&quot;svm_clf&quot;, SVC(kernel=&quot;poly&quot;, degree=3, coef0=1, C=5))
    ])
poly_kernel_svm_clf.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;svm_clf&#39;, SVC(C=5, coef0=1, kernel=&#39;poly&#39;))])
</pre></div>
</div>
</div>
</div>
<p><strong>Code to generate Figure 5–7. SVM classifiers with a polynomial kernel</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>poly100_kernel_svm_clf = Pipeline([
        (&quot;scaler&quot;, StandardScaler()),
        (&quot;svm_clf&quot;, SVC(kernel=&quot;poly&quot;, degree=10, coef0=100, C=5))
    ])
poly100_kernel_svm_clf.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;svm_clf&#39;, SVC(C=5, coef0=100, degree=10, kernel=&#39;poly&#39;))])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, axes = plt.subplots(ncols=2, figsize=(10.5, 4), sharey=True)

plt.sca(axes[0])
plot_predictions(poly_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])
plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])
plt.title(r&quot;$d=3, r=1, C=5$&quot;, fontsize=18)

plt.sca(axes[1])
plot_predictions(poly100_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])
plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])
plt.title(r&quot;$d=10, r=100, C=5$&quot;, fontsize=18)
plt.ylabel(&quot;&quot;)

save_fig(&quot;moons_kernelized_polynomial_svc_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure moons_kernelized_polynomial_svc_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_32_1.png" src="../../_images/05_support_vector_machines_32_1.png" />
</div>
</div>
</section>
<section id="similarity-features">
<h2>Similarity Features<a class="headerlink" href="#similarity-features" title="Permalink to this headline">#</a></h2>
<p><strong>Code to generate Figure 5–8. Similarity features using the Gaussian RBF</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def gaussian_rbf(x, landmark, gamma):
    return np.exp(-gamma * np.linalg.norm(x - landmark, axis=1)**2)

gamma = 0.3

x1s = np.linspace(-4.5, 4.5, 200).reshape(-1, 1)
x2s = gaussian_rbf(x1s, -2, gamma)
x3s = gaussian_rbf(x1s, 1, gamma)

XK = np.c_[gaussian_rbf(X1D, -2, gamma), gaussian_rbf(X1D, 1, gamma)]
yk = np.array([0, 0, 1, 1, 1, 1, 1, 0, 0])

plt.figure(figsize=(10.5, 4))

plt.subplot(121)
plt.grid(True, which=&#39;both&#39;)
plt.axhline(y=0, color=&#39;k&#39;)
plt.scatter(x=[-2, 1], y=[0, 0], s=150, alpha=0.5, c=&quot;red&quot;)
plt.plot(X1D[:, 0][yk==0], np.zeros(4), &quot;bs&quot;)
plt.plot(X1D[:, 0][yk==1], np.zeros(5), &quot;g^&quot;)
plt.plot(x1s, x2s, &quot;g--&quot;)
plt.plot(x1s, x3s, &quot;b:&quot;)
plt.gca().get_yaxis().set_ticks([0, 0.25, 0.5, 0.75, 1])
plt.xlabel(r&quot;$x_1$&quot;, fontsize=20)
plt.ylabel(r&quot;Similarity&quot;, fontsize=14)
plt.annotate(r&#39;$\mathbf{x}$&#39;,
             xy=(X1D[3, 0], 0),
             xytext=(-0.5, 0.20),
             ha=&quot;center&quot;,
             arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.1),
             fontsize=18,
            )
plt.text(-2, 0.9, &quot;$x_2$&quot;, ha=&quot;center&quot;, fontsize=20)
plt.text(1, 0.9, &quot;$x_3$&quot;, ha=&quot;center&quot;, fontsize=20)
plt.axis([-4.5, 4.5, -0.1, 1.1])

plt.subplot(122)
plt.grid(True, which=&#39;both&#39;)
plt.axhline(y=0, color=&#39;k&#39;)
plt.axvline(x=0, color=&#39;k&#39;)
plt.plot(XK[:, 0][yk==0], XK[:, 1][yk==0], &quot;bs&quot;)
plt.plot(XK[:, 0][yk==1], XK[:, 1][yk==1], &quot;g^&quot;)
plt.xlabel(r&quot;$x_2$&quot;, fontsize=20)
plt.ylabel(r&quot;$x_3$  &quot;, fontsize=20, rotation=0)
plt.annotate(r&#39;$\phi\left(\mathbf{x}\right)$&#39;,
             xy=(XK[3, 0], XK[3, 1]),
             xytext=(0.65, 0.50),
             ha=&quot;center&quot;,
             arrowprops=dict(facecolor=&#39;black&#39;, shrink=0.1),
             fontsize=18,
            )
plt.plot([-0.1, 1.1], [0.57, -0.1], &quot;r--&quot;, linewidth=3)
plt.axis([-0.1, 1.1, -0.1, 1.1])
    
plt.subplots_adjust(right=1)

save_fig(&quot;kernel_method_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure kernel_method_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_35_1.png" src="../../_images/05_support_vector_machines_35_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>x1_example = X1D[3, 0]
for landmark in (-2, 1):
    k = gaussian_rbf(np.array([[x1_example]]), np.array([[landmark]]), gamma)
    print(&quot;Phi({}, {}) = {}&quot;.format(x1_example, landmark, k))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Phi(-1.0, -2) = [0.74081822]
Phi(-1.0, 1) = [0.30119421]
</pre></div>
</div>
</div>
</div>
</section>
<section id="gaussian-rbf-kernel">
<h2>Gaussian RBF Kernel<a class="headerlink" href="#gaussian-rbf-kernel" title="Permalink to this headline">#</a></h2>
<p><strong>Next code example:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rbf_kernel_svm_clf = Pipeline([
        (&quot;scaler&quot;, StandardScaler()),
        (&quot;svm_clf&quot;, SVC(kernel=&quot;rbf&quot;, gamma=5, C=0.001))
    ])
rbf_kernel_svm_clf.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;svm_clf&#39;, SVC(C=0.001, gamma=5))])
</pre></div>
</div>
</div>
</div>
<p><strong>Code to generate Figure 5–9. SVM classifiers using an RBF kernel</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVC

gamma1, gamma2 = 0.1, 5
C1, C2 = 0.001, 1000
hyperparams = (gamma1, C1), (gamma1, C2), (gamma2, C1), (gamma2, C2)

svm_clfs = []
for gamma, C in hyperparams:
    rbf_kernel_svm_clf = Pipeline([
            (&quot;scaler&quot;, StandardScaler()),
            (&quot;svm_clf&quot;, SVC(kernel=&quot;rbf&quot;, gamma=gamma, C=C))
        ])
    rbf_kernel_svm_clf.fit(X, y)
    svm_clfs.append(rbf_kernel_svm_clf)

fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10.5, 7), sharex=True, sharey=True)

for i, svm_clf in enumerate(svm_clfs):
    plt.sca(axes[i // 2, i % 2])
    plot_predictions(svm_clf, [-1.5, 2.45, -1, 1.5])
    plot_dataset(X, y, [-1.5, 2.45, -1, 1.5])
    gamma, C = hyperparams[i]
    plt.title(r&quot;$\gamma = {}, C = {}$&quot;.format(gamma, C), fontsize=16)
    if i in (0, 1):
        plt.xlabel(&quot;&quot;)
    if i in (1, 3):
        plt.ylabel(&quot;&quot;)

save_fig(&quot;moons_rbf_svc_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure moons_rbf_svc_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_41_1.png" src="../../_images/05_support_vector_machines_41_1.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="svm-regression">
<h1>SVM Regression<a class="headerlink" href="#svm-regression" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
m = 50
X = 2 * np.random.rand(m, 1)
y = (4 + 3 * X + np.random.randn(m, 1)).ravel()
</pre></div>
</div>
</div>
</div>
<p><strong>Next code example:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import LinearSVR

svm_reg = LinearSVR(epsilon=1.5, random_state=42)
svm_reg.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearSVR(epsilon=1.5, random_state=42)
</pre></div>
</div>
</div>
</div>
<p><strong>Code to generate Figure 5–10. SVM Regression</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm_reg1 = LinearSVR(epsilon=1.5, random_state=42)
svm_reg2 = LinearSVR(epsilon=0.5, random_state=42)
svm_reg1.fit(X, y)
svm_reg2.fit(X, y)

def find_support_vectors(svm_reg, X, y):
    y_pred = svm_reg.predict(X)
    off_margin = (np.abs(y - y_pred) &gt;= svm_reg.epsilon)
    return np.argwhere(off_margin)

svm_reg1.support_ = find_support_vectors(svm_reg1, X, y)
svm_reg2.support_ = find_support_vectors(svm_reg2, X, y)

eps_x1 = 1
eps_y_pred = svm_reg1.predict([[eps_x1]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_svm_regression(svm_reg, X, y, axes):
    x1s = np.linspace(axes[0], axes[1], 100).reshape(100, 1)
    y_pred = svm_reg.predict(x1s)
    plt.plot(x1s, y_pred, &quot;k-&quot;, linewidth=2, label=r&quot;$\hat{y}$&quot;)
    plt.plot(x1s, y_pred + svm_reg.epsilon, &quot;k--&quot;)
    plt.plot(x1s, y_pred - svm_reg.epsilon, &quot;k--&quot;)
    plt.scatter(X[svm_reg.support_], y[svm_reg.support_], s=180, facecolors=&#39;#FFAAAA&#39;)
    plt.plot(X, y, &quot;bo&quot;)
    plt.xlabel(r&quot;$x_1$&quot;, fontsize=18)
    plt.legend(loc=&quot;upper left&quot;, fontsize=18)
    plt.axis(axes)

fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)
plt.sca(axes[0])
plot_svm_regression(svm_reg1, X, y, [0, 2, 3, 11])
plt.title(r&quot;$\epsilon = {}$&quot;.format(svm_reg1.epsilon), fontsize=18)
plt.ylabel(r&quot;$y$&quot;, fontsize=18, rotation=0)
#plt.plot([eps_x1, eps_x1], [eps_y_pred, eps_y_pred - svm_reg1.epsilon], &quot;k-&quot;, linewidth=2)
plt.annotate(
        &#39;&#39;, xy=(eps_x1, eps_y_pred), xycoords=&#39;data&#39;,
        xytext=(eps_x1, eps_y_pred - svm_reg1.epsilon),
        textcoords=&#39;data&#39;, arrowprops={&#39;arrowstyle&#39;: &#39;&lt;-&gt;&#39;, &#39;linewidth&#39;: 1.5}
    )
plt.text(0.91, 5.6, r&quot;$\epsilon$&quot;, fontsize=20)
plt.sca(axes[1])
plot_svm_regression(svm_reg2, X, y, [0, 2, 3, 11])
plt.title(r&quot;$\epsilon = {}$&quot;.format(svm_reg2.epsilon), fontsize=18)
save_fig(&quot;svm_regression_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure svm_regression_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_48_1.png" src="../../_images/05_support_vector_machines_48_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.random.seed(42)
m = 100
X = 2 * np.random.rand(m, 1) - 1
y = (0.2 + 0.1 * X + 0.5 * X**2 + np.random.randn(m, 1)/10).ravel()
</pre></div>
</div>
</div>
</div>
<p><strong>Note</strong>: to be future-proof, we set <code class="docutils literal notranslate"><span class="pre">gamma=&quot;scale&quot;</span></code>, as this will be the default value in Scikit-Learn 0.22.</p>
<p><strong>Next code example:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVR

svm_poly_reg = SVR(kernel=&quot;poly&quot;, degree=2, C=100, epsilon=0.1, gamma=&quot;scale&quot;)
svm_poly_reg.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVR(C=100, degree=2, kernel=&#39;poly&#39;)
</pre></div>
</div>
</div>
</div>
<p><strong>Code to generate Figure 5–11. SVM Regression using a second-degree polynomial kernel</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVR

svm_poly_reg1 = SVR(kernel=&quot;poly&quot;, degree=2, C=100, epsilon=0.1, gamma=&quot;scale&quot;)
svm_poly_reg2 = SVR(kernel=&quot;poly&quot;, degree=2, C=0.01, epsilon=0.1, gamma=&quot;scale&quot;)
svm_poly_reg1.fit(X, y)
svm_poly_reg2.fit(X, y)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVR(C=0.01, degree=2, kernel=&#39;poly&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)
plt.sca(axes[0])
plot_svm_regression(svm_poly_reg1, X, y, [-1, 1, 0, 1])
plt.title(r&quot;$degree={}, C={}, \epsilon = {}$&quot;.format(svm_poly_reg1.degree, svm_poly_reg1.C, svm_poly_reg1.epsilon), fontsize=18)
plt.ylabel(r&quot;$y$&quot;, fontsize=18, rotation=0)
plt.sca(axes[1])
plot_svm_regression(svm_poly_reg2, X, y, [-1, 1, 0, 1])
plt.title(r&quot;$degree={}, C={}, \epsilon = {}$&quot;.format(svm_poly_reg2.degree, svm_poly_reg2.C, svm_poly_reg2.epsilon), fontsize=18)
save_fig(&quot;svm_with_polynomial_kernel_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure svm_with_polynomial_kernel_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_55_1.png" src="../../_images/05_support_vector_machines_55_1.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="under-the-hood">
<h1>Under the Hood<a class="headerlink" href="#under-the-hood" title="Permalink to this headline">#</a></h1>
<section id="decision-function-and-predictions">
<h2>Decision Function and Predictions<a class="headerlink" href="#decision-function-and-predictions" title="Permalink to this headline">#</a></h2>
<p><strong>Code to generate Figure 5–12. Decision function for the iris dataset</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>iris = datasets.load_iris()
X = iris[&quot;data&quot;][:, (2, 3)]  # petal length, petal width
y = (iris[&quot;target&quot;] == 2).astype(np.float64)  # Iris virginica
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from mpl_toolkits.mplot3d import Axes3D

def plot_3D_decision_function(ax, w, b, x1_lim=[4, 6], x2_lim=[0.8, 2.8]):
    x1_in_bounds = (X[:, 0] &gt; x1_lim[0]) &amp; (X[:, 0] &lt; x1_lim[1])
    X_crop = X[x1_in_bounds]
    y_crop = y[x1_in_bounds]
    x1s = np.linspace(x1_lim[0], x1_lim[1], 20)
    x2s = np.linspace(x2_lim[0], x2_lim[1], 20)
    x1, x2 = np.meshgrid(x1s, x2s)
    xs = np.c_[x1.ravel(), x2.ravel()]
    df = (xs.dot(w) + b).reshape(x1.shape)
    m = 1 / np.linalg.norm(w)
    boundary_x2s = -x1s*(w[0]/w[1])-b/w[1]
    margin_x2s_1 = -x1s*(w[0]/w[1])-(b-1)/w[1]
    margin_x2s_2 = -x1s*(w[0]/w[1])-(b+1)/w[1]
    ax.plot_surface(x1s, x2, np.zeros_like(x1),
                    color=&quot;b&quot;, alpha=0.2, cstride=100, rstride=100)
    ax.plot(x1s, boundary_x2s, 0, &quot;k-&quot;, linewidth=2, label=r&quot;$h=0$&quot;)
    ax.plot(x1s, margin_x2s_1, 0, &quot;k--&quot;, linewidth=2, label=r&quot;$h=\pm 1$&quot;)
    ax.plot(x1s, margin_x2s_2, 0, &quot;k--&quot;, linewidth=2)
    ax.plot(X_crop[:, 0][y_crop==1], X_crop[:, 1][y_crop==1], 0, &quot;g^&quot;)
    ax.plot_wireframe(x1, x2, df, alpha=0.3, color=&quot;k&quot;)
    ax.plot(X_crop[:, 0][y_crop==0], X_crop[:, 1][y_crop==0], 0, &quot;bs&quot;)
    ax.axis(x1_lim + x2_lim)
    ax.text(4.5, 2.5, 3.8, &quot;Decision function $h$&quot;, fontsize=16)
    ax.set_xlabel(r&quot;Petal length&quot;, fontsize=16, labelpad=10)
    ax.set_ylabel(r&quot;Petal width&quot;, fontsize=16, labelpad=10)
    ax.set_zlabel(r&quot;$h = \mathbf{w}^T \mathbf{x} + b$&quot;, fontsize=18, labelpad=5)
    ax.legend(loc=&quot;upper left&quot;, fontsize=16)

fig = plt.figure(figsize=(11, 6))
ax1 = fig.add_subplot(111, projection=&#39;3d&#39;)
plot_3D_decision_function(ax1, w=svm_clf2.coef_[0], b=svm_clf2.intercept_[0])

save_fig(&quot;iris_3D_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure iris_3D_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_59_1.png" src="../../_images/05_support_vector_machines_59_1.png" />
</div>
</div>
<p><strong>Code to generate Figure 5–13. A smaller weight vector results in a larger margin</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_2D_decision_function(w, b, ylabel=True, x1_lim=[-3, 3]):
    x1 = np.linspace(x1_lim[0], x1_lim[1], 200)
    y = w * x1 + b
    m = 1 / w

    plt.plot(x1, y)
    plt.plot(x1_lim, [1, 1], &quot;k:&quot;)
    plt.plot(x1_lim, [-1, -1], &quot;k:&quot;)
    plt.axhline(y=0, color=&#39;k&#39;)
    plt.axvline(x=0, color=&#39;k&#39;)
    plt.plot([m, m], [0, 1], &quot;k--&quot;)
    plt.plot([-m, -m], [0, -1], &quot;k--&quot;)
    plt.plot([-m, m], [0, 0], &quot;k-o&quot;, linewidth=3)
    plt.axis(x1_lim + [-2, 2])
    plt.xlabel(r&quot;$x_1$&quot;, fontsize=16)
    if ylabel:
        plt.ylabel(r&quot;$w_1 x_1$  &quot;, rotation=0, fontsize=16)
    plt.title(r&quot;$w_1 = {}$&quot;.format(w), fontsize=16)

fig, axes = plt.subplots(ncols=2, figsize=(9, 3.2), sharey=True)
plt.sca(axes[0])
plot_2D_decision_function(1, 0)
plt.sca(axes[1])
plot_2D_decision_function(0.5, 0, ylabel=False)
save_fig(&quot;small_w_large_margin_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure small_w_large_margin_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_61_1.png" src="../../_images/05_support_vector_machines_61_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVC
from sklearn import datasets

iris = datasets.load_iris()
X = iris[&quot;data&quot;][:, (2, 3)] # petal length, petal width
y = (iris[&quot;target&quot;] == 2).astype(np.float64) # Iris virginica

svm_clf = SVC(kernel=&quot;linear&quot;, C=1)
svm_clf.fit(X, y)
svm_clf.predict([[5.3, 1.3]])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.])
</pre></div>
</div>
</div>
</div>
<p><strong>Code to generate the Hinge Loss figure:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>t = np.linspace(-2, 4, 200)
h = np.where(1 - t &lt; 0, 0, 1 - t)  # max(0, 1-t)

plt.figure(figsize=(5,2.8))
plt.plot(t, h, &quot;b-&quot;, linewidth=2, label=&quot;$max(0, 1 - t)$&quot;)
plt.grid(True, which=&#39;both&#39;)
plt.axhline(y=0, color=&#39;k&#39;)
plt.axvline(x=0, color=&#39;k&#39;)
plt.yticks(np.arange(-1, 2.5, 1))
plt.xlabel(&quot;$t$&quot;, fontsize=16)
plt.axis([-2, 4, -1, 2.5])
plt.legend(loc=&quot;upper right&quot;, fontsize=16)
save_fig(&quot;hinge_plot&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Saving figure hinge_plot
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_64_1.png" src="../../_images/05_support_vector_machines_64_1.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="extra-material">
<h1>Extra material<a class="headerlink" href="#extra-material" title="Permalink to this headline">#</a></h1>
<section id="training-time">
<h2>Training time<a class="headerlink" href="#training-time" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>X, y = make_moons(n_samples=1000, noise=0.4, random_state=42)
plt.plot(X[:, 0][y==0], X[:, 1][y==0], &quot;bs&quot;)
plt.plot(X[:, 0][y==1], X[:, 1][y==1], &quot;g^&quot;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7f936084ecd0&gt;]
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_67_1.png" src="../../_images/05_support_vector_machines_67_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import time

tol = 0.1
tols = []
times = []
for i in range(10):
    svm_clf = SVC(kernel=&quot;poly&quot;, gamma=3, C=10, tol=tol, verbose=1)
    t1 = time.time()
    svm_clf.fit(X, y)
    t2 = time.time()
    times.append(t2-t1)
    tols.append(tol)
    print(i, tol, t2-t1)
    tol /= 10
plt.semilogx(tols, times, &quot;bo-&quot;)
plt.xlabel(&quot;Tolerance&quot;, fontsize=16)
plt.ylabel(&quot;Time (seconds)&quot;, fontsize=16)
plt.grid(True)
plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[LibSVM]0 0.1 0.2017989158630371
[LibSVM]1 0.01 0.19569611549377441
[LibSVM]2 0.001 0.23690319061279297
[LibSVM]3 0.0001 0.41855812072753906
[LibSVM]4 1e-05 0.7902979850769043
[LibSVM]5 1.0000000000000002e-06 0.6455130577087402
[LibSVM]6 1.0000000000000002e-07 0.7135508060455322
[LibSVM]7 1.0000000000000002e-08 0.7550830841064453
[LibSVM]8 1.0000000000000003e-09 0.8036937713623047
[LibSVM]9 1.0000000000000003e-10 0.7757120132446289
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_68_1.png" src="../../_images/05_support_vector_machines_68_1.png" />
</div>
</div>
</section>
<section id="linear-svm-classifier-implementation-using-batch-gradient-descent">
<h2>Linear SVM classifier implementation using Batch Gradient Descent<a class="headerlink" href="#linear-svm-classifier-implementation-using-batch-gradient-descent" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Training set
X = iris[&quot;data&quot;][:, (2, 3)] # petal length, petal width
y = (iris[&quot;target&quot;] == 2).astype(np.float64).reshape(-1, 1) # Iris virginica
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.base import BaseEstimator

class MyLinearSVC(BaseEstimator):
    def __init__(self, C=1, eta0=1, eta_d=10000, n_epochs=1000, random_state=None):
        self.C = C
        self.eta0 = eta0
        self.n_epochs = n_epochs
        self.random_state = random_state
        self.eta_d = eta_d

    def eta(self, epoch):
        return self.eta0 / (epoch + self.eta_d)
        
    def fit(self, X, y):
        # Random initialization
        if self.random_state:
            np.random.seed(self.random_state)
        w = np.random.randn(X.shape[1], 1) # n feature weights
        b = 0

        m = len(X)
        t = y * 2 - 1  # -1 if y==0, +1 if y==1
        X_t = X * t
        self.Js=[]

        # Training
        for epoch in range(self.n_epochs):
            support_vectors_idx = (X_t.dot(w) + t * b &lt; 1).ravel()
            X_t_sv = X_t[support_vectors_idx]
            t_sv = t[support_vectors_idx]

            J = 1/2 * np.sum(w * w) + self.C * (np.sum(1 - X_t_sv.dot(w)) - b * np.sum(t_sv))
            self.Js.append(J)

            w_gradient_vector = w - self.C * np.sum(X_t_sv, axis=0).reshape(-1, 1)
            b_derivative = -self.C * np.sum(t_sv)
                
            w = w - self.eta(epoch) * w_gradient_vector
            b = b - self.eta(epoch) * b_derivative
            

        self.intercept_ = np.array([b])
        self.coef_ = np.array([w])
        support_vectors_idx = (X_t.dot(w) + t * b &lt; 1).ravel()
        self.support_vectors_ = X[support_vectors_idx]
        return self

    def decision_function(self, X):
        return X.dot(self.coef_[0]) + self.intercept_[0]

    def predict(self, X):
        return (self.decision_function(X) &gt;= 0).astype(np.float64)

C=2
svm_clf = MyLinearSVC(C=C, eta0 = 10, eta_d = 1000, n_epochs=60000, random_state=2)
svm_clf.fit(X, y)
svm_clf.predict(np.array([[5, 2], [4, 1]]))
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.],
       [0.]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>plt.plot(range(svm_clf.n_epochs), svm_clf.Js)
plt.axis([0, svm_clf.n_epochs, 0, 100])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0, 60000.0, 0.0, 100.0)
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_72_1.png" src="../../_images/05_support_vector_machines_72_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(svm_clf.intercept_, svm_clf.coef_)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-15.56761653] [[[2.28120287]
  [2.71621742]]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm_clf2 = SVC(kernel=&quot;linear&quot;, C=C)
svm_clf2.fit(X, y.ravel())
print(svm_clf2.intercept_, svm_clf2.coef_)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-15.51721253] [[2.27128546 2.71287145]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>yr = y.ravel()
fig, axes = plt.subplots(ncols=2, figsize=(11, 3.2), sharey=True)
plt.sca(axes[0])
plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], &quot;g^&quot;, label=&quot;Iris virginica&quot;)
plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], &quot;bs&quot;, label=&quot;Not Iris virginica&quot;)
plot_svc_decision_boundary(svm_clf, 4, 6)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.title(&quot;MyLinearSVC&quot;, fontsize=14)
plt.axis([4, 6, 0.8, 2.8])
plt.legend(loc=&quot;upper left&quot;)

plt.sca(axes[1])
plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], &quot;g^&quot;)
plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], &quot;bs&quot;)
plot_svc_decision_boundary(svm_clf2, 4, 6)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.title(&quot;SVC&quot;, fontsize=14)
plt.axis([4, 6, 0.8, 2.8])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4.0, 6.0, 0.8, 2.8)
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_75_1.png" src="../../_images/05_support_vector_machines_75_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(loss=&quot;hinge&quot;, alpha=0.017, max_iter=1000, tol=1e-3, random_state=42)
sgd_clf.fit(X, y.ravel())

m = len(X)
t = y * 2 - 1  # -1 if y==0, +1 if y==1
X_b = np.c_[np.ones((m, 1)), X]  # Add bias input x0=1
X_b_t = X_b * t
sgd_theta = np.r_[sgd_clf.intercept_[0], sgd_clf.coef_[0]]
print(sgd_theta)
support_vectors_idx = (X_b_t.dot(sgd_theta) &lt; 1).ravel()
sgd_clf.support_vectors_ = X[support_vectors_idx]
sgd_clf.C = C

plt.figure(figsize=(5.5,3.2))
plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], &quot;g^&quot;)
plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], &quot;bs&quot;)
plot_svc_decision_boundary(sgd_clf, 4, 6)
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.title(&quot;SGDClassifier&quot;, fontsize=14)
plt.axis([4, 6, 0.8, 2.8])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-12.52988101   1.94162342   1.84544824]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4.0, 6.0, 0.8, 2.8)
</pre></div>
</div>
<img alt="../../_images/05_support_vector_machines_76_2.png" src="../../_images/05_support_vector_machines_76_2.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="exercise-solutions">
<h1>Exercise solutions<a class="headerlink" href="#exercise-solutions" title="Permalink to this headline">#</a></h1>
<section id="to-7">
<h2>1. to 7.<a class="headerlink" href="#to-7" title="Permalink to this headline">#</a></h2>
<p>See appendix A.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>8.<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h1>
<p><em>Exercise: train a <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> on a linearly separable dataset. Then train an <code class="docutils literal notranslate"><span class="pre">SVC</span></code> and a <code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code> on the same dataset. See if you can get them to produce roughly the same model.</em></p>
<p>Let’s use the Iris dataset: the Iris Setosa and Iris Versicolor classes are linearly separable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn import datasets

iris = datasets.load_iris()
X = iris[&quot;data&quot;][:, (2, 3)]  # petal length, petal width
y = iris[&quot;target&quot;]

setosa_or_versicolor = (y == 0) | (y == 1)
X = X[setosa_or_versicolor]
y = y[setosa_or_versicolor]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler

C = 5
alpha = 1 / (C * len(X))

lin_clf = LinearSVC(loss=&quot;hinge&quot;, C=C, random_state=42)
svm_clf = SVC(kernel=&quot;linear&quot;, C=C)
sgd_clf = SGDClassifier(loss=&quot;hinge&quot;, learning_rate=&quot;constant&quot;, eta0=0.001, alpha=alpha,
                        max_iter=1000, tol=1e-3, random_state=42)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

lin_clf.fit(X_scaled, y)
svm_clf.fit(X_scaled, y)
sgd_clf.fit(X_scaled, y)

print(&quot;LinearSVC:                   &quot;, lin_clf.intercept_, lin_clf.coef_)
print(&quot;SVC:                         &quot;, svm_clf.intercept_, svm_clf.coef_)
print(&quot;SGDClassifier(alpha={:.5f}):&quot;.format(sgd_clf.alpha), sgd_clf.intercept_, sgd_clf.coef_)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearSVC:                    [0.28475098] [[1.05364854 1.09903804]]
SVC:                          [0.31896852] [[1.1203284  1.02625193]]
SGDClassifier(alpha=0.00200): [0.117] [[0.77714169 0.72981762]]
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the decision boundaries of these three models:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Compute the slope and bias of each decision boundary
w1 = -lin_clf.coef_[0, 0]/lin_clf.coef_[0, 1]
b1 = -lin_clf.intercept_[0]/lin_clf.coef_[0, 1]
w2 = -svm_clf.coef_[0, 0]/svm_clf.coef_[0, 1]
b2 = -svm_clf.intercept_[0]/svm_clf.coef_[0, 1]
w3 = -sgd_clf.coef_[0, 0]/sgd_clf.coef_[0, 1]
b3 = -sgd_clf.intercept_[0]/sgd_clf.coef_[0, 1]

# Transform the decision boundary lines back to the original scale
line1 = scaler.inverse_transform([[-10, -10 * w1 + b1], [10, 10 * w1 + b1]])
line2 = scaler.inverse_transform([[-10, -10 * w2 + b2], [10, 10 * w2 + b2]])
line3 = scaler.inverse_transform([[-10, -10 * w3 + b3], [10, 10 * w3 + b3]])

# Plot all three decision boundaries
plt.figure(figsize=(11, 4))
plt.plot(line1[:, 0], line1[:, 1], &quot;k:&quot;, label=&quot;LinearSVC&quot;)
plt.plot(line2[:, 0], line2[:, 1], &quot;b--&quot;, linewidth=2, label=&quot;SVC&quot;)
plt.plot(line3[:, 0], line3[:, 1], &quot;r-&quot;, label=&quot;SGDClassifier&quot;)
plt.plot(X[:, 0][y==1], X[:, 1][y==1], &quot;bs&quot;) # label=&quot;Iris versicolor&quot;
plt.plot(X[:, 0][y==0], X[:, 1][y==0], &quot;yo&quot;) # label=&quot;Iris setosa&quot;
plt.xlabel(&quot;Petal length&quot;, fontsize=14)
plt.ylabel(&quot;Petal width&quot;, fontsize=14)
plt.legend(loc=&quot;upper center&quot;, fontsize=14)
plt.axis([0, 5.5, 0, 2])

plt.show()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05_support_vector_machines_86_0.png" src="../../_images/05_support_vector_machines_86_0.png" />
</div>
</div>
<p>Close enough!</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="id2">
<h1>9.<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h1>
<p><em>Exercise: train an SVM classifier on the MNIST dataset. Since SVM classifiers are binary classifiers, you will need to use one-versus-all to classify all 10 digits. You may want to tune the hyperparameters using small validation sets to speed up the process. What accuracy can you reach?</em></p>
<p>First, let’s load the dataset and split it into a training set and a test set. We could use <code class="docutils literal notranslate"><span class="pre">train_test_split()</span></code> but people usually just take the first 60,000 instances for the training set, and the last 10,000 instances for the test set (this makes it possible to compare your model’s performance with others):</p>
<p><strong>Warning:</strong> since Scikit-Learn 0.24, <code class="docutils literal notranslate"><span class="pre">fetch_openml()</span></code> returns a Pandas <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> by default. To avoid this, we use <code class="docutils literal notranslate"><span class="pre">as_frame=False</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.datasets import fetch_openml
mnist = fetch_openml(&#39;mnist_784&#39;, version=1, cache=True, as_frame=False)

X = mnist[&quot;data&quot;]
y = mnist[&quot;target&quot;].astype(np.uint8)

X_train = X[:60000]
y_train = y[:60000]
X_test = X[60000:]
y_test = y[60000:]
</pre></div>
</div>
</div>
</div>
<p>Many training algorithms are sensitive to the order of the training instances, so it’s generally good practice to shuffle them first. However, the dataset is already shuffled, so we do not need to do it.</p>
<p>Let’s start simple, with a linear SVM classifier. It will automatically use the One-vs-All (also called One-vs-the-Rest, OvR) strategy, so there’s nothing special we need to do. Easy!</p>
<p><strong>Warning</strong>: this may take a few minutes depending on your hardware.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lin_clf = LinearSVC(random_state=42)
lin_clf.fit(X_train, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  &quot;the number of iterations.&quot;, ConvergenceWarning)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearSVC(random_state=42)
</pre></div>
</div>
</div>
</div>
<p>Let’s make predictions on the training set and measure the accuracy (we don’t want to measure it on the test set yet, since we have not selected and trained the final model yet):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.metrics import accuracy_score

y_pred = lin_clf.predict(X_train)
accuracy_score(y_train, y_pred)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8348666666666666
</pre></div>
</div>
</div>
</div>
<p>Okay, 89.5% accuracy on MNIST is pretty bad. This linear model is certainly too simple for MNIST, but perhaps we just needed to scale the data first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype(np.float32))
X_test_scaled = scaler.transform(X_test.astype(np.float32))
</pre></div>
</div>
</div>
</div>
<p><strong>Warning</strong>: this may take a few minutes depending on your hardware.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>lin_clf = LinearSVC(random_state=42)
lin_clf.fit(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  &quot;the number of iterations.&quot;, ConvergenceWarning)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearSVC(random_state=42)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = lin_clf.predict(X_train_scaled)
accuracy_score(y_train, y_pred)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9217333333333333
</pre></div>
</div>
</div>
</div>
<p>That’s much better (we cut the error rate by about 25%), but still not great at all for MNIST. If we want to use an SVM, we will have to use a kernel. Let’s try an <code class="docutils literal notranslate"><span class="pre">SVC</span></code> with an RBF kernel (the default).</p>
<p><strong>Note</strong>: to be future-proof we set <code class="docutils literal notranslate"><span class="pre">gamma=&quot;scale&quot;</span></code> since it will be the default value in Scikit-Learn 0.22.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>svm_clf = SVC(gamma=&quot;scale&quot;)
svm_clf.fit(X_train_scaled[:10000], y_train[:10000])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVC()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = svm_clf.predict(X_train_scaled)
accuracy_score(y_train, y_pred)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9455333333333333
</pre></div>
</div>
</div>
</div>
<p>That’s promising, we get better performance even though we trained the model on 6 times less data. Let’s tune the hyperparameters by doing a randomized search with cross validation. We will do this on a small dataset just to speed up the process:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import reciprocal, uniform

param_distributions = {&quot;gamma&quot;: reciprocal(0.001, 0.1), &quot;C&quot;: uniform(1, 10)}
rnd_search_cv = RandomizedSearchCV(svm_clf, param_distributions, n_iter=10, verbose=2, cv=3)
rnd_search_cv.fit(X_train_scaled[:1000], y_train[:1000])
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 3 folds for each of 10 candidates, totalling 30 fits
[CV] C=5.847490967837556, gamma=0.004375955271336425 .................
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[CV] .. C=5.847490967837556, gamma=0.004375955271336425, total=   0.8s
[CV] C=5.847490967837556, gamma=0.004375955271336425 .................
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[CV] .. C=5.847490967837556, gamma=0.004375955271336425, total=   0.8s
[CV] C=5.847490967837556, gamma=0.004375955271336425 .................
[CV] .. C=5.847490967837556, gamma=0.004375955271336425, total=   0.8s
[CV] C=2.544266730893301, gamma=0.024987648190235304 .................
[CV] .. C=2.544266730893301, gamma=0.024987648190235304, total=   0.9s
[CV] C=2.544266730893301, gamma=0.024987648190235304 .................
[CV] .. C=2.544266730893301, gamma=0.024987648190235304, total=   0.9s
[CV] C=2.544266730893301, gamma=0.024987648190235304 .................
[CV] .. C=2.544266730893301, gamma=0.024987648190235304, total=   0.9s
[CV] C=2.199505425963898, gamma=0.009340106304825553 .................
[CV] .. C=2.199505425963898, gamma=0.009340106304825553, total=   0.8s
[CV] C=2.199505425963898, gamma=0.009340106304825553 .................
[CV] .. C=2.199505425963898, gamma=0.009340106304825553, total=   0.8s
[CV] C=2.199505425963898, gamma=0.009340106304825553 .................
[CV] .. C=2.199505425963898, gamma=0.009340106304825553, total=   0.9s
[CV] C=7.327377306009368, gamma=0.04329656504133618 ..................
[CV] ... C=7.327377306009368, gamma=0.04329656504133618, total=   0.9s
[CV] C=7.327377306009368, gamma=0.04329656504133618 ..................
[CV] ... C=7.327377306009368, gamma=0.04329656504133618, total=   0.9s
[CV] C=7.327377306009368, gamma=0.04329656504133618 ..................
[CV] ... C=7.327377306009368, gamma=0.04329656504133618, total=   0.9s
[CV] C=7.830259944094713, gamma=0.009933958471354695 .................
[CV] .. C=7.830259944094713, gamma=0.009933958471354695, total=   0.9s
[CV] C=7.830259944094713, gamma=0.009933958471354695 .................
[CV] .. C=7.830259944094713, gamma=0.009933958471354695, total=   0.9s
[CV] C=7.830259944094713, gamma=0.009933958471354695 .................
[CV] .. C=7.830259944094713, gamma=0.009933958471354695, total=   0.9s
[CV] C=6.867969780001033, gamma=0.027511132256566175 .................
[CV] .. C=6.867969780001033, gamma=0.027511132256566175, total=   0.9s
[CV] C=6.867969780001033, gamma=0.027511132256566175 .................
[CV] .. C=6.867969780001033, gamma=0.027511132256566175, total=   0.9s
[CV] C=6.867969780001033, gamma=0.027511132256566175 .................
[CV] .. C=6.867969780001033, gamma=0.027511132256566175, total=   0.9s
[CV] C=3.584980864373988, gamma=0.01237128009623357 ..................
[CV] ... C=3.584980864373988, gamma=0.01237128009623357, total=   0.9s
[CV] C=3.584980864373988, gamma=0.01237128009623357 ..................
[CV] ... C=3.584980864373988, gamma=0.01237128009623357, total=   0.9s
[CV] C=3.584980864373988, gamma=0.01237128009623357 ..................
[CV] ... C=3.584980864373988, gamma=0.01237128009623357, total=   0.9s
[CV] C=5.073078322899452, gamma=0.002259275783824143 .................
[CV] .. C=5.073078322899452, gamma=0.002259275783824143, total=   0.7s
[CV] C=5.073078322899452, gamma=0.002259275783824143 .................
[CV] .. C=5.073078322899452, gamma=0.002259275783824143, total=   0.7s
[CV] C=5.073078322899452, gamma=0.002259275783824143 .................
[CV] .. C=5.073078322899452, gamma=0.002259275783824143, total=   0.7s
[CV] C=10.696324058267928, gamma=0.0039267813006514255 ...............
[CV]  C=10.696324058267928, gamma=0.0039267813006514255, total=   0.8s
[CV] C=10.696324058267928, gamma=0.0039267813006514255 ...............
[CV]  C=10.696324058267928, gamma=0.0039267813006514255, total=   0.8s
[CV] C=10.696324058267928, gamma=0.0039267813006514255 ...............
[CV]  C=10.696324058267928, gamma=0.0039267813006514255, total=   0.8s
[CV] C=3.8786881587000437, gamma=0.0017076019229344522 ...............
[CV]  C=3.8786881587000437, gamma=0.0017076019229344522, total=   0.7s
[CV] C=3.8786881587000437, gamma=0.0017076019229344522 ...............
[CV]  C=3.8786881587000437, gamma=0.0017076019229344522, total=   0.7s
[CV] C=3.8786881587000437, gamma=0.0017076019229344522 ...............
[CV]  C=3.8786881587000437, gamma=0.0017076019229344522, total=   0.7s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   24.8s finished
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RandomizedSearchCV(cv=3, estimator=SVC(),
                   param_distributions={&#39;C&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f93b0a61990&gt;,
                                        &#39;gamma&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f93b0a61850&gt;},
                   verbose=2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rnd_search_cv.best_estimator_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVC(C=3.8786881587000437, gamma=0.0017076019229344522)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rnd_search_cv.best_score_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.8599947252641863
</pre></div>
</div>
</div>
</div>
<p>This looks pretty low but remember we only trained the model on 1,000 instances. Let’s retrain the best estimator on the whole training set:</p>
<p><strong>Warning</strong>: the following cell may take hours to run, depending on your hardware.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rnd_search_cv.best_estimator_.fit(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVC(C=3.8786881587000437, gamma=0.0017076019229344522)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)
accuracy_score(y_train, y_pred)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9978166666666667
</pre></div>
</div>
</div>
</div>
<p>Ah, this looks good! Let’s select this model. Now we can test it on the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)
accuracy_score(y_test, y_pred)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9717
</pre></div>
</div>
</div>
</div>
<p>Not too bad, but apparently the model is overfitting slightly. It’s tempting to tweak the hyperparameters a bit more (e.g. decreasing <code class="docutils literal notranslate"><span class="pre">C</span></code> and/or <code class="docutils literal notranslate"><span class="pre">gamma</span></code>), but we would run the risk of overfitting the test set. Other people have found that the hyperparameters <code class="docutils literal notranslate"><span class="pre">C=5</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma=0.005</span></code> yield even better performance (over 98% accuracy). By running the randomized search for longer and on a larger part of the training set, you may be able to find this as well.</p>
<section id="id3">
<h2>10.<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<p><em>Exercise: train an SVM regressor on the California housing dataset.</em></p>
<p>Let’s load the dataset using Scikit-Learn’s <code class="docutils literal notranslate"><span class="pre">fetch_california_housing()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.datasets import fetch_california_housing

housing = fetch_california_housing()
X = housing[&quot;data&quot;]
y = housing[&quot;target&quot;]
</pre></div>
</div>
</div>
</div>
<p>Split it into a training set and a test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
</pre></div>
</div>
</div>
</div>
<p>Don’t forget to scale the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
</pre></div>
</div>
</div>
</div>
<p>Let’s train a simple <code class="docutils literal notranslate"><span class="pre">LinearSVR</span></code> first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import LinearSVR

lin_svr = LinearSVR(random_state=42)
lin_svr.fit(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  &quot;the number of iterations.&quot;, ConvergenceWarning)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LinearSVR(random_state=42)
</pre></div>
</div>
</div>
</div>
<p>Let’s see how it performs on the training set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.metrics import mean_squared_error

y_pred = lin_svr.predict(X_train_scaled)
mse = mean_squared_error(y_train, y_pred)
mse
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9641780189948642
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the RMSE:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.sqrt(mse)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9819256687727764
</pre></div>
</div>
</div>
</div>
<p>In this training set, the targets are tens of thousands of dollars. The RMSE gives a rough idea of the kind of error you should expect (with a higher weight for large errors): so with this model we can expect errors somewhere around $10,000. Not great. Let’s see if we can do better with an RBF Kernel. We will use randomized search with cross validation to find the appropriate hyperparameter values for <code class="docutils literal notranslate"><span class="pre">C</span></code> and <code class="docutils literal notranslate"><span class="pre">gamma</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import SVR
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import reciprocal, uniform

param_distributions = {&quot;gamma&quot;: reciprocal(0.001, 0.1), &quot;C&quot;: uniform(1, 10)}
rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=10, verbose=2, cv=3, random_state=42)
rnd_search_cv.fit(X_train_scaled, y_train)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 3 folds for each of 10 candidates, totalling 30 fits
[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................
[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   4.7s
[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.7s remaining:    0.0s
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   4.6s
[CV] C=4.745401188473625, gamma=0.07969454818643928 ..................
[CV] ... C=4.745401188473625, gamma=0.07969454818643928, total=   4.7s
[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................
[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   4.3s
[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................
[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   4.2s
[CV] C=8.31993941811405, gamma=0.015751320499779724 ..................
[CV] ... C=8.31993941811405, gamma=0.015751320499779724, total=   4.3s
[CV] C=2.560186404424365, gamma=0.002051110418843397 .................
[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   3.8s
[CV] C=2.560186404424365, gamma=0.002051110418843397 .................
[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   3.8s
[CV] C=2.560186404424365, gamma=0.002051110418843397 .................
[CV] .. C=2.560186404424365, gamma=0.002051110418843397, total=   3.9s
[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................
[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   3.9s
[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................
[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   3.8s
[CV] C=1.5808361216819946, gamma=0.05399484409787431 .................
[CV] .. C=1.5808361216819946, gamma=0.05399484409787431, total=   3.9s
[CV] C=7.011150117432088, gamma=0.026070247583707663 .................
[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   4.3s
[CV] C=7.011150117432088, gamma=0.026070247583707663 .................
[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   4.4s
[CV] C=7.011150117432088, gamma=0.026070247583707663 .................
[CV] .. C=7.011150117432088, gamma=0.026070247583707663, total=   4.4s
[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................
[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   3.8s
[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................
[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   3.9s
[CV] C=1.2058449429580245, gamma=0.0870602087830485 ..................
[CV] ... C=1.2058449429580245, gamma=0.0870602087830485, total=   3.9s
[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................
[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   4.0s
[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................
[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   4.0s
[CV] C=9.324426408004218, gamma=0.0026587543983272693 ................
[CV] . C=9.324426408004218, gamma=0.0026587543983272693, total=   3.9s
[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................
[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   3.8s
[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................
[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   3.8s
[CV] C=2.818249672071006, gamma=0.0023270677083837795 ................
[CV] . C=2.818249672071006, gamma=0.0023270677083837795, total=   3.8s
[CV] C=4.042422429595377, gamma=0.011207606211860567 .................
[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   3.8s
[CV] C=4.042422429595377, gamma=0.011207606211860567 .................
[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   3.9s
[CV] C=4.042422429595377, gamma=0.011207606211860567 .................
[CV] .. C=4.042422429595377, gamma=0.011207606211860567, total=   3.9s
[CV] C=5.319450186421157, gamma=0.003823475224675185 .................
[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   3.8s
[CV] C=5.319450186421157, gamma=0.003823475224675185 .................
[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   3.9s
[CV] C=5.319450186421157, gamma=0.003823475224675185 .................
[CV] .. C=5.319450186421157, gamma=0.003823475224675185, total=   3.9s
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  2.0min finished
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RandomizedSearchCV(cv=3, estimator=SVR(),
                   param_distributions={&#39;C&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9370860850&gt;,
                                        &#39;gamma&#39;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9380503890&gt;},
                   random_state=42, verbose=2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>rnd_search_cv.best_estimator_
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVR(C=4.745401188473625, gamma=0.07969454818643928)
</pre></div>
</div>
</div>
</div>
<p>Now let’s measure the RMSE on the training set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = rnd_search_cv.best_estimator_.predict(X_train_scaled)
mse = mean_squared_error(y_train, y_pred)
np.sqrt(mse)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5727524770785359
</pre></div>
</div>
</div>
</div>
<p>Looks much better than the linear model. Let’s select this model and evaluate it on the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>y_pred = rnd_search_cv.best_estimator_.predict(X_test_scaled)
mse = mean_squared_error(y_test, y_pred)
np.sqrt(mse)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.5929168385528734
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./handson-ml2/original"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="04_training_linear_models.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Chapter 4 – Training Models</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="06_decision_trees.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 6 – Decision Trees</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Daniel Kapitan<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>